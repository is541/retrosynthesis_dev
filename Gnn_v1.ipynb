{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "210180cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipped loading some Jax models, missing a dependency. jax requires jaxlib to be installed. See https://github.com/google/jax#installation for installation instructions.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "import deepchem as dc\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch_geometric.nn import MessagePassing\n",
    "# from torch_geometric.data import DataLoader\n",
    "from torch.utils.data import DataLoader\n",
    "# from torch.utils.data import DataLoader\n",
    "from torch_geometric.utils import to_dense_batch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import numpy as np\n",
    "from rdkit import Chem\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from rdkit.Chem import AllChem\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "from torch.utils.data import Subset\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42e21916",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read json.config\n",
    "with open('config_gnn.json', 'r') as f:\n",
    "    config = json.load(f)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c62b675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'not_in_route_sample_size': 100, 'seed': 42, 'run_id': '202305-2911-2320-5a95df0e-3008-4ebe-acd8-ecb3b50607c7', 'nr_sample_targets': -1, 'model_type': 'gnn', 'batch_size': 64, 'shuffle': True, 'hidden_dim': 512, 'output_dim': 256, 'temperature': 0.1, 'lr': 0.001, 'num_epochs': 100}\n"
     ]
    }
   ],
   "source": [
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e7b34c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = f\"{config['model_type']}_v1\"\n",
    "\n",
    "checkpoint_folder = f'GraphRuns/{experiment_name}/'\n",
    "# if not os.path.exists(checkpoint_folder):\n",
    "#     os.makedirs(checkpoint_folder)\n",
    "\n",
    "checkpoint_name = 'checkpoint.pth'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "393680c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gnn_v1'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "991c98ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save \n",
    "with open(f'{checkpoint_folder}/config.json', 'w') as f:\n",
    "    json.dump(config, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "972dc56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_preprocessed_data = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101cd352",
   "metadata": {},
   "source": [
    "### Read routes data - consider only route 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "26c34f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file_routes = f'Runs/{config[\"run_id\"] }/targ_routes.pickle'\n",
    "# input_file_distances = f'Runs/{config[\"run_id\"]}/targ_to_purch_distances.pickle'\n",
    "\n",
    "# Routes data\n",
    "with open(input_file_routes, 'rb') as handle:\n",
    "    targ_routes_dict = pickle.load(handle)\n",
    "    \n",
    "# # Load distances data\n",
    "# with open(input_file_distances, 'rb') as handle:\n",
    "#     distances_dict = pickle.load(handle)\n",
    "\n",
    "\n",
    "# Inventory\n",
    "from paroutes import PaRoutesInventory\n",
    "inventory=PaRoutesInventory(n=5)\n",
    "purch_smiles = [mol.smiles for mol in inventory.purchasable_mols()]\n",
    "len(purch_smiles)\n",
    "\n",
    "def num_heavy_atoms(mol):\n",
    "    return Chem.rdchem.Mol.GetNumAtoms(mol, onlyExplicit=True)\n",
    "\n",
    "purch_mol_to_exclude = []\n",
    "for smiles in purch_smiles:\n",
    "    if num_heavy_atoms(Chem.MolFromSmiles(smiles)) < 2:\n",
    "        purch_mol_to_exclude = purch_mol_to_exclude + [smiles]\n",
    "\n",
    "\n",
    "\n",
    "targ_route_not_in_route_dict = {}\n",
    "for target, target_routes_dict in targ_routes_dict.items():\n",
    "    targ_route_not_in_route_dict[target] = {}\n",
    "    \n",
    "    target_route_df = target_routes_dict[\"route_1\"]\n",
    "    purch_in_route = list(target_route_df['smiles'])\n",
    "    purch_not_in_route = [purch_smile for purch_smile in purch_smiles if purch_smile not in purch_in_route]\n",
    "    random.seed(config[\"seed\"])\n",
    "    purch_not_in_route_sample = random.sample(purch_not_in_route, config[\"not_in_route_sample_size\"])\n",
    "    \n",
    "    # Filter out molecules with only one atom (problems with featurizer)\n",
    "    purch_in_route = [smiles for smiles in purch_in_route if smiles not in purch_mol_to_exclude]\n",
    "    purch_not_in_route_sample = [smiles for smiles in purch_not_in_route_sample if smiles not in purch_mol_to_exclude]\n",
    "    \n",
    "    targ_route_not_in_route_dict[target]['positive_samples'] = purch_in_route\n",
    "    targ_route_not_in_route_dict[target]['negative_samples'] = purch_not_in_route_sample\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b49573e",
   "metadata": {},
   "source": [
    "### Temp - select a sample of targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e572c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a random sample of keys from targ_routes_dict\n",
    "if config[\"nr_sample_targets\"]!= -1:\n",
    "    sample_targets = random.sample(list(targ_route_not_in_route_dict.keys()), config[\"nr_sample_targets\"])\n",
    "else:\n",
    "    sample_targets = targ_route_not_in_route_dict\n",
    "\n",
    "\n",
    "# Create targ_routes_dict_sample with the sampled keys and their corresponding values\n",
    "targ_route_not_in_route_dict_sample = {target: targ_route_not_in_route_dict[target] for target in sample_targets}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da030ef2",
   "metadata": {},
   "source": [
    "### Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be7b650e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gnn_preprocess_input(input_data):\n",
    "    featurizer = dc.feat.MolGraphConvFeaturizer()\n",
    "    targets = []\n",
    "    positive_samples = []\n",
    "    negative_samples = []\n",
    "\n",
    "    for target_smiles, samples in tqdm(input_data.items()):\n",
    "#         try:\n",
    "        target_feats = featurizer.featurize(Chem.MolFromSmiles(target_smiles))\n",
    "        pos_mols = [Chem.MolFromSmiles(positive_smiles) for positive_smiles in samples['positive_samples']]\n",
    "        neg_mols = [Chem.MolFromSmiles(negative_smiles) for negative_smiles in samples['negative_samples']]\n",
    "        pos_feats = featurizer.featurize(pos_mols)\n",
    "        neg_feats = featurizer.featurize(neg_mols)\n",
    "\n",
    "        targets.append(target_feats[0])\n",
    "        positive_samples.append(pos_feats)\n",
    "        negative_samples.append(neg_feats)\n",
    "#             targets_torch = torch.tensor(target_feats, dtype=torch.double)\n",
    "#             positive_samples = torch.tensor(pos_feats, dtype=torch.double)\n",
    "#             negative_samples = torch.tensor(neg_feats, dtype=torch.double)\n",
    "#             targets.append(targets_torch)\n",
    "#             positive_samples.append(positive_samples)\n",
    "#             negative_samples.append(negative_samples)\n",
    "            \n",
    "#         except:\n",
    "#             # Handle the case where featurization fails for a sample\n",
    "#             print(f\"Featurization failed for sample: {target_smiles}\")\n",
    "        \n",
    "#     targets_tensor = torch.stack(targets)\n",
    "#     positive_samples_tensor = torch.stack(positive_samples)\n",
    "#     negative_samples_tensor = torch.stack(negative_samples)\n",
    "#     return targets_tensor, positive_samples_tensor, negative_samples_tensor\n",
    "    return targets, positive_samples, negative_samples\n",
    "\n",
    "\n",
    "def fingerprint_vect_from_smiles(mol_smiles):\n",
    "    return AllChem.GetMorganFingerprintAsBitVect(AllChem.MolFromSmiles(mol_smiles), radius=3)\n",
    "\n",
    "def fingerprint_preprocess_input(input_data):\n",
    "    targets = []\n",
    "    positive_samples = []\n",
    "    negative_samples = []\n",
    "\n",
    "    for target_smiles, samples in tqdm(input_data.items()):\n",
    "#         target_feats = fingerprint_from_smiles(Chem.MolFromSmiles(target_smiles))\n",
    "#         pos_mols = [Chem.MolFromSmiles(positive_smiles) for positive_smiles in samples['positive_samples']]\n",
    "#         neg_mols = [Chem.MolFromSmiles(negative_smiles) for negative_smiles in samples['negative_samples']]\n",
    "        target_feats = fingerprint_vect_from_smiles(target_smiles)\n",
    "        pos_feats = list(map(fingerprint_vect_from_smiles, samples['positive_samples']))\n",
    "        neg_feats = list(map(fingerprint_vect_from_smiles, samples['negative_samples']))\n",
    "        \n",
    "#         targets.append(target_feats[0])\n",
    "#         positive_samples.append(pos_feats)\n",
    "#         negative_samples.append(neg_feats)\n",
    "        targets.append(torch.tensor(target_feats, dtype=torch.double))\n",
    "        positive_samples.append(torch.tensor(pos_feats, dtype=torch.double))\n",
    "        negative_samples.append(torch.tensor(neg_feats, dtype=torch.double))\n",
    "        \n",
    "\n",
    "    return targets, positive_samples, negative_samples\n",
    "\n",
    "\n",
    "\n",
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, targets, positive_samples, negative_samples):\n",
    "        self.targets = targets\n",
    "        self.positive_samples = positive_samples\n",
    "        self.negative_samples = negative_samples\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.targets)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        target = self.targets[idx]\n",
    "        positive = self.positive_samples[idx]\n",
    "        negative = self.negative_samples[idx]\n",
    "\n",
    "        return target, positive, negative\n",
    "\n",
    "\n",
    "# def collate_fn(data):\n",
    "#     print(\"Using collate_fn\")\n",
    "#     targets = []\n",
    "#     positive_samples = []\n",
    "#     negative_samples = []\n",
    "\n",
    "#     for target, positive, negative in data:\n",
    "#         targets.append(target)\n",
    "#         positive_samples.extend(positive)\n",
    "#         negative_samples.extend(negative)\n",
    "\n",
    "#     targets = torch.stack(targets, dim=0)\n",
    "#     positive_samples = torch.stack(positive_samples, dim=0)\n",
    "#     negative_samples = torch.stack(negative_samples, dim=0)\n",
    "\n",
    "#     return targets, positive_samples, negative_samples\n",
    "\n",
    "def collate_fn(data):\n",
    "    targets, positive_samples, negative_samples = zip(*data)\n",
    "\n",
    "    return targets, positive_samples, negative_samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "189777fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SampleData:\n",
    "    def __init__(self, target, positive_samples, negative_samples):\n",
    "        self.target = target\n",
    "        self.positive_samples = positive_samples\n",
    "        self.negative_samples = negative_samples\n",
    "\n",
    "\n",
    "# def preprocess_input(input_data):\n",
    "#     featurizer = dc.feat.MolGraphConvFeaturizer()\n",
    "#     data_list = []\n",
    "    \n",
    "#     for target_smiles, samples in tqdm(input_data.items()):\n",
    "#         target_feats = featurizer.featurize(Chem.MolFromSmiles(target_smiles))\n",
    "#         pos_mols = [Chem.MolFromSmiles(positive_smiles) for positive_smiles in samples['positive_samples']]\n",
    "#         neg_mols = [Chem.MolFromSmiles(negative_smiles) for negative_smiles in samples['negative_samples']]\n",
    "#         pos_feats = featurizer.featurize(pos_mols)\n",
    "#         neg_feats = featurizer.featurize(neg_mols)\n",
    "#         data_list = data_list + [SampleData(target=target_feats, positive_samples=pos_feats, negative_samples=neg_feats)]\n",
    "#     return data_list\n",
    "        \n",
    "# class CustomDataset(Dataset):\n",
    "#     def __init__(self, data):\n",
    "#         self.data = data\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.data)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         sample = self.data[idx]\n",
    "# #         return sample\n",
    "\n",
    "# #         # Extract the target_smiles, positive_sample, and negative_samples\n",
    "# # #         target_smiles = sample['target_smiles']\n",
    "# # #         positive_sample = sample['positive_sample']\n",
    "# # #         negative_samples = sample['negative_samples']\n",
    "#         target = sample.target\n",
    "#         positive_samples = sample.positive_samples\n",
    "#         negative_samples = sample.negative_samples\n",
    "\n",
    "#         # Convert the data to tensors or any other necessary preprocessing\n",
    "\n",
    "#         # Return the sample with named attributes\n",
    "# #         return {\n",
    "# #             'target': target,\n",
    "# #             'positive_samples': positive_samples,\n",
    "# #             'negative_samples': negative_samples\n",
    "# #         }\n",
    "#         return target, positive_samples, negative_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "07a799c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Define embedding model\n",
    "class FullyConnectedModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(FullyConnectedModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "def custom_global_max_pool(x):\n",
    "    return torch.max(x, dim=0)[0]\n",
    "\n",
    "class GNNModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "#     def __init__(self, hidden_dim, output_dim):\n",
    "        super(GNNModel, self).__init__()\n",
    "        self.conv1 = GCNConv(input_dim, hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, hidden_dim)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        # Global max pooling (from node level to graph level embeddings)\n",
    "#         x = global_max_pool(x) #, edge_index[0]\n",
    "        x = custom_global_max_pool(x)\n",
    "\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "class FingerprintModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(FingerprintModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim, dtype=torch.double)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim, dtype=torch.double)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "from scipy.special import logsumexp\n",
    "\n",
    "# Step 3: Create a contrastive learning loss function\n",
    "class NTXentLoss(nn.Module):\n",
    "    def __init__(self, temperature):\n",
    "        super(NTXentLoss, self).__init__()\n",
    "        self.temperature = temperature\n",
    "        self.cos_sim = nn.CosineSimilarity(dim=-1)\n",
    "\n",
    "    def forward(self, embeddings):\n",
    "        sample_losses = []\n",
    "        for single_sample_embeddings in embeddings:\n",
    "            target_emb = single_sample_embeddings.target\n",
    "            positive_embs = single_sample_embeddings.positive_samples\n",
    "            negative_embs = single_sample_embeddings.negative_samples\n",
    "            \n",
    "            # Sample one positive\n",
    "            nr_positives = positive_embs.size(0)\n",
    "            # Randomly select a positive sample\n",
    "            row_index = torch.randint(0, nr_positives, (1,))\n",
    "            positive_emb = torch.index_select(positive_embs, dim=0, index=row_index)\n",
    "#             positive_emb = positive_emb.squeeze(0)\n",
    "            \n",
    "            positive_similarity = self.cos_sim(target_emb, positive_emb)\n",
    "            positive_similarity /= self.temperature           \n",
    "            negative_similarity = self.cos_sim(target_emb, negative_embs)\n",
    "            negative_similarity /= self.temperature\n",
    "            \n",
    "            # Old implementation\n",
    "#             numerator = torch.exp(positive_similarity)\n",
    "#             denominator = torch.sum(torch.exp(negative_similarity))\n",
    "#             sample_loss = -torch.log(numerator / (numerator + denominator))\n",
    "            # End Old implementation\n",
    "            # New implementation\n",
    "            all_similarities =  torch.cat([positive_similarity, negative_similarity], dim=0)\n",
    "            sample_loss = -positive_similarity + logsumexp(all_similarities, dim=0, keepdims=True)\n",
    "            # End New implementation\n",
    "            \n",
    "            sample_losses = sample_losses + [sample_loss]\n",
    "        \n",
    "        return sum(sample_losses) / len(sample_losses)\n",
    "\n",
    "\n",
    "\n",
    "# import torch\n",
    "# from pytorch_metric_learning.losses import GenericPairLoss\n",
    "\n",
    "# class NTXentLoss(GenericPairLoss):\n",
    "\n",
    "#     def __init__(self, temperature, **kwargs):\n",
    "#         super().__init__(use_similarity=True, mat_based_loss=False, **kwargs)\n",
    "#         self.temperature = temperature\n",
    "\n",
    "#     def _compute_loss(self, pos_pairs, neg_pairs, indices_tuple):\n",
    "#         a1, p, a2, _ = indices_tuple\n",
    "\n",
    "#         if len(a1) > 0 and len(a2) > 0:\n",
    "#             pos_pairs = pos_pairs.unsqueeze(1) / self.temperature\n",
    "#             neg_pairs = neg_pairs / self.temperature\n",
    "#             n_per_p = (a2.unsqueeze(0) == a1.unsqueeze(1)).float()\n",
    "#             neg_pairs = neg_pairs*n_per_p\n",
    "#             neg_pairs[n_per_p==0] = float('-inf')\n",
    "\n",
    "#             max_val = torch.max(pos_pairs, torch.max(neg_pairs, dim=1, keepdim=True)[0].half()) ###This is the line change\n",
    "#             numerator = torch.exp(pos_pairs - max_val).squeeze(1)\n",
    "#             denominator = torch.sum(torch.exp(neg_pairs - max_val), dim=1) + numerator\n",
    "#             log_exp = torch.log((numerator/denominator) + 1e-20)\n",
    "#             return {\"loss\": {\"losses\": -log_exp, \"indices\": (a1, p), \"reduction_type\": \"pos_pair\"}}\n",
    "#         return self.zero_losses()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Or use NTXentMultiplePositives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7a2fa61a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 9895/9895 [1:13:36<00:00,  2.24it/s]\n"
     ]
    }
   ],
   "source": [
    "# # Step 1: Prepare the dataset\n",
    "# # Assuming we have a dataset file named 'molecules.csv' with molecular structures and labels\n",
    "# dataset = dc.data.CSVLoader(tasks=['property'], feature_field='smiles')\n",
    "# dataset.load_from_file('molecules.csv')\n",
    "# splitter = dc.splits.RandomSplitter()\n",
    "# train_dataset, valid_dataset, _ = splitter.train_valid_test_split(dataset)\n",
    "\n",
    "# Step 1: Create data dictionary getting negative samples for each target\n",
    "input_data = targ_route_not_in_route_dict_sample\n",
    "\n",
    "\n",
    "# Step 2: Featurizer and cast as CustomDataset\n",
    "# Step 3: Create DataLoader\n",
    "\n",
    "\n",
    "if config[\"model_type\"] == 'gnn':\n",
    "    preprocessed_targets, preprocessed_positive_samples, preprocessed_negative_samples = gnn_preprocess_input(input_data)\n",
    "    dataset = CustomDataset(preprocessed_targets, preprocessed_positive_samples, preprocessed_negative_samples)\n",
    "elif config[\"model_type\"] == 'fingerprints':\n",
    "    preprocessed_targets, preprocessed_positive_samples, preprocessed_negative_samples = fingerprint_preprocess_input(input_data)\n",
    "    dataset = CustomDataset(preprocessed_targets, preprocessed_positive_samples, preprocessed_negative_samples)\n",
    "else:\n",
    "    raise NotImplementedError(f'Model type {config[\"model_type\"]}')\n",
    "    \n",
    "    \n",
    "\n",
    "# def collate_fn(data):\n",
    "#     targets = [sample[0] for sample in data]\n",
    "#     positive_samples = [sample[1] for sample in data]\n",
    "#     negative_samples = [sample[2] for sample in data]\n",
    "\n",
    "#     return targets, positive_samples, negative_samples\n",
    "# def collate_fn(data):\n",
    "#     targets = [sample[0] for sample in data]\n",
    "#     positive_samples = [sample[1] for sample in data]\n",
    "#     negative_samples = [sample[2] for sample in data]\n",
    "\n",
    "#     return targets, positive_samples, negative_samples\n",
    "\n",
    "# Save\n",
    "if save_preprocessed_data:\n",
    "    with open(f'{checkpoint_folder}/preprocessed_targets.pickle', 'wb') as handle:\n",
    "            pickle.dump(preprocessed_targets, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    with open(f'{checkpoint_folder}/preprocessed_positive_samples.pickle', 'wb') as handle:\n",
    "            pickle.dump(preprocessed_positive_samples, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    with open(f'{checkpoint_folder}/preprocessed_negative_samples.pickle', 'wb') as handle:\n",
    "            pickle.dump(preprocessed_negative_samples, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# # Load\n",
    "# with open(f'{checkpoint_folder}/preprocessed_targets.pickle', 'wb') as handle:\n",
    "#     preprocessed_targets = pickle.load(handle)\n",
    "# with open(f'{checkpoint_folder}/preprocessed_positive_samples.pickle', 'wb') as handle:\n",
    "#     preprocessed_positive_samples = pickle.load(handle)\n",
    "# with open(f'{checkpoint_folder}/preprocessed_negative_samples.pickle', 'wb') as handle:\n",
    "#     preprocessed_negative_samples = pickle.load(handle)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67384521",
   "metadata": {},
   "source": [
    "##### Train and validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb56227c",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_ratio = config[\"validation_ratio\"]\n",
    "num_samples = len(dataset)\n",
    "num_val_samples = int(validation_ratio * num_samples)\n",
    "\n",
    "train_indices, val_indices = train_test_split(range(num_samples), test_size=num_val_samples, random_state=42)\n",
    "\n",
    "train_dataset = Subset(dataset, train_indices)\n",
    "val_dataset = Subset(dataset, val_indices)\n",
    "\n",
    "train_data_loader = DataLoader(train_dataset, batch_size=config[\"train_batch_size\"], shuffle=config[\"train_shuffle\"], collate_fn=collate_fn)\n",
    "val_data_loader = DataLoader(val_dataset, batch_size=config[\"val_batch_size\"], shuffle=config[\"val_shuffle\"], collate_fn=collate_fn)\n",
    "\n",
    "\n",
    "# Batch size: The batch size determines the number of samples processed in each iteration during training or validation. In most cases, it is common to use the same batch size for both training and validation to maintain consistency. However, there are situations where you might choose a different batch size for validation. For instance, if memory constraints are more relaxed during validation, you can use a larger batch size to speed up evaluation.\n",
    "# Shuffle training data: Shuffling the training data before each epoch is beneficial because it helps the model see the data in different orders, reducing the risk of the model learning patterns specific to the order of the data. Shuffling the training data introduces randomness and promotes better generalization.\n",
    "# No shuffle for validation data: It is generally not necessary to shuffle the validation data because validation is meant to evaluate the model's performance on unseen data that is representative of the real-world scenarios. Shuffling the validation data could lead to inconsistent evaluation results between different validation iterations, making it harder to track the model's progress and compare performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "04bf86df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function collate_fn at 0x2d45fe440>\n"
     ]
    }
   ],
   "source": [
    "print(data_loader.collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4dd6eec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(preprocessed_targets[0])\n",
    "# (preprocessed_targets[0].size()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f529c2ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ef2f1b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if config[\"model_type\"] == 'gnn':\n",
    "    gnn_input_dim = preprocessed_targets[0].node_features.shape[1]\n",
    "    gnn_hidden_dim = config[\"hidden_dim\"]\n",
    "    gnn_output_dim = config[\"output_dim\"]\n",
    "    \n",
    "    with open(f'{checkpoint_folder}/input_dim.pickle' , 'wb') as f:\n",
    "        pickle.dump({'input_dim': gnn_input_dim}, f)\n",
    "    \n",
    "elif config[\"model_type\"] == 'fingerprints':\n",
    "#     fingerprint_input_dim = preprocessed_targets[0].GetNumBits()\n",
    "    fingerprint_input_dim = len(preprocessed_targets[0].node_features) #(preprocessed_targets[0].size()[0])\n",
    "    fingerprint_hidden_dim = config[\"hidden_dim\"]\n",
    "    fingerprint_output_dim = config[\"output_dim\"]\n",
    "    \n",
    "    with open(f'{checkpoint_folder}/input_dim.pickle' , 'wb') as f:\n",
    "        pickle.dump({'input_dim': fingerprint_input_dim}, f)\n",
    "    \n",
    "    \n",
    "else:\n",
    "    raise NotImplementedError(f'Model type {config[\"model_type\"]}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c66b9ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Set up the training loop for the GNN model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "if config[\"model_type\"] == 'gnn':\n",
    "    model = GNNModel(\n",
    "        input_dim=gnn_input_dim, \n",
    "        hidden_dim=gnn_hidden_dim, \n",
    "        output_dim=gnn_output_dim).to(device)\n",
    "    model.double()\n",
    "    \n",
    "elif config[\"model_type\"] == 'fingerprints':\n",
    "    model = FingerprintModel(\n",
    "        input_dim=fingerprint_input_dim, \n",
    "        hidden_dim=fingerprint_hidden_dim, \n",
    "        output_dim=fingerprint_output_dim).to(device)\n",
    "else:\n",
    "    raise NotImplementedError(f'Model type {config[\"model_type\"]}')\n",
    "\n",
    "\n",
    "\n",
    "loss_fn = NTXentLoss(temperature=config[\"temperature\"])\n",
    "optimizer = optim.Adam(model.parameters(), lr=config[\"lr\"])\n",
    "\n",
    "num_epochs = config[\"num_epochs\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2ddda7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def compute_gnn_embedding(gnn_model):\n",
    "#     node_features = torch.tensor(example.node_features, dtype=torch.double)\n",
    "#     edge_index = torch.tensor(example.edge_index, dtype=torch.long)  # Assuming edge_index is of type 'long'\n",
    "\n",
    "#     # Convert the input node features to double\n",
    "#     node_features = node_features.double()\n",
    "\n",
    "#     # Compute the embeddings for the positive example\n",
    "#     embedding = model(node_features, edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b84332da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.collate_fn(data)>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_loader.collate_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2ca7f5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_from_checkpoint=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c585c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_embeddings_and_loss(model, batch_targets, batch_positive_samples, batch_negative_samples, loss_fn):\n",
    "    embeddings = []\n",
    "    for i in range(len(batch_targets)):\n",
    "        target = batch_targets[i]\n",
    "        positives = batch_positive_samples[i]\n",
    "        negatives = batch_negative_samples[i]\n",
    "\n",
    "        if config[\"model_type\"] == 'gnn':\n",
    "            target_node_features = torch.tensor(target.node_features, dtype=torch.double)\n",
    "            target_edge_index = torch.tensor(target.edge_index, dtype=torch.long)\n",
    "            target_embedding = model(target_node_features, target_edge_index)\n",
    "\n",
    "            positive_samples_embeddings = torch.stack([\n",
    "                model(torch.tensor(example.node_features, dtype=torch.double),\n",
    "                      torch.tensor(example.edge_index, dtype=torch.long))\n",
    "                for example in positives\n",
    "            ], dim=0)\n",
    "\n",
    "            negative_samples_embeddings = torch.stack([\n",
    "                model(torch.tensor(example.node_features, dtype=torch.double),\n",
    "                      torch.tensor(example.edge_index, dtype=torch.long))\n",
    "                for example in negatives\n",
    "            ], dim=0)\n",
    "\n",
    "            embeddings.append(\n",
    "                SampleData(target=target_embedding, positive_samples=positive_samples_embeddings,\n",
    "                           negative_samples=negative_samples_embeddings)\n",
    "            )\n",
    "#             embeddings = embeddings + [SampleData(target=target_embedding, positive_samples=positive_samples_embeddings, negative_samples=negative_samples_embeddings)]\n",
    "\n",
    "\n",
    "        elif config[\"model_type\"] == 'fingerprints':\n",
    "            target_embedding = model(target)\n",
    "            positive_samples_embeddings = model(positives)\n",
    "            negative_samples_embeddings = model(negatives)\n",
    "\n",
    "            embeddings.append(\n",
    "                SampleData(target=target_embedding, positive_samples=positive_samples_embeddings,\n",
    "                           negative_samples=negative_samples_embeddings)\n",
    "            )\n",
    "#             embeddings = embeddings + [SampleData(target=target_embedding, positive_samples=positive_samples_embeddings, negative_samples=negative_samples_embeddings)]\n",
    "\n",
    "\n",
    "        else:\n",
    "            raise NotImplementedError(f'Model type {config[\"model_type\"]}')\n",
    "\n",
    "    # Compute loss for the batch\n",
    "    loss = loss_fn(embeddings)\n",
    "\n",
    "    return embeddings, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "653842f7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▋                                                                       | 1/100 [24:21<40:10:50, 1461.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gnn Model - Epoch 1/100, Loss: 2.103701420761078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|███████▌                                                             | 11/100 [4:47:43<39:34:54, 1601.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gnn Model - Epoch 11/100, Loss: 0.18274515600282853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|████████████▋                                                      | 19/100 [29:41:15<126:33:45, 5625.00s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 41\u001b[0m\n\u001b[1;32m     33\u001b[0m     target_embedding \u001b[38;5;241m=\u001b[39m model(target_node_features, target_edge_index)\n\u001b[1;32m     35\u001b[0m     positive_samples_embeddings \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack([\n\u001b[1;32m     36\u001b[0m         model(torch\u001b[38;5;241m.\u001b[39mtensor(example\u001b[38;5;241m.\u001b[39mnode_features, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdouble)\u001b[38;5;241m.\u001b[39mdouble(),\n\u001b[1;32m     37\u001b[0m               torch\u001b[38;5;241m.\u001b[39mtensor(example\u001b[38;5;241m.\u001b[39medge_index, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong)) \n\u001b[1;32m     38\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m example \u001b[38;5;129;01min\u001b[39;00m positives\n\u001b[1;32m     39\u001b[0m     ], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m---> 41\u001b[0m     negative_samples_embeddings \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack([\n\u001b[1;32m     42\u001b[0m         model(torch\u001b[38;5;241m.\u001b[39mtensor(example\u001b[38;5;241m.\u001b[39mnode_features, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdouble)\u001b[38;5;241m.\u001b[39mdouble(),\n\u001b[1;32m     43\u001b[0m               torch\u001b[38;5;241m.\u001b[39mtensor(example\u001b[38;5;241m.\u001b[39medge_index, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong)) \n\u001b[1;32m     44\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m example \u001b[38;5;129;01min\u001b[39;00m negatives\n\u001b[1;32m     45\u001b[0m     ], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     46\u001b[0m     embeddings \u001b[38;5;241m=\u001b[39m embeddings \u001b[38;5;241m+\u001b[39m [SampleData(target\u001b[38;5;241m=\u001b[39mtarget_embedding, positive_samples\u001b[38;5;241m=\u001b[39mpositive_samples_embeddings, negative_samples\u001b[38;5;241m=\u001b[39mnegative_samples_embeddings)]\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfingerprints\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "Cell \u001b[0;32mIn[23], line 42\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     33\u001b[0m     target_embedding \u001b[38;5;241m=\u001b[39m model(target_node_features, target_edge_index)\n\u001b[1;32m     35\u001b[0m     positive_samples_embeddings \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack([\n\u001b[1;32m     36\u001b[0m         model(torch\u001b[38;5;241m.\u001b[39mtensor(example\u001b[38;5;241m.\u001b[39mnode_features, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdouble)\u001b[38;5;241m.\u001b[39mdouble(),\n\u001b[1;32m     37\u001b[0m               torch\u001b[38;5;241m.\u001b[39mtensor(example\u001b[38;5;241m.\u001b[39medge_index, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong)) \n\u001b[1;32m     38\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m example \u001b[38;5;129;01min\u001b[39;00m positives\n\u001b[1;32m     39\u001b[0m     ], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     41\u001b[0m     negative_samples_embeddings \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack([\n\u001b[0;32m---> 42\u001b[0m         \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexample\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnode_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdouble\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdouble\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m              \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexample\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlong\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \n\u001b[1;32m     44\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m example \u001b[38;5;129;01min\u001b[39;00m negatives\n\u001b[1;32m     45\u001b[0m     ], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     46\u001b[0m     embeddings \u001b[38;5;241m=\u001b[39m embeddings \u001b[38;5;241m+\u001b[39m [SampleData(target\u001b[38;5;241m=\u001b[39mtarget_embedding, positive_samples\u001b[38;5;241m=\u001b[39mpositive_samples_embeddings, negative_samples\u001b[38;5;241m=\u001b[39mnegative_samples_embeddings)]\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfingerprints\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[0;32m~/miniforge3/envs/syntheseus_temp_molclr/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[12], line 35\u001b[0m, in \u001b[0;36mGNNModel.forward\u001b[0;34m(self, x, edge_index)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, edge_index):\n\u001b[0;32m---> 35\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(x)\n\u001b[1;32m     37\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(x, edge_index)\n",
      "File \u001b[0;32m~/miniforge3/envs/syntheseus_temp_molclr/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniforge3/envs/syntheseus_temp_molclr/lib/python3.10/site-packages/torch_geometric/nn/conv/gcn_conv.py:182\u001b[0m, in \u001b[0;36mGCNConv.forward\u001b[0;34m(self, x, edge_index, edge_weight)\u001b[0m\n\u001b[1;32m    179\u001b[0m x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m@\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight\n\u001b[1;32m    181\u001b[0m \u001b[38;5;66;03m# propagate_type: (x: Tensor, edge_weight: OptTensor)\u001b[39;00m\n\u001b[0;32m--> 182\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpropagate\u001b[49m\u001b[43m(\u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43medge_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m                     \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    186\u001b[0m     out \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias\n",
      "File \u001b[0;32m~/miniforge3/envs/syntheseus_temp_molclr/lib/python3.10/site-packages/torch_geometric/nn/conv/message_passing.py:233\u001b[0m, in \u001b[0;36mMessagePassing.propagate\u001b[0;34m(self, edge_index, size, **kwargs)\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;66;03m# Otherwise, run both functions in separation.\u001b[39;00m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(edge_index, Tensor) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuse:\n\u001b[0;32m--> 233\u001b[0m     coll_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__collect__\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__user_args__\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    234\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    236\u001b[0m     msg_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minspector\u001b[38;5;241m.\u001b[39mdistribute(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m'\u001b[39m, coll_dict)\n\u001b[1;32m    237\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmessage(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmsg_kwargs)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Check if a checkpoint exists and load the model state and optimizer state if available\n",
    "if load_from_checkpoint:\n",
    "    checkpoint = torch.load(checkpoint_path)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    start_epoch = checkpoint['epoch'] + 1\n",
    "else:\n",
    "    start_epoch = 0\n",
    "\n",
    "# Create a SummaryWriter for TensorBoard logging\n",
    "log_dir = f'{checkpoint_folder}/logs'  # Specify the directory to store TensorBoard logs\n",
    "writer = SummaryWriter(log_dir)\n",
    "\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "best_model = None\n",
    "\n",
    "epoch_loss = pd.DataFrame(columns=['Epoch', 'TrainLoss', 'ValLoss'])\n",
    "for epoch in tqdm(range(start_epoch, num_epochs)):\n",
    "    # TRAIN\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_batches = 0\n",
    "    \n",
    "    for batch_idx, batch_data in enumerate(train_data_loader):\n",
    "        batch_targets, batch_positive_samples, batch_negative_samples = batch_data\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        embeddings, loss = compute_embeddings_and_loss(model, batch_targets, batch_positive_samples, batch_negative_samples, loss_fn)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Track total loss\n",
    "        train_loss += loss.item()\n",
    "        train_batches += 1\n",
    "    \n",
    "    # VALIDATION\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    val_loss = 0.0\n",
    "    val_batches = 0\n",
    "    with torch.no_grad():  # Disable gradient calculation during validation\n",
    "        for val_batch_idx, val_batch_data in enumerate(val_data_loader):\n",
    "            val_batch_targets, val_batch_positive_samples, val_batch_negative_samples = val_batch_data\n",
    "\n",
    "            val_embeddings, val_batch_loss = compute_embeddings_and_loss(model, val_batch_targets,\n",
    "                                                                     val_batch_positive_samples,\n",
    "                                                                     val_batch_negative_samples, loss_fn)\n",
    "\n",
    "\n",
    "            val_loss += val_batch_loss.item()\n",
    "            val_batches += 1\n",
    "            \n",
    "    # METRICS\n",
    "    # - TRAIN\n",
    "    # Compute average loss for the epoch\n",
    "    average_train_loss = train_loss / train_batches\n",
    "        \n",
    "    # Log the loss to TensorBoard\n",
    "    writer.add_scalar('Loss/train', average_train_loss, epoch+1)\n",
    "    \n",
    "    # - VALIDATION\n",
    "    average_val_loss = val_loss / val_batches\n",
    "    \n",
    "    # Log the loss to TensorBoard\n",
    "    writer.add_scalar('Loss/val', average_val_loss, epoch+1)\n",
    "    \n",
    "    new_row = pd.DataFrame({'Epoch': [epoch], 'TrainLoss': [average_train_loss], 'ValLoss': [average_val_loss]})\n",
    "    epoch_loss = pd.concat([epoch_loss, new_row], axis=0)\n",
    "\n",
    "    \n",
    "    if ((epoch%10==0) | (epoch==num_epochs-1)):\n",
    "        print(f\"{config['model_type']} Model - Epoch {epoch+1}/{num_epochs}, TrainLoss: {average_train_loss}, ValLoss: {average_val_loss}\")\n",
    "        \n",
    "        # Save the model and optimizer state as a checkpoint\n",
    "        checkpoint = {\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "        }\n",
    "        checkpoint_path = f'{checkpoint_folder}/epoch_{epoch+1}_{checkpoint_name}'  # Specify the checkpoint file path\n",
    "        torch.save(checkpoint, checkpoint_path)\n",
    "        \n",
    "#         loss_df = pd.DataFrame({'Epoch': range(len(epoch_loss)), 'TrainLoss': epoch_loss})\n",
    "        epoch_loss.to_csv(f'{checkpoint_folder}/train_val_loss.csv', index=False)\n",
    "    \n",
    "    if average_val_loss < best_val_loss:\n",
    "        best_val_loss = average_val_loss\n",
    "        best_model = model\n",
    "    \n",
    "    \n",
    "        \n",
    "\n",
    "# Close the SummaryWriter\n",
    "writer.close()\n",
    "\n",
    "# Save the best model as a pickle\n",
    "best_model_path = f'{checkpoint_folder}/model_min_val.pkl' #'path/to/best_model.pkl'\n",
    "\n",
    "with open(best_model_path, 'wb') as f:\n",
    "    pickle.dump(best_model, f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e736cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "# fig = px.line(x=epoch_loss['Epoch'], y=epoch_loss['TrainLoss'], title=\"Train loss\")\n",
    "# fig.update_layout(width=1000, height=600, showlegend=False)\n",
    "# fig.write_image(f\"{checkpoint_folder}/Train_loss.pdf\")\n",
    "# fig.show()\n",
    "\n",
    "# Create a new figure with two lines\n",
    "fig = px.line()\n",
    "\n",
    "# Add the TrainLoss line to the figure\n",
    "fig.add_scatter(x=epoch_loss['Epoch'], y=epoch_loss['TrainLoss'], name='Train Loss')\n",
    "\n",
    "# Add the ValLoss line to the figure\n",
    "fig.add_scatter(x=epoch_loss['Epoch'], y=epoch_loss['ValLoss'], name='Validation Loss')\n",
    "\n",
    "# Set the title of the figure\n",
    "fig.update_layout(title=\"Train and Validation Loss\")\n",
    "\n",
    "# Set the layout size and show the legend\n",
    "fig.update_layout(width=1000, height=600, showlegend=True)\n",
    "\n",
    "# Save the figure as a PDF file\n",
    "fig.write_image(f\"{checkpoint_folder}/Train_and_Val_loss.pdf\")\n",
    "\n",
    "# Show the figure\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e57b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save\n",
    "# with open(f'{checkpoint_folder}/preprocessed_targets.pickle', 'wb') as handle:\n",
    "#         pickle.dump(preprocessed_targets, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "# with open(f'{checkpoint_folder}/preprocessed_positive_samples.pickle', 'wb') as handle:\n",
    "#         pickle.dump(preprocessed_positive_samples, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "# with open(f'{checkpoint_folder}/preprocessed_negative_samples.pickle', 'wb') as handle:\n",
    "#         pickle.dump(preprocessed_negative_samples, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f0b8ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

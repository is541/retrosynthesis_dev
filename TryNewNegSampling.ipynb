{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "387e7995",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to featurize datapoint 1585, Cl. Appending empty array\n",
      "Exception message: More than one atom should be present in the molecule for this featurizer to work.\n",
      "Failed to featurize datapoint 3118, F. Appending empty array\n",
      "Exception message: More than one atom should be present in the molecule for this featurizer to work.\n",
      "Failed to featurize datapoint 3161, [S-2]. Appending empty array\n",
      "Exception message: More than one atom should be present in the molecule for this featurizer to work.\n",
      "Failed to featurize datapoint 4706, [Mg]. Appending empty array\n",
      "Exception message: More than one atom should be present in the molecule for this featurizer to work.\n",
      "Failed to featurize datapoint 8338, N. Appending empty array\n",
      "Exception message: More than one atom should be present in the molecule for this featurizer to work.\n",
      "Failed to featurize datapoint 10127, O. Appending empty array\n",
      "Exception message: More than one atom should be present in the molecule for this featurizer to work.\n",
      "Failed to featurize datapoint 10753, S. Appending empty array\n",
      "Exception message: More than one atom should be present in the molecule for this featurizer to work.\n",
      "Failed to featurize datapoint 11426, Br. Appending empty array\n",
      "Exception message: More than one atom should be present in the molecule for this featurizer to work.\n",
      "Failed to featurize datapoint 11620, I. Appending empty array\n",
      "Exception message: More than one atom should be present in the molecule for this featurizer to work.\n",
      "/Users/ilariasartori/miniforge3/envs/syntheseus_temp/lib/python3.10/site-packages/deepchem/feat/base_classes.py:322: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return np.asarray(features)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9634c7f4cd554e359df7df6d67159a8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'node_features'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 385\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;66;03m# Batch size: The batch size determines the number of samples processed in each iteration during training or validation. In most cases, it is common to use the same batch size for both training and validation to maintain consistency. However, there are situations where you might choose a different batch size for validation. For instance, if memory constraints are more relaxed during validation, you can use a larger batch size to speed up evaluation.\u001b[39;00m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;66;03m# Shuffle training data: Shuffling the training data before each epoch is beneficial because it helps the model see the data in different orders, reducing the risk of the model learning patterns specific to the order of the data. Shuffling the training data introduces randomness and promotes better generalization.\u001b[39;00m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;66;03m# No shuffle for validation data: It is generally not necessary to shuffle the validation data because validation is meant to evaluate the model's performance on unseen data that is representative of the real-world scenarios. Shuffling the validation data could lead to inconsistent evaluation results between different validation iterations, making it harder to track the model's progress and compare performance.\u001b[39;00m\n\u001b[1;32m    382\u001b[0m \n\u001b[1;32m    383\u001b[0m \u001b[38;5;66;03m# Define network dimensions\u001b[39;00m\n\u001b[1;32m    384\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgnn\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 385\u001b[0m     gnn_input_dim \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtargets\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnode_features\u001b[49m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    386\u001b[0m     gnn_hidden_dim \u001b[38;5;241m=\u001b[39m config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhidden_dim\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    387\u001b[0m     gnn_output_dim \u001b[38;5;241m=\u001b[39m config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_dim\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'node_features'"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Script to train neural network to get molecules embeddings\n",
    "\"\"\"\n",
    "from __future__ import annotations\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import pickle\n",
    "import json\n",
    "import random\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from paroutes import PaRoutesInventory, get_target_smiles\n",
    "from embedding_model import (\n",
    "    fingerprint_preprocess_input,\n",
    "    gnn_preprocess_input,\n",
    "    CustomDataset,\n",
    "    collate_fn,\n",
    "    # SampleData,\n",
    "    fingerprint_vect_from_smiles,\n",
    "    compute_embeddings,\n",
    "    GNNModel,\n",
    "    FingerprintModel,\n",
    "    NTXentLoss,\n",
    "    num_heavy_atoms\n",
    ")\n",
    "from paroutes import PaRoutesInventory\n",
    "from torch.utils.data import Subset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import plotly.express as px\n",
    "from rdkit import Chem\n",
    "import deepchem as dc\n",
    "\n",
    "\n",
    "def gnn_preprocess_input_v1(\n",
    "    input_data,\n",
    "#     featurizer,\n",
    "#     featurizer_dict=None,\n",
    "    pos_sampling=None,\n",
    "):\n",
    "    targets = []\n",
    "    positive_samples = []\n",
    "    negative_samples = []\n",
    "    pos_weights = []\n",
    "\n",
    "    for target_smiles, samples in tqdm(input_data.items()):\n",
    "#         target_feats, pos_feats, neg_feats = gnn_preprocess_target_pos_negs(\n",
    "#             target_smiles, samples, featurizer, featurizer_dict\n",
    "#         )\n",
    "        targets.append(target_smiles)\n",
    "        positive_samples.append(samples[\"positive_samples\"])\n",
    "        negative_samples.append(samples[\"negative_samples\"])\n",
    "\n",
    "        # Deal with pos_sampling\n",
    "        if pos_sampling == \"uniform\":\n",
    "            positive_weights = None\n",
    "        elif pos_sampling == \"prop_num_atoms\":\n",
    "            positive_weights = [\n",
    "                num_heavy_atoms(Chem.MolFromSmiles(positive_smiles))\n",
    "                for positive_smiles in samples[\"positive_samples\"]\n",
    "            ]\n",
    "            positive_weights = torch.tensor(positive_weights, dtype=torch.double)\n",
    "            # Normalize the tensor to sum up to 1\n",
    "            positive_weights = positive_weights / positive_weights.sum()\n",
    "        else:\n",
    "            raise NotImplementedError(f\"{pos_sampling}\")\n",
    "\n",
    "        pos_weights.append(positive_weights)\n",
    "\n",
    "    return CustomDataset(\n",
    "        targets=targets,\n",
    "        positive_samples=positive_samples,\n",
    "        negative_samples=negative_samples,\n",
    "        pos_weights=pos_weights,\n",
    "    )\n",
    "\n",
    "from embedding_model import gnn_preprocess_target_pos_negs, compute_actual_embeddings\n",
    "def preprocess_and_compute_embeddings(\n",
    "    device,\n",
    "    model_type,\n",
    "    model,\n",
    "    batch_data,\n",
    "    featurizer, \n",
    "    featurizer_dict\n",
    "):\n",
    "    targets = []\n",
    "    positive_samples = []\n",
    "    negative_samples = []\n",
    "    pos_weights = []\n",
    "    \n",
    "    (\n",
    "        batch_targets,\n",
    "        batch_positive_samples,\n",
    "        batch_negative_samples,\n",
    "        batch_pos_weights,\n",
    "    ) = batch_data\n",
    "\n",
    "    for (\n",
    "        target_i,\n",
    "        positives_i,\n",
    "        negatives_i,\n",
    "        pos_weights_i,\n",
    "    ) in zip(\n",
    "        batch_targets,\n",
    "        batch_positive_samples,\n",
    "        batch_negative_samples,\n",
    "        batch_pos_weights,\n",
    "    ):\n",
    "        # Prepare data\n",
    "        # - Sample the negatives\n",
    "        negatives_i_sample = random.sample(\n",
    "            negatives_i, config[\"not_in_route_sample_size\"]\n",
    "        )\n",
    "        samples = {\n",
    "            \"positive_samples\": positives_i,\n",
    "            \"negative_samples\": negatives_i_sample,\n",
    "        }\n",
    "        \n",
    "        # - Featurize all\n",
    "        target_feats_i, pos_feats_i, neg_feats_i = gnn_preprocess_target_pos_negs(\n",
    "            target_i, samples, featurizer, featurizer_dict\n",
    "        )\n",
    "        \n",
    "        (\n",
    "            target_embedding,\n",
    "            positive_samples_embeddings,\n",
    "            negative_samples_embeddings,\n",
    "        ) = compute_actual_embeddings(\n",
    "            device=device,\n",
    "            model_type=model_type,\n",
    "            model=model,\n",
    "            target=target_feats_i,\n",
    "            positives=pos_feats_i,\n",
    "            negatives=neg_feats_i,\n",
    "        )\n",
    "        targets.append(target_embedding)\n",
    "        positive_samples.append(positive_samples_embeddings)\n",
    "        negative_samples.append(negative_samples_embeddings)\n",
    "\n",
    "        pos_weights.append(pos_weights_i)\n",
    "\n",
    "    # return embeddings\n",
    "    return CustomDataset(\n",
    "        targets=targets,\n",
    "        positive_samples=positive_samples,\n",
    "        negative_samples=negative_samples,\n",
    "        pos_weights=pos_weights,\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "with open(f\"config_gnn_0709_sampleInLoss.json\", \"r\") as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "experiment_name = config[\"experiment_name\"]\n",
    "checkpoint_folder = f\"GraphRuns/{experiment_name}/\"\n",
    "if not os.path.exists(checkpoint_folder):\n",
    "    os.makedirs(checkpoint_folder)\n",
    "\n",
    "checkpoint_name = \"checkpoint.pth\"\n",
    "\n",
    "# if not args.load_from_preprocessed_data:\n",
    "# Save config in output folder\n",
    "with open(f\"{checkpoint_folder}/config.json\", \"w\") as f:\n",
    "    json.dump(config, f, indent=4)\n",
    "\n",
    "# Read routes data\n",
    "input_file_routes = f'Runs/{config[\"run_id\"]}/targ_routes.pickle'\n",
    "# input_file_distances = f'Runs/{config[\"run_id\"]}/targ_to_purch_distances.pickle'\n",
    "\n",
    "# Routes data\n",
    "with open(input_file_routes, \"rb\") as handle:\n",
    "    targ_routes_dict = pickle.load(handle)\n",
    "\n",
    "# # Load distances data\n",
    "# with open(input_file_distances, 'rb') as handle:\n",
    "#     distances_dict = pickle.load(handle)\n",
    "\n",
    "# Inventory\n",
    "\n",
    "inventory = PaRoutesInventory(n=5)\n",
    "purch_smiles = [mol.smiles for mol in inventory.purchasable_mols()]\n",
    "# len(purch_smiles)\n",
    "\n",
    "# def num_heavy_atoms(mol):\n",
    "#     return Chem.rdchem.Mol.GetNumAtoms(mol, onlyExplicit=True)\n",
    "\n",
    "purch_mol_to_exclude = []\n",
    "purch_nr_heavy_atoms = {}\n",
    "for smiles in purch_smiles:\n",
    "    nr_heavy_atoms = num_heavy_atoms(Chem.MolFromSmiles(smiles))\n",
    "    if nr_heavy_atoms < 2:\n",
    "        purch_mol_to_exclude = purch_mol_to_exclude + [smiles]\n",
    "    purch_nr_heavy_atoms[smiles] = nr_heavy_atoms\n",
    "\n",
    "if config[\"run_id\"] == \"202305-2911-2320-5a95df0e-3008-4ebe-acd8-ecb3b50607c7\":\n",
    "    all_targets = get_target_smiles(n=5)\n",
    "elif config[\"run_id\"] == \"Guacamol_combined\":\n",
    "    with open(\"Data/Guacamol/guacamol_v1_test_10ksample.txt\", \"r\") as f:\n",
    "        all_targets = [line.strip() for line in f.readlines()]\n",
    "\n",
    "targ_route_not_in_route_dict = {}\n",
    "for target in all_targets:\n",
    "    targ_route_not_in_route_dict[target] = {}\n",
    "\n",
    "    target_routes_dict = targ_routes_dict.get(target, \"Target_Not_Solved\")\n",
    "\n",
    "    if target_routes_dict == \"Target_Not_Solved\":\n",
    "        purch_in_route = []\n",
    "    else:\n",
    "        target_route_df = target_routes_dict[\"route_1\"]\n",
    "        purch_in_route = list(\n",
    "            target_route_df.loc[target_route_df[\"label\"] != \"Target\", \"smiles\"]\n",
    "        )\n",
    "    #         purch_in_route = [smiles for smiles in purch_in_route if smiles in purch_smiles]\n",
    "    purch_not_in_route = [\n",
    "        purch_smile\n",
    "        for purch_smile in purch_smiles\n",
    "        if purch_smile not in purch_in_route\n",
    "    ]\n",
    "    random.seed(config[\"seed\"])\n",
    "\n",
    "    \n",
    "#     if config[\"neg_sampling\"] == \"uniform\":\n",
    "#         purch_not_in_route_sample = random.sample(\n",
    "#             purch_not_in_route, config[\"not_in_route_sample_size\"]\n",
    "#         )\n",
    "#     elif config[\"neg_sampling\"] == \"...\":\n",
    "#         pass\n",
    "#     else:\n",
    "#         raise NotImplementedError(f'{config[\"neg_sampling\"]}')\n",
    "    purch_not_in_route_sample = purch_not_in_route\n",
    "\n",
    "    # Filter out molecules with only one atom (problems with featurizer)\n",
    "    purch_in_route = [\n",
    "        smiles for smiles in purch_in_route if smiles not in purch_mol_to_exclude\n",
    "    ]\n",
    "    purch_not_in_route_sample = [\n",
    "        smiles\n",
    "        for smiles in purch_not_in_route_sample\n",
    "        if smiles not in purch_mol_to_exclude\n",
    "    ]\n",
    "\n",
    "    targ_route_not_in_route_dict[target][\"positive_samples\"] = purch_in_route\n",
    "    targ_route_not_in_route_dict[target][\n",
    "        \"negative_samples\"\n",
    "    ] = purch_not_in_route_sample\n",
    "\n",
    "# Get a random sample of keys from targ_routes_dict\n",
    "if config[\"nr_sample_targets\"] != -1:\n",
    "    sample_targets = random.sample(\n",
    "        list(targ_route_not_in_route_dict.keys()), config[\"nr_sample_targets\"]\n",
    "    )\n",
    "else:\n",
    "    sample_targets = targ_route_not_in_route_dict\n",
    "# Create targ_routes_dict_sample with the sampled keys and their corresponding values\n",
    "targ_route_not_in_route_dict_sample = {\n",
    "    target: targ_route_not_in_route_dict[target] for target in sample_targets\n",
    "}\n",
    "\n",
    "input_data = targ_route_not_in_route_dict_sample\n",
    "\n",
    "if config[\"model_type\"] == \"gnn\":\n",
    "    featurizer = dc.feat.MolGraphConvFeaturizer()\n",
    "\n",
    "    purch_mols = [Chem.MolFromSmiles(smiles) for smiles in purch_smiles]\n",
    "    purch_featurizer = featurizer.featurize(purch_mols)\n",
    "    purch_featurizer_dict = dict(zip(purch_smiles, purch_featurizer))\n",
    "    with open(f\"{checkpoint_folder}/purch_featurizer_dict.pickle\", \"wb\") as handle:\n",
    "        pickle.dump(purch_featurizer_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    fingerprint_num_atoms_dict = None\n",
    "\n",
    "    dataset = gnn_preprocess_input_v1(\n",
    "        input_data=input_data, \n",
    "#         featurizer=featurizer, \n",
    "#         featurizer_dict=purch_featurizer_dict,\n",
    "        pos_sampling=config[\"pos_sampling\"],\n",
    "    )\n",
    "\n",
    "elif config[\"model_type\"] == \"fingerprints\":\n",
    "    purch_fingerprints = list(map(fingerprint_vect_from_smiles, purch_smiles))\n",
    "    purch_fingerprints_dict = dict(zip(purch_smiles, purch_fingerprints))\n",
    "    with open(\n",
    "        f\"{checkpoint_folder}/purch_fingerprints_dict.pickle\", \"wb\"\n",
    "    ) as handle:\n",
    "        pickle.dump(\n",
    "            purch_fingerprints_dict, handle, protocol=pickle.HIGHEST_PROTOCOL\n",
    "        )\n",
    "\n",
    "    # Also save dict to retrieve number of atoms from fingerprints\n",
    "    # fingerprint_num_atoms_dict = {\n",
    "    #     torch.tensor(fp, dtype=torch.double): purch_nr_heavy_atoms[smiles]\n",
    "    #     for smiles, fp in purch_fingerprints_dict.items()\n",
    "    # }\n",
    "    # with open(\n",
    "    #     f\"{checkpoint_folder}/fingerprint_num_atoms_dict.pickle\", \"wb\"\n",
    "    # ) as handle:\n",
    "    #     pickle.dump(\n",
    "    #         fingerprint_num_atoms_dict, handle, protocol=pickle.HIGHEST_PROTOCOL\n",
    "    #     )\n",
    "\n",
    "    dataset = fingerprint_preprocess_input(\n",
    "        input_data, \n",
    "        fingerprints_dict=purch_fingerprints_dict, \n",
    "        pos_sampling=config[\"pos_sampling\"],\n",
    "    )\n",
    "\n",
    "else:\n",
    "    raise NotImplementedError(f'Model type {config[\"model_type\"]}')\n",
    "\n",
    "# if args.save_preprocessed_data:\n",
    "#     with open(f\"{checkpoint_folder}/preprocessed_targets.pickle\", \"wb\") as handle:\n",
    "#         pickle.dump(preprocessed_targets, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "#     with open(\n",
    "#         f\"{checkpoint_folder}/preprocessed_positive_samples.pickle\", \"wb\"\n",
    "#     ) as handle:\n",
    "#         pickle.dump(\n",
    "#             preprocessed_positive_samples, handle, protocol=pickle.HIGHEST_PROTOCOL\n",
    "#         )\n",
    "#     with open(\n",
    "#         f\"{checkpoint_folder}/preprocessed_negative_samples.pickle\", \"wb\"\n",
    "#     ) as handle:\n",
    "#         pickle.dump(\n",
    "#             preprocessed_negative_samples, handle, protocol=pickle.HIGHEST_PROTOCOL\n",
    "#         )\n",
    "# else:\n",
    "#     with open(f\"{checkpoint_folder}/preprocessed_targets.pickle\", \"rb\") as handle:\n",
    "#         preprocessed_targets = pickle.load(handle)\n",
    "#     with open(f\"{checkpoint_folder}/preprocessed_positive_samples.pickle\", \"rb\") as handle:\n",
    "#         preprocessed_positive_samples = pickle.load(handle)\n",
    "#     with open(f\"{checkpoint_folder}/preprocessed_negative_samples.pickle\", \"rb\") as handle:\n",
    "#         preprocessed_negative_samples = pickle.load(handle)\n",
    "#     if config[\"model_type\"] == \"fingerprints\":\n",
    "#         with open(\n",
    "#             f\"{checkpoint_folder}/fingerprint_num_atoms_dict.pickle\", \"rb\"\n",
    "#         ) as handle:\n",
    "#             fingerprint_num_atoms_dict = pickle.load(handle)\n",
    "#     else:\n",
    "#         fingerprint_num_atoms_dict = None\n",
    "\n",
    "#     dataset = CustomDataset(\n",
    "#             preprocessed_targets,\n",
    "#             preprocessed_positive_samples,\n",
    "#             preprocessed_negative_samples,\n",
    "#         )\n",
    "\n",
    "# Train validation split\n",
    "validation_ratio = config[\"validation_ratio\"]\n",
    "num_samples = len(dataset)\n",
    "num_val_samples = int(validation_ratio * num_samples)\n",
    "\n",
    "train_indices, val_indices = train_test_split(\n",
    "    range(num_samples), test_size=num_val_samples, random_state=42\n",
    ")\n",
    "\n",
    "train_dataset = Subset(dataset, train_indices)\n",
    "val_dataset = Subset(dataset, val_indices)\n",
    "\n",
    "train_data_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=config[\"train_batch_size\"],\n",
    "    shuffle=config[\"train_shuffle\"],\n",
    "    collate_fn=collate_fn,\n",
    ")\n",
    "val_data_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=config[\"val_batch_size\"],\n",
    "    shuffle=config[\"val_shuffle\"],\n",
    "    collate_fn=collate_fn,\n",
    ")\n",
    "\n",
    "# Batch size: The batch size determines the number of samples processed in each iteration during training or validation. In most cases, it is common to use the same batch size for both training and validation to maintain consistency. However, there are situations where you might choose a different batch size for validation. For instance, if memory constraints are more relaxed during validation, you can use a larger batch size to speed up evaluation.\n",
    "# Shuffle training data: Shuffling the training data before each epoch is beneficial because it helps the model see the data in different orders, reducing the risk of the model learning patterns specific to the order of the data. Shuffling the training data introduces randomness and promotes better generalization.\n",
    "# No shuffle for validation data: It is generally not necessary to shuffle the validation data because validation is meant to evaluate the model's performance on unseen data that is representative of the real-world scenarios. Shuffling the validation data could lead to inconsistent evaluation results between different validation iterations, making it harder to track the model's progress and compare performance.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8335615e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77d29957d6a248ce965a4c366c218702",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gnn Model - Epoch 1/5, TrainLoss: 3.904505304336548, ValLoss: 3.3473444059491158\n",
      "gnn Model - Epoch 2/5, TrainLoss: 3.1036663646697997, ValLoss: 3.030165858566761\n",
      "gnn Model - Epoch 3/5, TrainLoss: 2.8874917736053467, ValLoss: 2.8653238862752914\n",
      "gnn Model - Epoch 4/5, TrainLoss: 2.7190915870666506, ValLoss: 2.6334672793745995\n",
      "gnn Model - Epoch 5/5, TrainLoss: 2.6033140258789063, ValLoss: 2.571866288781166\n"
     ]
    }
   ],
   "source": [
    "# Define network dimensions\n",
    "if config[\"model_type\"] == \"gnn\":\n",
    "    gnn_input_dim = 30 # dataset.targets[0].node_features.shape[1]\n",
    "    gnn_hidden_dim = config[\"hidden_dim\"]\n",
    "    gnn_output_dim = config[\"output_dim\"]\n",
    "\n",
    "    with open(f\"{checkpoint_folder}/input_dim.pickle\", \"wb\") as f:\n",
    "        pickle.dump({\"input_dim\": gnn_input_dim}, f)\n",
    "\n",
    "elif config[\"model_type\"] == \"fingerprints\":\n",
    "    #     fingerprint_input_dim = preprocessed_targets[0].GetNumBits()\n",
    "    fingerprint_input_dim = dataset.targets[0].size()[\n",
    "        0\n",
    "    ]  # len(preprocessed_targets[0].node_features)\n",
    "    fingerprint_hidden_dim = config[\"hidden_dim\"]\n",
    "    fingerprint_output_dim = config[\"output_dim\"]\n",
    "\n",
    "    with open(f\"{checkpoint_folder}/input_dim.pickle\", \"wb\") as f:\n",
    "        pickle.dump({\"input_dim\": fingerprint_input_dim}, f)\n",
    "\n",
    "else:\n",
    "    raise NotImplementedError(f'Model type {config[\"model_type\"]}')\n",
    "\n",
    "# Step 3: Set up the training loop for the GNN model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "if config[\"model_type\"] == \"gnn\":\n",
    "    model = GNNModel(\n",
    "        input_dim=gnn_input_dim,\n",
    "        hidden_dim=gnn_hidden_dim,\n",
    "        output_dim=gnn_output_dim,\n",
    "    ).to(device)\n",
    "    model.double()\n",
    "\n",
    "elif config[\"model_type\"] == \"fingerprints\":\n",
    "    model = FingerprintModel(\n",
    "        input_dim=fingerprint_input_dim,\n",
    "        hidden_dim=fingerprint_hidden_dim,\n",
    "        output_dim=fingerprint_output_dim,\n",
    "    ).to(device)\n",
    "else:\n",
    "    raise NotImplementedError(f'Model type {config[\"model_type\"]}')\n",
    "\n",
    "loss_fn = NTXentLoss(temperature=config[\"temperature\"], device=device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=config[\"lr\"])\n",
    "\n",
    "num_epochs = config[\"num_epochs\"]\n",
    "\n",
    "load_from_checkpoint = False\n",
    "# input_checkpoint_folder  = 'GraphRuns/gnn_0629'\n",
    "# input_checkpoint_path = f'{checkpoint_folder}/epoch_71_checkpoint.pth'\n",
    "\n",
    "# STEP 5: Train loop\n",
    "# Check if a checkpoint exists and load the model state and optimizer state if available\n",
    "if load_from_checkpoint:\n",
    "    checkpoint = torch.load(input_checkpoint_path)\n",
    "    model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "    optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "    start_epoch = checkpoint[\"epoch\"] + 1\n",
    "\n",
    "    epoch_loss = pd.read_csv(f'{input_checkpoint_folder}/train_val_loss.csv')\n",
    "    best_val_loss = epoch_loss[\"ValLoss\"].min()\n",
    "    with open(f'{input_checkpoint_folder}/model_min_val.pkl', \"rb\") as handle:\n",
    "        best_model = pickle.load(handle)\n",
    "else:\n",
    "    start_epoch = 0\n",
    "    best_val_loss = float(\"inf\")\n",
    "    best_model = None\n",
    "    epoch_loss = pd.DataFrame(columns=[\"Epoch\", \"TrainLoss\", \"ValLoss\"])\n",
    "\n",
    "# Create a SummaryWriter for TensorBoard logging\n",
    "log_dir = (\n",
    "    f\"{checkpoint_folder}/logs\"  # Specify the directory to store TensorBoard logs\n",
    ")\n",
    "writer = SummaryWriter(log_dir)\n",
    "\n",
    "# best_val_loss = float(\"inf\")\n",
    "# best_model = None\n",
    "\n",
    "# epoch_loss = pd.DataFrame(columns=[\"Epoch\", \"TrainLoss\", \"ValLoss\"])\n",
    "for epoch in tqdm(range(start_epoch, num_epochs)):\n",
    "    # TRAIN\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_batches = 0\n",
    "\n",
    "    for batch_idx, batch_data in enumerate(train_data_loader):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "\n",
    "        # Compute embeddings\n",
    "        embeddings_dataset = preprocess_and_compute_embeddings(\n",
    "            device=device,\n",
    "            model_type=config['model_type'],\n",
    "            model=model,\n",
    "            batch_data=batch_data,\n",
    "            featurizer=featurizer, \n",
    "            featurizer_dict=purch_featurizer_dict,\n",
    "        )\n",
    "        # Compute loss\n",
    "        loss = loss_fn(embeddings_dataset)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Track total loss\n",
    "        train_loss += loss.item()\n",
    "        train_batches += 1\n",
    "\n",
    "    # VALIDATION\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    val_loss = 0.0\n",
    "    val_batches = 0\n",
    "    with torch.no_grad():  # Disable gradient calculation during validation\n",
    "        for val_batch_idx, val_batch_data in enumerate(val_data_loader):\n",
    "            # Compute embeddings\n",
    "            val_embeddings = preprocess_and_compute_embeddings(\n",
    "                device=device,\n",
    "                model_type=config['model_type'],\n",
    "                model=model,\n",
    "                batch_data=val_batch_data,\n",
    "                featurizer=featurizer, \n",
    "                featurizer_dict=purch_featurizer_dict,\n",
    "            )\n",
    "            # Compute loss\n",
    "            val_batch_loss = loss_fn(val_embeddings)\n",
    "\n",
    "            val_loss += val_batch_loss.item()\n",
    "            val_batches += 1\n",
    "\n",
    "    # METRICS\n",
    "    # - TRAIN\n",
    "    # Compute average loss for the epoch\n",
    "    average_train_loss = train_loss / train_batches\n",
    "\n",
    "    # Log the loss to TensorBoard\n",
    "    writer.add_scalar(\"Loss/train\", average_train_loss, epoch + 1)\n",
    "\n",
    "    # - VALIDATION\n",
    "    average_val_loss = val_loss / val_batches\n",
    "\n",
    "    # Log the loss to TensorBoard\n",
    "    writer.add_scalar(\"Loss/val\", average_val_loss, epoch + 1)\n",
    "\n",
    "    new_row = pd.DataFrame(\n",
    "        {\n",
    "            \"Epoch\": [epoch],\n",
    "            \"TrainLoss\": [average_train_loss],\n",
    "            \"ValLoss\": [average_val_loss],\n",
    "        }\n",
    "    )\n",
    "    epoch_loss = pd.concat([epoch_loss, new_row], axis=0)\n",
    "\n",
    "    if average_val_loss < best_val_loss:\n",
    "        best_val_loss = average_val_loss\n",
    "        best_model = model\n",
    "\n",
    "    if (epoch % 1 == 0) | (epoch == num_epochs - 1):\n",
    "        print(\n",
    "            f\"{config['model_type']} Model - Epoch {epoch+1}/{num_epochs}, TrainLoss: {average_train_loss}, ValLoss: {average_val_loss}\"\n",
    "        )\n",
    "\n",
    "        # Save the model and optimizer state as a checkpoint\n",
    "        checkpoint = {\n",
    "            \"epoch\": epoch,\n",
    "            \"model_state_dict\": model.state_dict(),\n",
    "            \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "        }\n",
    "        checkpoint_path = f\"{checkpoint_folder}/epoch_{epoch+1}_{checkpoint_name}\"  # Specify the checkpoint file path\n",
    "        torch.save(checkpoint, checkpoint_path)\n",
    "\n",
    "        #         loss_df = pd.DataFrame({'Epoch': range(len(epoch_loss)), 'TrainLoss': epoch_loss})\n",
    "        epoch_loss.to_csv(f\"{checkpoint_folder}/train_val_loss.csv\", index=False)\n",
    "\n",
    "        # Save the best model as a pickle\n",
    "        best_model_path = (\n",
    "            f\"{checkpoint_folder}/model_min_val.pkl\"  #'path/to/best_model.pkl'\n",
    "        )\n",
    "\n",
    "        with open(best_model_path, \"wb\") as f:\n",
    "            pickle.dump(best_model, f)\n",
    "\n",
    "\n",
    "\n",
    "# Close the SummaryWriter\n",
    "writer.close()\n",
    "\n",
    "\n",
    "\n",
    "# STEP 6: Plot\n",
    "\n",
    "# fig = px.line(x=epoch_loss['Epoch'], y=epoch_loss['TrainLoss'], title=\"Train loss\")\n",
    "# fig.update_layout(width=1000, height=600, showlegend=False)\n",
    "# fig.write_image(f\"{checkpoint_folder}/Train_loss.pdf\")\n",
    "# fig.show()\n",
    "\n",
    "# Create a new figure with two lines    \n",
    "fig = px.line()\n",
    "\n",
    "# Add the TrainLoss line to the figure\n",
    "fig.add_scatter(x=epoch_loss[\"Epoch\"], y=epoch_loss[\"TrainLoss\"], name=\"Train Loss\")\n",
    "\n",
    "# Add the ValLoss line to the figure\n",
    "fig.add_scatter(\n",
    "    x=epoch_loss[\"Epoch\"], y=epoch_loss[\"ValLoss\"], name=\"Validation Loss\"\n",
    ")\n",
    "\n",
    "# Set the title of the figure\n",
    "fig.update_layout(title=\"Train and Validation Loss\")\n",
    "\n",
    "# Set the layout size and show the legend\n",
    "fig.update_layout(width=1000, height=600, showlegend=True)\n",
    "\n",
    "# Save the figure as a PDF file\n",
    "fig.write_image(f\"{checkpoint_folder}/Train_and_Val_loss.pdf\")\n",
    "time.sleep(10)\n",
    "fig.write_image(f\"{checkpoint_folder}/Train_and_Val_loss.pdf\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5790c89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c674e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss_post = 0.0\n",
    "val_batches_post = 0\n",
    "with torch.no_grad():  # Disable gradient calculation during validation\n",
    "    for val_batch_idx, val_batch_data in tqdm(enumerate(val_data_loader)):\n",
    "        # Compute embeddings\n",
    "        val_embeddings_post = compute_embeddings(\n",
    "            device=device,\n",
    "            model_type=config['model_type'],\n",
    "            model=model,\n",
    "            batch_data=val_batch_data,\n",
    "        )\n",
    "        # Compute loss\n",
    "        val_batch_loss_post = loss_fn(val_embeddings_post)\n",
    "\n",
    "        val_loss_post += val_batch_loss_post.item()\n",
    "        val_batches_post += 1\n",
    "\n",
    "    # Compute average loss\n",
    "    average_val_loss_post = val_loss_post / val_batches_post\n",
    "\n",
    "print(\"Validation loss: \", average_val_loss_post)\n",
    "\n",
    "# Should be the same\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f776d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL TO EVALUATE\n",
    "experiment_name = config[\"experiment_name\"]  # gnn_0627\n",
    "checkpoint_folder = f\"GraphRuns/{experiment_name}/\"\n",
    "input_checkpoint_name = f\"epoch_5_checkpoint.pth\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344a4a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0. LOAD MODEL \n",
    "# Option 1: FROM CHECKPOINT\n",
    "input_checkpoint_folder  = f'GraphRuns/{experiment_name}'\n",
    "input_checkpoint_path = f'{input_checkpoint_folder}/{input_checkpoint_name}'\n",
    "\n",
    "\n",
    "with open(f'{checkpoint_folder}/input_dim.pickle', \"rb\") as f:\n",
    "    input_dim = pickle.load(f)['input_dim']\n",
    "\n",
    "# Define network dimensions\n",
    "if config[\"model_type\"] == \"gnn\":\n",
    "    gnn_input_dim = input_dim\n",
    "    gnn_hidden_dim = config[\"hidden_dim\"]\n",
    "    gnn_output_dim = config[\"output_dim\"]\n",
    "\n",
    "elif config[\"model_type\"] == \"fingerprints\":\n",
    "    #     fingerprint_input_dim = preprocessed_targets[0].GetNumBits()\n",
    "    fingerprint_input_dim = input_dim\n",
    "    fingerprint_hidden_dim = config[\"hidden_dim\"]\n",
    "    fingerprint_output_dim = config[\"output_dim\"]\n",
    "\n",
    "else:\n",
    "    raise NotImplementedError(f'Model type {config[\"model_type\"]}')\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "if config[\"model_type\"] == \"gnn\":\n",
    "    model_loaded = GNNModel(\n",
    "        input_dim=gnn_input_dim,\n",
    "        hidden_dim=gnn_hidden_dim,\n",
    "        output_dim=gnn_output_dim,\n",
    "    ).to(device)\n",
    "    model_loaded.double()\n",
    "\n",
    "elif config[\"model_type\"] == \"fingerprints\":\n",
    "    model_loaded = FingerprintModel(\n",
    "        input_dim=fingerprint_input_dim,\n",
    "        hidden_dim=fingerprint_hidden_dim,\n",
    "        output_dim=fingerprint_output_dim,\n",
    "    ).to(device)\n",
    "else:\n",
    "    raise NotImplementedError(f'Model type {config[\"model_type\"]}')\n",
    "\n",
    "loss_fn_loaded = NTXentLoss(temperature=config[\"temperature\"], device=device)\n",
    "\n",
    "checkpoint = torch.load(input_checkpoint_path)\n",
    "model_loaded.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "\n",
    "# # # OPTION 2: From pickle\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# loss_fn = NTXentLoss(temperature=config[\"temperature\"], device=device)\n",
    "# with open(f'{checkpoint_folder}/model_min_val.pkl', \"rb\") as f:\n",
    "#     model = pickle.load(f)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a967d7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss1 = 0.0\n",
    "val_batches1 = 0\n",
    "with torch.no_grad():  # Disable gradient calculation during validation\n",
    "    for val_batch_idx, val_batch_data in tqdm(enumerate(val_data_loader)):\n",
    "        # Compute embeddings\n",
    "        val_embeddings1_loaded = compute_embeddings(\n",
    "            device=device,\n",
    "            model_type=config['model_type'],\n",
    "            model=model_loaded,\n",
    "            batch_data=val_batch_data,\n",
    "        )\n",
    "        # Compute loss\n",
    "        val_batch_loss1 = loss_fn_loaded(val_embeddings1_loaded)\n",
    "\n",
    "        val_loss1 += val_batch_loss1.item()\n",
    "        val_batches1 += 1\n",
    "\n",
    "    # Compute average loss\n",
    "    average_val_loss1 = val_loss1 / val_batches1\n",
    "\n",
    "print(\"Validation loss: \", average_val_loss1)\n",
    "\n",
    "# If it is not the same, there is an issue in the save\n",
    "# If it is the same, there is an issue in the preprocessing \n",
    "# --> Try applying model and model_loaded (on the new preprocessed data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d448bfa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. PREPROCESS DATA AGAIN (Only gnn_preprocess_input)\n",
    "input_data_1 = input_data.copy()\n",
    "\n",
    "if config[\"model_type\"] == \"gnn\":\n",
    "    featurizer_1 = dc.feat.MolGraphConvFeaturizer()\n",
    "\n",
    "    purch_mols_1 = [Chem.MolFromSmiles(smiles) for smiles in purch_smiles]\n",
    "    purch_featurizer_1 = featurizer.featurize(purch_mols_1)\n",
    "    purch_featurizer_dict_1 = dict(zip(purch_smiles, purch_featurizer_1))\n",
    "\n",
    "    dataset_1 = gnn_preprocess_input(\n",
    "        input_data=input_data_1, \n",
    "        featurizer=featurizer_1, \n",
    "        featurizer_dict=purch_featurizer_dict_1,\n",
    "        pos_sampling=config[\"pos_sampling\"],\n",
    "    )\n",
    "\n",
    "# elif config[\"model_type\"] == \"fingerprints\":\n",
    "#     purch_fingerprints = list(map(fingerprint_vect_from_smiles, purch_smiles))\n",
    "#     purch_fingerprints_dict = dict(zip(purch_smiles, purch_fingerprints))\n",
    "\n",
    "\n",
    "#     dataset = fingerprint_preprocess_input(\n",
    "#         input_data, \n",
    "#         fingerprints_dict=purch_fingerprints_dict, \n",
    "#         pos_sampling=config[\"pos_sampling\"],\n",
    "#     )\n",
    "\n",
    "else:\n",
    "    raise NotImplementedError(f'Model type {config[\"model_type\"]}')\n",
    "\n",
    "\n",
    "# 2. TRAIN VALIDATION SPLIT\n",
    "validation_ratio = config[\"validation_ratio\"]\n",
    "num_samples_1 = len(dataset_1)\n",
    "num_val_samples_1 = int(validation_ratio * num_samples_1)\n",
    "\n",
    "train_indices_1, val_indices_1 = train_test_split(\n",
    "    range(num_samples_1), test_size=num_val_samples_1, random_state=42\n",
    ")\n",
    "\n",
    "train_dataset_1 = Subset(dataset_1, train_indices_1)\n",
    "val_dataset_1 = Subset(dataset_1, val_indices_1)\n",
    "\n",
    "train_data_loader_1 = DataLoader(\n",
    "    train_dataset_1,\n",
    "    batch_size=config[\"train_batch_size\"],\n",
    "    shuffle=config[\"train_shuffle\"],\n",
    "    collate_fn=collate_fn,\n",
    ")\n",
    "val_data_loader_1 = DataLoader(\n",
    "    val_dataset_1,\n",
    "    batch_size=config[\"val_batch_size\"],\n",
    "    shuffle=config[\"val_shuffle\"],\n",
    "    collate_fn=collate_fn,\n",
    ")\n",
    "\n",
    "# Batch size: The batch size determines the number of samples processed in each iteration during training or validation. In most cases, it is common to use the same batch size for both training and validation to maintain consistency. However, there are situations where you might choose a different batch size for validation. For instance, if memory constraints are more relaxed during validation, you can use a larger batch size to speed up evaluation.\n",
    "# Shuffle training data: Shuffling the training data before each epoch is beneficial because it helps the model see the data in different orders, reducing the risk of the model learning patterns specific to the order of the data. Shuffling the training data introduces randomness and promotes better generalization.\n",
    "# No shuffle for validation data: It is generally not necessary to shuffle the validation data because validation is meant to evaluate the model's performance on unseen data that is representative of the real-world scenarios. Shuffling the validation data could lead to inconsistent evaluation results between different validation iterations, making it harder to track the model's progress and compare performance.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb795a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss_new_preprocess = 0.0\n",
    "val_batches_new_preprocess = 0\n",
    "with torch.no_grad():  # Disable gradient calculation during validation\n",
    "    for val_batch_idx, val_batch_data in tqdm(enumerate(val_data_loader_1)):\n",
    "        # Compute embeddings\n",
    "        val_embeddings_new_preprocess = compute_embeddings(\n",
    "            device=device,\n",
    "            model_type=config['model_type'],\n",
    "            model=model,\n",
    "            batch_data=val_batch_data,\n",
    "        )\n",
    "        # Compute loss\n",
    "        val_batch_loss_new_preprocess = loss_fn_loaded(val_embeddings_new_preprocess)\n",
    "\n",
    "        val_loss_new_preprocess += val_batch_loss_new_preprocess.item()\n",
    "        val_batches_new_preprocess += 1\n",
    "\n",
    "    # Compute average loss\n",
    "    average_val_loss_new_preprocess = val_loss_new_preprocess / val_batches_new_preprocess\n",
    "\n",
    "print(\"Validation loss: \", average_val_loss_new_preprocess)\n",
    "\n",
    "# If it is not the same, there is an issue in the save\n",
    "# If it is the same, there is an issue in the preprocessing \n",
    "# --> Try applying model and model_loaded (on the new preprocessed data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e7a027",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e4b81b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a4b74c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No normalization for AvgIpc. Feature removed!\n",
      "Skipped loading modules with pytorch-geometric dependency, missing a dependency. No module named 'dgl'\n",
      "Skipped loading modules with transformers dependency. No module named 'transformers'\n",
      "cannot import name 'HuggingFaceModel' from 'deepchem.models.torch_models' (/Users/ilariasartori/miniforge3/envs/syntheseus_temp/lib/python3.10/site-packages/deepchem/models/torch_models/__init__.py)\n",
      "Skipped loading modules with pytorch-lightning dependency, missing a dependency. No module named 'pytorch_lightning'\n",
      "Skipped loading some Jax models, missing a dependency. jax requires jaxlib to be installed. See https://github.com/google/jax#installation for installation instructions.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Script to train neural network to get molecules embeddings\n",
    "\"\"\"\n",
    "from __future__ import annotations\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import pickle\n",
    "import json\n",
    "import random\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from paroutes import PaRoutesInventory, get_target_smiles\n",
    "from embedding_model import (\n",
    "    fingerprint_preprocess_input,\n",
    "    gnn_preprocess_input,\n",
    "    CustomDataset,\n",
    "    collate_fn,\n",
    "    # SampleData,\n",
    "    fingerprint_vect_from_smiles,\n",
    "    compute_embeddings,\n",
    "    GNNModel,\n",
    "    FingerprintModel,\n",
    "    NTXentLoss,\n",
    "    num_heavy_atoms\n",
    ")\n",
    "from paroutes import PaRoutesInventory\n",
    "from torch.utils.data import Subset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import plotly.express as px\n",
    "from rdkit import Chem\n",
    "import deepchem as dc\n",
    "\n",
    "\n",
    "    \n",
    "with open(f\"config_gnn_0627.json\", \"r\") as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "\n",
    "\n",
    "# MODEL TO EVALUATE\n",
    "experiment_name = config[\"experiment_name\"]  # gnn_0629\n",
    "checkpoint_folder = f\"GraphRuns/{experiment_name}/\"\n",
    "input_checkpoint_name = f\"epoch_5_checkpoint.pth\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8f1d5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7075e5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to featurize datapoint 146, N. Appending empty array\n",
      "Exception message: More than one atom should be present in the molecule for this featurizer to work.\n",
      "Failed to featurize datapoint 703, S. Appending empty array\n",
      "Exception message: More than one atom should be present in the molecule for this featurizer to work.\n",
      "Failed to featurize datapoint 1055, Br. Appending empty array\n",
      "Exception message: More than one atom should be present in the molecule for this featurizer to work.\n",
      "Failed to featurize datapoint 1126, I. Appending empty array\n",
      "Exception message: More than one atom should be present in the molecule for this featurizer to work.\n",
      "Failed to featurize datapoint 3401, O. Appending empty array\n",
      "Exception message: More than one atom should be present in the molecule for this featurizer to work.\n",
      "Failed to featurize datapoint 4103, F. Appending empty array\n",
      "Exception message: More than one atom should be present in the molecule for this featurizer to work.\n",
      "Failed to featurize datapoint 6768, Cl. Appending empty array\n",
      "Exception message: More than one atom should be present in the molecule for this featurizer to work.\n",
      "Failed to featurize datapoint 8073, [Mg]. Appending empty array\n",
      "Exception message: More than one atom should be present in the molecule for this featurizer to work.\n",
      "Failed to featurize datapoint 9942, [S-2]. Appending empty array\n",
      "Exception message: More than one atom should be present in the molecule for this featurizer to work.\n",
      "/Users/ilariasartori/miniforge3/envs/syntheseus_temp/lib/python3.10/site-packages/deepchem/feat/base_classes.py:322: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return np.asarray(features)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f90c4cce16504570bfdece56a7fac9c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1. PREPROCESS DATA AGAIN\n",
    "# if not args.load_from_preprocessed_data:\n",
    "\n",
    "# Read routes data\n",
    "input_file_routes = f'Runs/{config[\"run_id\"]}/targ_routes.pickle'\n",
    "# input_file_distances = f'Runs/{config[\"run_id\"]}/targ_to_purch_distances.pickle'\n",
    "\n",
    "# Routes data\n",
    "with open(input_file_routes, \"rb\") as handle:\n",
    "    targ_routes_dict = pickle.load(handle)\n",
    "\n",
    "# # Load distances data\n",
    "# with open(input_file_distances, 'rb') as handle:\n",
    "#     distances_dict = pickle.load(handle)\n",
    "\n",
    "# Inventory\n",
    "\n",
    "inventory = PaRoutesInventory(n=5)\n",
    "purch_smiles = [mol.smiles for mol in inventory.purchasable_mols()]\n",
    "# len(purch_smiles)\n",
    "\n",
    "# def num_heavy_atoms(mol):\n",
    "#     return Chem.rdchem.Mol.GetNumAtoms(mol, onlyExplicit=True)\n",
    "\n",
    "purch_mol_to_exclude = []\n",
    "purch_nr_heavy_atoms = {}\n",
    "for smiles in purch_smiles:\n",
    "    nr_heavy_atoms = num_heavy_atoms(Chem.MolFromSmiles(smiles))\n",
    "    if nr_heavy_atoms < 2:\n",
    "        purch_mol_to_exclude = purch_mol_to_exclude + [smiles]\n",
    "    purch_nr_heavy_atoms[smiles] = nr_heavy_atoms\n",
    "\n",
    "if config[\"run_id\"] == \"202305-2911-2320-5a95df0e-3008-4ebe-acd8-ecb3b50607c7\":\n",
    "    all_targets = get_target_smiles(n=5)\n",
    "elif config[\"run_id\"] == \"Guacamol_combined\":\n",
    "    with open(\"Data/Guacamol/guacamol_v1_test_10ksample.txt\", \"r\") as f:\n",
    "        all_targets = [line.strip() for line in f.readlines()]\n",
    "\n",
    "targ_route_not_in_route_dict = {}\n",
    "for target in all_targets:\n",
    "    targ_route_not_in_route_dict[target] = {}\n",
    "\n",
    "    target_routes_dict = targ_routes_dict.get(target, \"Target_Not_Solved\")\n",
    "\n",
    "    if target_routes_dict == \"Target_Not_Solved\":\n",
    "        purch_in_route = []\n",
    "    else:\n",
    "        target_route_df = target_routes_dict[\"route_1\"]\n",
    "        purch_in_route = list(\n",
    "            target_route_df.loc[target_route_df[\"label\"] != \"Target\", \"smiles\"]\n",
    "        )\n",
    "    #         purch_in_route = [smiles for smiles in purch_in_route if smiles in purch_smiles]\n",
    "    purch_not_in_route = [\n",
    "        purch_smile\n",
    "        for purch_smile in purch_smiles\n",
    "        if purch_smile not in purch_in_route\n",
    "    ]\n",
    "    random.seed(config[\"seed\"])\n",
    "\n",
    "    if config[\"neg_sampling\"] == \"uniform\":\n",
    "        purch_not_in_route_sample = random.sample(\n",
    "            purch_not_in_route, config[\"not_in_route_sample_size\"]\n",
    "        )\n",
    "    elif config[\"neg_sampling\"] == \"...\":\n",
    "        pass\n",
    "    else:\n",
    "        raise NotImplementedError(f'{config[\"neg_sampling\"]}')\n",
    "\n",
    "    # Filter out molecules with only one atom (problems with featurizer)\n",
    "    purch_in_route = [\n",
    "        smiles for smiles in purch_in_route if smiles not in purch_mol_to_exclude\n",
    "    ]\n",
    "    purch_not_in_route_sample = [\n",
    "        smiles\n",
    "        for smiles in purch_not_in_route_sample\n",
    "        if smiles not in purch_mol_to_exclude\n",
    "    ]\n",
    "\n",
    "    targ_route_not_in_route_dict[target][\"positive_samples\"] = purch_in_route\n",
    "    targ_route_not_in_route_dict[target][\n",
    "        \"negative_samples\"\n",
    "    ] = purch_not_in_route_sample\n",
    "\n",
    "# Get a random sample of keys from targ_routes_dict\n",
    "if config[\"nr_sample_targets\"] != -1:\n",
    "    sample_targets = random.sample(\n",
    "        list(targ_route_not_in_route_dict.keys()), config[\"nr_sample_targets\"]\n",
    "    )\n",
    "else:\n",
    "    sample_targets = targ_route_not_in_route_dict\n",
    "# Create targ_routes_dict_sample with the sampled keys and their corresponding values\n",
    "targ_route_not_in_route_dict_sample = {\n",
    "    target: targ_route_not_in_route_dict[target] for target in sample_targets\n",
    "}\n",
    "\n",
    "input_data = targ_route_not_in_route_dict_sample\n",
    "\n",
    "if config[\"model_type\"] == \"gnn\":\n",
    "    featurizer = dc.feat.MolGraphConvFeaturizer()\n",
    "\n",
    "    purch_mols = [Chem.MolFromSmiles(smiles) for smiles in purch_smiles]\n",
    "    purch_featurizer = featurizer.featurize(purch_mols)\n",
    "    purch_featurizer_dict = dict(zip(purch_smiles, purch_featurizer))\n",
    "\n",
    "    dataset = gnn_preprocess_input(\n",
    "        input_data=input_data, \n",
    "        featurizer=featurizer, \n",
    "        featurizer_dict=purch_featurizer_dict,\n",
    "        pos_sampling=config[\"pos_sampling\"],\n",
    "    )\n",
    "\n",
    "elif config[\"model_type\"] == \"fingerprints\":\n",
    "    purch_fingerprints = list(map(fingerprint_vect_from_smiles, purch_smiles))\n",
    "    purch_fingerprints_dict = dict(zip(purch_smiles, purch_fingerprints))\n",
    "\n",
    "\n",
    "    dataset = fingerprint_preprocess_input(\n",
    "        input_data, \n",
    "        fingerprints_dict=purch_fingerprints_dict, \n",
    "        pos_sampling=config[\"pos_sampling\"],\n",
    "    )\n",
    "\n",
    "else:\n",
    "    raise NotImplementedError(f'Model type {config[\"model_type\"]}')\n",
    "\n",
    "\n",
    "# 2. TRAIN VALIDATION SPLIT\n",
    "validation_ratio = config[\"validation_ratio\"]\n",
    "num_samples = len(dataset)\n",
    "num_val_samples = int(validation_ratio * num_samples)\n",
    "\n",
    "train_indices, val_indices = train_test_split(\n",
    "    range(num_samples), test_size=num_val_samples, random_state=42\n",
    ")\n",
    "\n",
    "train_dataset = Subset(dataset, train_indices)\n",
    "val_dataset = Subset(dataset, val_indices)\n",
    "\n",
    "train_data_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=config[\"train_batch_size\"],\n",
    "    shuffle=config[\"train_shuffle\"],\n",
    "    collate_fn=collate_fn,\n",
    ")\n",
    "val_data_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=config[\"val_batch_size\"],\n",
    "    shuffle=config[\"val_shuffle\"],\n",
    "    collate_fn=collate_fn,\n",
    ")\n",
    "\n",
    "# Batch size: The batch size determines the number of samples processed in each iteration during training or validation. In most cases, it is common to use the same batch size for both training and validation to maintain consistency. However, there are situations where you might choose a different batch size for validation. For instance, if memory constraints are more relaxed during validation, you can use a larger batch size to speed up evaluation.\n",
    "# Shuffle training data: Shuffling the training data before each epoch is beneficial because it helps the model see the data in different orders, reducing the risk of the model learning patterns specific to the order of the data. Shuffling the training data introduces randomness and promotes better generalization.\n",
    "# No shuffle for validation data: It is generally not necessary to shuffle the validation data because validation is meant to evaluate the model's performance on unseen data that is representative of the real-world scenarios. Shuffling the validation data could lead to inconsistent evaluation results between different validation iterations, making it harder to track the model's progress and compare performance.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83f782d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0. LOAD MODEL \n",
    "# Option 1: FROM CHECKPOINT\n",
    "input_checkpoint_folder  = f'GraphRuns/{experiment_name}'\n",
    "input_checkpoint_path = f'{input_checkpoint_folder}/{input_checkpoint_name}'\n",
    "\n",
    "\n",
    "with open(f'{checkpoint_folder}/input_dim.pickle', \"rb\") as f:\n",
    "    input_dim = pickle.load(f)['input_dim']\n",
    "\n",
    "# Define network dimensions\n",
    "if config[\"model_type\"] == \"gnn\":\n",
    "    gnn_input_dim = input_dim\n",
    "    gnn_hidden_dim = config[\"hidden_dim\"]\n",
    "    gnn_output_dim = config[\"output_dim\"]\n",
    "\n",
    "elif config[\"model_type\"] == \"fingerprints\":\n",
    "    #     fingerprint_input_dim = preprocessed_targets[0].GetNumBits()\n",
    "    fingerprint_input_dim = input_dim\n",
    "    fingerprint_hidden_dim = config[\"hidden_dim\"]\n",
    "    fingerprint_output_dim = config[\"output_dim\"]\n",
    "\n",
    "else:\n",
    "    raise NotImplementedError(f'Model type {config[\"model_type\"]}')\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "if config[\"model_type\"] == \"gnn\":\n",
    "    model = GNNModel(\n",
    "        input_dim=gnn_input_dim,\n",
    "        hidden_dim=gnn_hidden_dim,\n",
    "        output_dim=gnn_output_dim,\n",
    "    ).to(device)\n",
    "    model.double()\n",
    "\n",
    "elif config[\"model_type\"] == \"fingerprints\":\n",
    "    model = FingerprintModel(\n",
    "        input_dim=fingerprint_input_dim,\n",
    "        hidden_dim=fingerprint_hidden_dim,\n",
    "        output_dim=fingerprint_output_dim,\n",
    "    ).to(device)\n",
    "else:\n",
    "    raise NotImplementedError(f'Model type {config[\"model_type\"]}')\n",
    "\n",
    "loss_fn = NTXentLoss(temperature=config[\"temperature\"], device=device)\n",
    "\n",
    "checkpoint = torch.load(input_checkpoint_path)\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "\n",
    "# # # OPTION 2: From pickle\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# loss_fn = NTXentLoss(temperature=config[\"temperature\"], device=device)\n",
    "# with open(f'{checkpoint_folder}/model_min_val.pkl', \"rb\") as f:\n",
    "#     model = pickle.load(f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aee4165b",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint1 = torch.load(input_checkpoint_path)\n",
    "checkpoint2 = torch.load(input_checkpoint_path)\n",
    "\n",
    "aa = checkpoint1[\"model_state_dict\"]\n",
    "bb = checkpoint1[\"model_state_dict\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e91edbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['conv1.bias', 'conv1.lin.weight', 'conv2.bias', 'conv2.lin.weight', 'fc.weight', 'fc.bias'])\n"
     ]
    }
   ],
   "source": [
    "print(aa.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ace34348",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0182,  0.0882,  0.0097,  ..., -0.0630,  0.0137, -0.0142],\n",
       "        [-0.0137, -0.0323,  0.0690,  ...,  0.0586, -0.0718,  0.0425],\n",
       "        [-0.0948, -0.0169, -0.2129,  ..., -0.0453,  0.0261,  0.0008],\n",
       "        ...,\n",
       "        [ 0.0455,  0.0312,  0.0367,  ...,  0.1213,  0.0331, -0.1026],\n",
       "        [ 0.0481,  0.1346,  0.0286,  ..., -0.0846,  0.0547, -0.0316],\n",
       "        [ 0.0465, -0.1177,  0.0113,  ...,  0.0605,  0.0737,  0.0774]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa[\"conv1.lin.weight\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7303cd1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0182,  0.0882,  0.0097,  ..., -0.0630,  0.0137, -0.0142],\n",
       "        [-0.0137, -0.0323,  0.0690,  ...,  0.0586, -0.0718,  0.0425],\n",
       "        [-0.0948, -0.0169, -0.2129,  ..., -0.0453,  0.0261,  0.0008],\n",
       "        ...,\n",
       "        [ 0.0455,  0.0312,  0.0367,  ...,  0.1213,  0.0331, -0.1026],\n",
       "        [ 0.0481,  0.1346,  0.0286,  ..., -0.0846,  0.0547, -0.0316],\n",
       "        [ 0.0465, -0.1177,  0.0113,  ...,  0.0605,  0.0737,  0.0774]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bb[\"conv1.lin.weight\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8cd720b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1 = GNNModel(\n",
    "    input_dim=gnn_input_dim,\n",
    "    hidden_dim=gnn_hidden_dim,\n",
    "    output_dim=gnn_output_dim,\n",
    ").to(device)\n",
    "model1.double()\n",
    "\n",
    "model2 = GNNModel(\n",
    "    input_dim=gnn_input_dim,\n",
    "    hidden_dim=gnn_hidden_dim,\n",
    "    output_dim=gnn_output_dim,\n",
    ").to(device)\n",
    "model2.double()\n",
    "\n",
    "model1.load_state_dict(aa)\n",
    "model2.load_state_dict(bb)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "258a9227",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ffcacb5cebc457d8c23daa7b59480d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss:  3.619757167994976\n"
     ]
    }
   ],
   "source": [
    "val_loss1 = 0.0\n",
    "val_batches1 = 0\n",
    "with torch.no_grad():  # Disable gradient calculation during validation\n",
    "    for val_batch_idx, val_batch_data in tqdm(enumerate(val_data_loader)):\n",
    "        # Compute embeddings\n",
    "        val_embeddings1 = compute_embeddings(\n",
    "            device=device,\n",
    "            model_type=config['model_type'],\n",
    "            model=model1,\n",
    "            batch_data=val_batch_data,\n",
    "        )\n",
    "        # Compute loss\n",
    "        val_batch_loss1 = loss_fn(val_embeddings1)\n",
    "\n",
    "        val_loss1 += val_batch_loss1.item()\n",
    "        val_batches1 += 1\n",
    "\n",
    "    # Compute average loss\n",
    "    average_val_loss1 = val_loss1 / val_batches1\n",
    "\n",
    "print(\"Validation loss: \", average_val_loss1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a34f327c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e08c708cfd44e9fa34c61ef0129dac5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss:  3.585004560649395\n"
     ]
    }
   ],
   "source": [
    "val_loss2 = 0.0\n",
    "val_batches2 = 0\n",
    "with torch.no_grad():  # Disable gradient calculation during validation\n",
    "    for val_batch_idx, val_batch_data in tqdm(enumerate(val_data_loader)):\n",
    "        # Compute embeddings\n",
    "        val_embeddings2 = compute_embeddings(\n",
    "            device=device,\n",
    "            model_type=config['model_type'],\n",
    "            model=model2,\n",
    "            batch_data=val_batch_data,\n",
    "        )\n",
    "        # Compute loss\n",
    "        val_batch_loss2 = loss_fn(val_embeddings2)\n",
    "\n",
    "        val_loss2 += val_batch_loss2.item()\n",
    "        val_batches2 += 1\n",
    "\n",
    "    # Compute average loss\n",
    "    average_val_loss2 = val_loss2 / val_batches2\n",
    "\n",
    "print(\"Validation loss: \", average_val_loss2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c77aff9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ccac17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3: EVALUATE MODEL\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "# Loss on train\n",
    "train_loss = 0.0\n",
    "train_batches = 0\n",
    "\n",
    "with torch.no_grad():  # Disable gradient calculation during validation\n",
    "    for train_batch_idx, train_batch_data in enumerate(train_data_loader):\n",
    "        # Compute embeddings\n",
    "        train_embeddings = compute_embeddings(\n",
    "            device=device,\n",
    "            model_type=config['model_type'],\n",
    "            model=model,\n",
    "            batch_data=train_batch_data,\n",
    "        )\n",
    "        # Compute loss\n",
    "        train_batch_loss = loss_fn(train_embeddings)\n",
    "\n",
    "        train_loss += train_batch_loss.item()\n",
    "        train_batches += 1\n",
    "\n",
    "    # Compute average loss\n",
    "    average_train_loss = train_loss / train_batches\n",
    "\n",
    "print(\"Train loss: \", average_train_loss)\n",
    "\n",
    "# Loss on validation\n",
    "val_loss = 0.0\n",
    "val_batches = 0\n",
    "with torch.no_grad():  # Disable gradient calculation during validation\n",
    "    for val_batch_idx, val_batch_data in enumerate(val_data_loader):\n",
    "        # Compute embeddings\n",
    "        val_embeddings = compute_embeddings(\n",
    "            device=device,\n",
    "            model_type=config['model_type'],\n",
    "            model=model,\n",
    "            batch_data=val_batch_data,\n",
    "        )\n",
    "        # Compute loss\n",
    "        val_batch_loss = loss_fn(val_embeddings)\n",
    "\n",
    "        val_loss += val_batch_loss.item()\n",
    "        val_batches += 1\n",
    "\n",
    "    # Compute average loss\n",
    "    average_val_loss = val_loss / val_batches\n",
    "\n",
    "print(\"Validation loss: \", average_val_loss)\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

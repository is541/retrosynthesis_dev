{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3179f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !export PYTHONPATH=/Users/ilariasartori/syntheseus:/Users/ilariasartori/syntheseus/tutorials/search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0859e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !echo $PYTHONPATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b11cd69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from uuid import uuid4\n",
    "import os\n",
    "\n",
    "eventid = datetime.now().strftime('%Y%m-%d%H-%M%S-') + str(uuid4())\n",
    "print(eventid)\n",
    "\n",
    "output_folder = f\"Results/{eventid}\"\n",
    "\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d9e5c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96d1c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Basic code for nearest-neighbour value functions.\"\"\"\n",
    "from __future__ import annotations\n",
    "\n",
    "from enum import Enum\n",
    "\n",
    "import numpy as np\n",
    "from rdkit.Chem import DataStructs, AllChem\n",
    "\n",
    "from syntheseus.search.graph.and_or import OrNode\n",
    "from syntheseus.search.node_evaluation.base import NoCacheNodeEvaluator\n",
    "from syntheseus.search.mol_inventory import ExplicitMolInventory\n",
    "\n",
    "# from Users.ilariasartori.syntheseus.search.graph.and_or import OrNode\n",
    "\n",
    "\n",
    "class DistanceToCost(Enum):\n",
    "    NOTHING = 0\n",
    "    EXP = 1\n",
    "    SQRT = 2\n",
    "    TIMES10 = 3\n",
    "    TIMES100 = 4\n",
    "    NUM_NEIGHBORS_TO_06 = 5\n",
    "\n",
    "\n",
    "class TanimotoNNCostEstimator(NoCacheNodeEvaluator):\n",
    "    \"\"\"Estimates cost of a node using Tanimoto distance to purchasable molecules.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        inventory: ExplicitMolInventory,\n",
    "        distance_to_cost: DistanceToCost,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__(**kwargs)\n",
    "        self.distance_to_cost = distance_to_cost\n",
    "        self._set_fingerprints([mol.smiles for mol in inventory.purchasable_mols()])\n",
    "\n",
    "    def get_fingerprint(self, mol: AllChem.Mol):\n",
    "        return AllChem.GetMorganFingerprint(mol, radius=3)\n",
    "\n",
    "    def _set_fingerprints(self, smiles_list: list[str]) -> None:\n",
    "        \"\"\"Initialize fingerprint cache.\"\"\"\n",
    "        mols = list(map(AllChem.MolFromSmiles, smiles_list))\n",
    "        assert None not in mols, \"Invalid SMILES encountered.\"\n",
    "        self._fps = list(map(self.get_fingerprint, mols))\n",
    "        \n",
    "    def find_min_num_elem_summing_to_threshold(self, array, threshold):\n",
    "        # Sort the array in ascending order\n",
    "        sorted_array = np.sort(array)[::-1]\n",
    "\n",
    "        # Calculate the cumulative sum of the sorted array\n",
    "        cum_sum = np.cumsum(sorted_array)\n",
    "\n",
    "        # Find the index where the cumulative sum exceeds threshold \n",
    "        index = np.searchsorted(cum_sum, threshold)\n",
    "\n",
    "        # Check if a subset of elements sums up to more than threshold\n",
    "        if index < len(array):\n",
    "            return index + 1  # Add 1 to account for 0-based indexing\n",
    "\n",
    "        # If no subset of elements sums up to more than threshold\n",
    "        return len(array) #-1\n",
    "\n",
    "    def _get_nearest_neighbour_dist(self, smiles: str) -> float:\n",
    "        fp_query = self.get_fingerprint(AllChem.MolFromSmiles(smiles))\n",
    "        tanimoto_sims = DataStructs.BulkTanimotoSimilarity(fp_query, self._fps)\n",
    "        if self.distance_to_cost == DistanceToCost.NUM_NEIGHBORS_TO_06:\n",
    "            return 1 - self.find_min_num_elem_summing_to_threshold(array=tanimoto_sims,threshold=0.6)/ len(tanimoto_sims)\n",
    "        else:\n",
    "            return 1 - max(tanimoto_sims)\n",
    "\n",
    "    def _evaluate_nodes(self, nodes: list[OrNode], graph=None) -> list[float]:\n",
    "        if len(nodes) == 0:\n",
    "            return []\n",
    "\n",
    "        # Get distances to nearest neighbours\n",
    "        nn_dists = np.asarray(\n",
    "            [self._get_nearest_neighbour_dist(node.mol.smiles) for node in nodes]\n",
    "        )\n",
    "        assert np.min(nn_dists) >= 0\n",
    "\n",
    "        # Turn into costs\n",
    "        if self.distance_to_cost == DistanceToCost.NOTHING:\n",
    "            values = nn_dists\n",
    "        elif self.distance_to_cost == DistanceToCost.EXP:\n",
    "            values = np.exp(nn_dists) - 1\n",
    "        elif self.distance_to_cost == DistanceToCost.SQRT:\n",
    "            values = np.sqrt(nn_dists) \n",
    "        elif self.distance_to_cost == DistanceToCost.TIMES10:\n",
    "            values = 10.0*nn_dists\n",
    "        elif self.distance_to_cost == DistanceToCost.TIMES100:\n",
    "            values = 100.0*nn_dists\n",
    "        elif self.distance_to_cost == DistanceToCost.NUM_NEIGHBORS_TO_06:\n",
    "            values = nn_dists\n",
    "        else:\n",
    "            raise NotImplementedError(self.distance_to_cost)\n",
    "\n",
    "        return list(values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9d9368",
   "metadata": {},
   "outputs": [],
   "source": [
    "route_div = True # Count number of diverse routes found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ebc133",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Faster implementation\n",
    "\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "from collections.abc import Sequence\n",
    "\n",
    "from syntheseus.search.algorithms.best_first.retro_star import RetroStarSearch\n",
    "from syntheseus.search.graph.and_or import ANDOR_NODE, AndOrGraph, OrNode\n",
    "\n",
    "\n",
    "class ReduceValueFunctionCallsRetroStar(RetroStarSearch):\n",
    "    \"\"\"\n",
    "    More efficient version of Retro* which saves value function calls.\n",
    "    The difference is that retro* calls the value function (i.e. reaction number estimator)\n",
    "    for every leaf node whereas this algorithm assigns a placeholder value of 0 to every leaf node\n",
    "    and only calls the value function if it visits that node a second time.\n",
    "    This essentially leaves the behaviour of retro* unchanged, but saves value function calls.\n",
    "\n",
    "    The reason this works is that retro* greedily expands nodes on the current lowest-cost route,\n",
    "    using the value function (reaction number) estimate as the cost of the node.\n",
    "    If a node is not visited with a value function estimate of 0,\n",
    "    then it would definitely not be visited with a non-zero value function estimate.\n",
    "    Therefore if a node is not visited with a placeholder value of 0,\n",
    "    it doesn't really matter what the value function estimate is.\n",
    "    \"\"\"\n",
    "\n",
    "    def setup(self, graph: AndOrGraph) -> None:\n",
    "        # If there is only 1 node, \"visit\" it by setting its reaction number estimate to 0\n",
    "        # and incrementing its visit count\n",
    "        if len(graph) == 1:\n",
    "            graph.root_node.num_visit += 1\n",
    "            graph.root_node.data.setdefault(\"reaction_number_estimate\", 0.0)\n",
    "\n",
    "        return super().setup(graph)\n",
    "\n",
    "    def visit_node(self, node: OrNode, graph: AndOrGraph) -> Sequence[ANDOR_NODE]:\n",
    "        \"\"\"\n",
    "        If node.num_visit == 0 then evaluate the value function and return.\n",
    "        Otherwise expand.\n",
    "        \"\"\"\n",
    "        assert node.num_visit >= 0  # should not be negative\n",
    "        node.num_visit += 1\n",
    "        if node.num_visit == 1:\n",
    "            # Evaluate value function and return.\n",
    "            node.data[\"reaction_number_estimate\"] = self.reaction_number_estimator(\n",
    "                [node]\n",
    "            )[0]\n",
    "            return []\n",
    "        else:\n",
    "            return super().visit_node(node, graph)\n",
    "\n",
    "    def _set_reaction_number_estimate(\n",
    "        self, or_nodes: Sequence[OrNode], graph: AndOrGraph\n",
    "    ) -> None:\n",
    "        for node in or_nodes:\n",
    "            node.data.setdefault(\"reaction_number_estimate\", 0.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9be200",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Demo script comparing nearest neighbour cost function with constant value function on PaRoutes.\n",
    "\"\"\"\n",
    "from __future__ import annotations\n",
    "\n",
    "import argparse\n",
    "import logging\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from syntheseus.search.chem import Molecule\n",
    "from syntheseus.search.graph.and_or import AndNode\n",
    "from syntheseus.search.algorithms.best_first.retro_star import RetroStarSearch, MolIsPurchasableCost\n",
    "from syntheseus.search.analysis.solution_time import get_first_solution_time\n",
    "from syntheseus.search.analysis.route_extraction import min_cost_routes\n",
    "from syntheseus.search.reaction_models.base import BackwardReactionModel\n",
    "from syntheseus.search.mol_inventory import BaseMolInventory\n",
    "from syntheseus.search.node_evaluation.base import (\n",
    "    BaseNodeEvaluator,\n",
    "    NoCacheNodeEvaluator,\n",
    ")\n",
    "from syntheseus.search.node_evaluation.common import ConstantNodeEvaluator\n",
    "\n",
    "from paroutes import PaRoutesInventory, PaRoutesModel, get_target_smiles\n",
    "# from neighbour_value_functions import TanimotoNNCostEstimator, DistanceToCost\n",
    "\n",
    "from syntheseus.search.analysis import diversity\n",
    "# from syntheseus.search.algorithms.best_first.retro_star import MolIsPurchasableCost\n",
    "\n",
    "class SearchResult:\n",
    "    def __init__(self, name, soln_time_dict, num_different_routes_dict, \n",
    "                 final_num_rxn_model_calls_dict, final_num_value_function_calls_dict,\n",
    "                 output_graph_dict, routes_dict):\n",
    "        self.name = name\n",
    "        self.soln_time_dict = soln_time_dict\n",
    "        self.num_different_routes_dict = num_different_routes_dict\n",
    "        self.final_num_rxn_model_calls_dict = final_num_rxn_model_calls_dict\n",
    "        self.output_graph_dict = output_graph_dict\n",
    "        self.routes_dict = routes_dict\n",
    "        self.final_num_value_function_calls_dict = final_num_value_function_calls_dict\n",
    "\n",
    "\n",
    "class PaRoutesRxnCost(NoCacheNodeEvaluator[AndNode]):\n",
    "    \"\"\"Cost of reaction is negative log softmax, floored at -3.\"\"\"\n",
    "\n",
    "    def _evaluate_nodes(self, nodes: list[AndNode], graph=None) -> list[float]:\n",
    "        softmaxes = np.asarray([node.reaction.metadata[\"softmax\"] for node in nodes])\n",
    "        costs = np.clip(-np.log(softmaxes), 1e-1, 10.0)\n",
    "        return costs.tolist()\n",
    "\n",
    "\n",
    "def run_algorithm(\n",
    "    name: str,\n",
    "    smiles_list: list[str],\n",
    "    value_function: BaseNodeEvaluator,\n",
    "    rxn_model: BackwardReactionModel,\n",
    "    inventory: BaseMolInventory,\n",
    "    and_node_cost_fn: BaseNodeEvaluator[AndNode],\n",
    "    or_node_cost_fn: BaseNodeEvaluator[OrNode],\n",
    "    max_expansion_depth: int = 15,\n",
    "    prevent_repeat_mol_in_trees: bool= True,\n",
    "    use_tqdm: bool = False,\n",
    "    limit_rxn_model_calls: int = 100,\n",
    "    limit_iterations: int = 1_000_000,\n",
    "    logger: logging.RootLogger = logging.getLogger(),\n",
    ") -> SearchResult:\n",
    "    \"\"\"\n",
    "    Do search on a list of SMILES strings and report the time of first solution.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize algorithm.\n",
    "    common_kwargs = dict(\n",
    "        reaction_model=rxn_model,\n",
    "        mol_inventory=inventory,\n",
    "        limit_reaction_model_calls=limit_rxn_model_calls,\n",
    "        limit_iterations=limit_iterations,\n",
    "        max_expansion_depth=max_expansion_depth,  # prevent overly-deep solutions\n",
    "        prevent_repeat_mol_in_trees=prevent_repeat_mol_in_trees,  # original paper did this\n",
    "    )\n",
    "    alg = ReduceValueFunctionCallsRetroStar(\n",
    "            and_node_cost_fn=PaRoutesRxnCost(), value_function=value_function, **common_kwargs\n",
    "        )\n",
    "\n",
    "    # Do search\n",
    "    logger.info(f\"Start search with {name}\")\n",
    "    min_soln_times: list[tuple[float, ...]] = []\n",
    "    if use_tqdm:\n",
    "        smiles_iter = tqdm(smiles_list)\n",
    "    else:\n",
    "        smiles_iter = smiles_list\n",
    "        \n",
    "    output_graph_dict = {}\n",
    "    soln_time_dict = {}\n",
    "    routes_dict = {}\n",
    "    final_num_rxn_model_calls_dict = {}\n",
    "    final_num_value_function_calls_dict = {}\n",
    "    num_different_routes_dict = {}\n",
    "    \n",
    "    for i, smiles in enumerate(smiles_iter):\n",
    "        logger.debug(f\"Start search {i}/{len(smiles_list)}. SMILES: {smiles}\")\n",
    "        this_soln_times = list()\n",
    "        alg.reset()\n",
    "        output_graph, _ = alg.run_from_mol(Molecule(smiles))\n",
    "\n",
    "        # Analyze solution time\n",
    "        for node in output_graph.nodes():\n",
    "            node.data[\"analysis_time\"] = node.data[\"num_calls_rxn_model\"]\n",
    "        soln_time = get_first_solution_time(output_graph)\n",
    "        this_soln_times.append(soln_time)\n",
    "\n",
    "        # Analyze number of routes\n",
    "        MAX_ROUTES = 10000\n",
    "        routes = list(min_cost_routes(output_graph, MAX_ROUTES))\n",
    "\n",
    "        if alg.reaction_model.num_calls() < limit_rxn_model_calls:\n",
    "            note = \" (NOTE: this was less than the maximum budget)\"\n",
    "        else:\n",
    "            note = \"\"\n",
    "        logger.debug(\n",
    "            f\"Done {name}: nodes={len(output_graph)}, solution time = {soln_time}, \"\n",
    "            f\"num routes = {len(routes)} (capped at {MAX_ROUTES}), \"\n",
    "            f\"final num rxn model calls = {alg.reaction_model.num_calls()}{note}, \"\n",
    "            f\"final num value model calls = {alg.value_function.num_calls}.\"\n",
    "        )\n",
    "\n",
    "        # Analyze route diversity \n",
    "        if (len(routes)>0) & route_div:\n",
    "            route_objects = [output_graph.to_synthesis_graph(nodes) for nodes in routes]\n",
    "            packing_set = diversity.estimate_packing_number(\n",
    "                routes=route_objects,\n",
    "                distance_metric=diversity.reaction_jaccard_distance,\n",
    "                radius=0.999  # because comparison is > not >=\n",
    "            )\n",
    "            logger.debug((f\"number of distinct routes = {len(packing_set)}\"))\n",
    "        else:\n",
    "            packing_set = []\n",
    "\n",
    "        # Save results\n",
    "        soln_time_dict.update({smiles: soln_time})\n",
    "        final_num_rxn_model_calls_dict.update({smiles: alg.reaction_model.num_calls()})\n",
    "        final_num_value_function_calls_dict.update({smiles: alg.value_function.num_calls})\n",
    "        num_different_routes_dict.update({smiles: len(packing_set)})\n",
    "        output_graph_dict.update({smiles: output_graph})\n",
    "        routes_dict.update({smiles: routes})\n",
    "            \n",
    "    return SearchResult(name=name,\n",
    "                        soln_time_dict=soln_time_dict, \n",
    "                        num_different_routes_dict=num_different_routes_dict, \n",
    "                        final_num_rxn_model_calls_dict=final_num_rxn_model_calls_dict, \n",
    "                        final_num_value_function_calls_dict=final_num_value_function_calls_dict,\n",
    "                        output_graph_dict=output_graph_dict, \n",
    "                        routes_dict=routes_dict)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620f1d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arguments\n",
    "\n",
    "# COMMAND LINE\n",
    "# if __name__ == \"__main__\":\n",
    "#     parser = argparse.ArgumentParser()\n",
    "#     parser.add_argument(\n",
    "#         \"--limit_num_smiles\",\n",
    "#         type=int,\n",
    "#         default=None,\n",
    "#         help=\"Maximum number of SMILES to run.\",\n",
    "#     )\n",
    "#     parser.add_argument(\n",
    "#         \"--limit_iterations\",\n",
    "#         type=int,\n",
    "#         default=500,\n",
    "#         help=\"Maximum number of algorithm iterations.\",\n",
    "#     )\n",
    "#     parser.add_argument(\n",
    "#         \"--limit_rxn_model_calls\",\n",
    "#         type=int,\n",
    "#         default=25,\n",
    "#         help=\"Allowed number of calls to reaction model.\",\n",
    "#     )\n",
    "#     parser.add_argument(\n",
    "#         \"--paroutes_n\",\n",
    "#         type=int,\n",
    "#         default=5,\n",
    "#         help=\"Which PaRoutes benchmark to use.\",\n",
    "#     )\n",
    "#     args = parser.parse_args()\n",
    "\n",
    "# NOTEBOOK\n",
    "class Args:\n",
    "    limit_num_smiles = None\n",
    "    limit_iterations = 500 # 100000\n",
    "    limit_rxn_model_calls = 100 # 500\n",
    "    paroutes_n = 5\n",
    "    max_expansion_depth = 20\n",
    "    max_num_templates = 10  # Default 50\n",
    "    prevent_repeat_mol_in_trees = True\n",
    "    rxn_model = 'PAROUTES'\n",
    "    inventory = 'PAROUTES'\n",
    "    and_node_cost_fn='PAROUTES'\n",
    "    or_node_cost_fn = 'MOL_PURCHASABLE' \n",
    "\n",
    "\n",
    "args=Args()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0e8c5e",
   "metadata": {},
   "source": [
    "## Create dataframe for time to solution and number of routes found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18832768",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)\n",
    "# formatter = logging.Formatter('%(asctime)s | %(levelname)s | %(message)s')\n",
    "formatter = logging.Formatter('%(asctime)s %(name)s %(levelname)s %(message)s')\n",
    "\n",
    "stdout_handler = logging.StreamHandler(sys.stdout)\n",
    "stdout_handler.setLevel(logging.INFO)\n",
    "stdout_handler.setFormatter(formatter)\n",
    "\n",
    "file_handler = logging.FileHandler(f'{output_folder}/logs.txt', mode='w')\n",
    "file_handler.setLevel(logging.DEBUG)\n",
    "file_handler.setFormatter(formatter)\n",
    "\n",
    "logger.addHandler(file_handler)\n",
    "logger.addHandler(stdout_handler)\n",
    "\n",
    "\n",
    "# Load all SMILES to test\n",
    "test_smiles = get_target_smiles(args.paroutes_n)\n",
    "\n",
    "## Test on smaller dataset\n",
    "test_smiles_all = test_smiles.copy()\n",
    "dim_test = 100 # 500\n",
    "test_smiles = test_smiles_all[:dim_test]\n",
    "##\n",
    "\n",
    "if args.limit_num_smiles is not None:\n",
    "    test_smiles = test_smiles[: args.limit_num_smiles]\n",
    "\n",
    "# Make reaction model, inventory, cost functions and value functions\n",
    "if args.and_node_cost_fn == 'PAROUTES':\n",
    "    and_node_cost_fn=PaRoutesRxnCost()\n",
    "else:\n",
    "    raise NotImplementedError(f'and_node_cost_fn: {args.and_node_cost_fn}')\n",
    "\n",
    "if args.or_node_cost_fn == 'MOL_PURCHASABLE':\n",
    "    or_node_cost_fn=MolIsPurchasableCost()\n",
    "else:\n",
    "    raise NotImplementedError(f'or_node_cost_fn: {args.or_node_cost_fn}')\n",
    "\n",
    "if args.inventory == 'PAROUTES':\n",
    "    inventory=PaRoutesInventory(n=args.paroutes_n)\n",
    "else:\n",
    "    raise NotImplementedError(f'inventory: {args.inventory}')\n",
    "\n",
    "if args.rxn_model == 'PAROUTES':\n",
    "    rxn_model=PaRoutesModel(max_num_templates=args.max_num_templates)\n",
    "else:\n",
    "    raise NotImplementedError(f'rxn_model: {args.rxn_model}')\n",
    "\n",
    "\n",
    "value_fns = [\n",
    "#     (\"constant-0\", ConstantNodeEvaluator(0.0)),\n",
    "#     (\n",
    "#         \"Tanimoto-distance\",\n",
    "#         TanimotoNNCostEstimator(\n",
    "#             inventory=inventory, distance_to_cost=DistanceToCost.NOTHING\n",
    "#         ),\n",
    "#     ),\n",
    "#     (\n",
    "#         \"Tanimoto-distance-TIMES10\",\n",
    "#         TanimotoNNCostEstimator(\n",
    "#             inventory=inventory, distance_to_cost=DistanceToCost.TIMES10\n",
    "#         ),\n",
    "#     ),\n",
    "# #     (\n",
    "# #         \"Tanimoto-distance-TIMES100\",\n",
    "# #         TanimotoNNCostEstimator(\n",
    "# #             inventory=inventory, distance_to_cost=DistanceToCost.TIMES100\n",
    "# #         ),\n",
    "# #     ),\n",
    "#     (\n",
    "#         \"Tanimoto-distance-EXP\",\n",
    "#         TanimotoNNCostEstimator(\n",
    "#             inventory=inventory, distance_to_cost=DistanceToCost.EXP\n",
    "#         ),\n",
    "#     ),\n",
    "#     (\n",
    "#         \"Tanimoto-distance-SQRT\",\n",
    "#         TanimotoNNCostEstimator(\n",
    "#             inventory=inventory, distance_to_cost=DistanceToCost.SQRT\n",
    "#         ),\n",
    "#     ),\n",
    "    (\n",
    "        \"Tanimoto-distance-NUM_NEIGHBORS_TO_06\",\n",
    "        TanimotoNNCostEstimator(\n",
    "            inventory=inventory, distance_to_cost=DistanceToCost.NUM_NEIGHBORS_TO_06\n",
    "        ),\n",
    "    ),\n",
    "]\n",
    "\n",
    "labelalias = {\n",
    "    'constant-0': 'constant-0',\n",
    "    'Tanimoto-distance': 'Tanimoto',\n",
    "    'Tanimoto-distance-TIMES10': 'Tanimoto_times10',\n",
    "    'Tanimoto-distance-TIMES100': 'Tanimoto_times100',\n",
    "    'Tanimoto-distance-EXP': 'Tanimoto_exp',\n",
    "    'Tanimoto-distance-SQRT': 'Tanimoto_sqrt',\n",
    "    \"Tanimoto-distance-NUM_NEIGHBORS_TO_06\": \"Tanimoto_nn_to_06\",\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# Run\n",
    "logger.info(f\"Start experiment {eventid}\")\n",
    "args_string = \"\"\n",
    "for attr in dir(args):\n",
    "    if not callable(getattr(args, attr)) and not attr.startswith(\"__\"):\n",
    "        args_string = args_string + \"\\n\" + (f\"{attr}: {getattr(args, attr)}\") \n",
    "logger.info(f\"Args: {args_string}\")\n",
    "logger.info(f\"dim_test: {dim_test}\")\n",
    "\n",
    "\n",
    "import pickle\n",
    "\n",
    "result={}\n",
    "for name, fn in value_fns:\n",
    "    alg_result = run_algorithm(\n",
    "        name=name,\n",
    "        smiles_list=test_smiles, \n",
    "        value_function=fn, \n",
    "        rxn_model=rxn_model,\n",
    "        inventory=inventory,\n",
    "        and_node_cost_fn=and_node_cost_fn,\n",
    "        or_node_cost_fn=or_node_cost_fn, \n",
    "        max_expansion_depth=args.max_expansion_depth, \n",
    "        prevent_repeat_mol_in_trees=args.prevent_repeat_mol_in_trees, \n",
    "        use_tqdm=True,\n",
    "        limit_rxn_model_calls=args.limit_rxn_model_calls, \n",
    "        limit_iterations=args.limit_iterations,\n",
    "        logger=logger,\n",
    "    )\n",
    "    result[name] = alg_result\n",
    "    \n",
    "    # Save pickle\n",
    "    with open(f'{output_folder}/result_{name}.pickle', 'wb') as handle:\n",
    "        pickle.dump(alg_result, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce35b3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def create_result_df(result, name):\n",
    "    assert name == result[name].name, f\"name: {name} is different from result[name].name: {result[name].name}\"\n",
    "    \n",
    "    soln_time_dict = result[name].soln_time_dict\n",
    "    num_different_routes_dict = result[name].num_different_routes_dict\n",
    "    final_num_rxn_model_calls_dict = result[name].final_num_rxn_model_calls_dict\n",
    "    output_graph_dict = result[name].output_graph_dict\n",
    "    routes_dict = result[name].routes_dict\n",
    "\n",
    "    # df_results = pd.DataFrame()\n",
    "    df_soln_time = pd.DataFrame({'algorithm': [], 'similes': [], 'property':[], 'value': []})\n",
    "    df_different_routes = pd.DataFrame({'algorithm': [], 'similes': [], 'property':[], 'value': []})\n",
    "\n",
    "    #     for name_alg, value_dict  in soln_time_dict.items():\n",
    "    for smiles, value  in soln_time_dict.items():\n",
    "        row_soln_time = {'algorithm': name, 'similes': smiles, 'property':'sol_time', 'value': value}\n",
    "\n",
    "        df_soln_time = pd.concat([df_soln_time, pd.DataFrame([row_soln_time])], ignore_index=True)\n",
    "\n",
    "    #     for name_alg, value_dict  in num_different_routes_dict.items():\n",
    "    for smiles, value  in num_different_routes_dict.items():\n",
    "        row_different_routes = {'algorithm': name, 'similes': smiles, 'property':'diff_routes', 'value': value}\n",
    "\n",
    "        df_different_routes = pd.concat([df_different_routes, pd.DataFrame([row_different_routes])], ignore_index=True)\n",
    "\n",
    "    df_results_tot = pd.concat([df_soln_time, df_different_routes], axis=0)\n",
    "    return df_results_tot\n",
    "\n",
    "\n",
    "\n",
    "df_results_tot = pd.DataFrame({'algorithm': [], 'similes': [], 'property':[], 'value': []})\n",
    "for name in result.keys():\n",
    "    df_results_alg = create_result_df(result, name)\n",
    "    df_results_tot = pd.concat([df_results_tot, df_results_alg], axis=0)\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b4c8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85028c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to csv\n",
    "# df_results_tot.to_csv(f'Results/Compare/compare_times_{dim_test}.csv', index=False)\n",
    "df_results_tot.to_csv(f'{output_folder}/results_all.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa13598b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e78529",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad7523b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

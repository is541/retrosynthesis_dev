{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3179f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !export PYTHONPATH=/Users/ilariasartori/syntheseus:/Users/ilariasartori/syntheseus/tutorials/search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0859e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !echo $PYTHONPATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888196ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from uuid import uuid4\n",
    "import os\n",
    "\n",
    "eventid = datetime.now().strftime('%Y%m-%d%H-%M%S-') + str(uuid4())\n",
    "print(eventid)\n",
    "\n",
    "output_folder = f\"Results/{eventid}\"\n",
    "\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6888ecbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96d1c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Basic code for nearest-neighbour value functions.\"\"\"\n",
    "from __future__ import annotations\n",
    "\n",
    "from enum import Enum\n",
    "\n",
    "import numpy as np\n",
    "from rdkit.Chem import DataStructs, AllChem\n",
    "\n",
    "from syntheseus.search.graph.and_or import OrNode\n",
    "from syntheseus.search.node_evaluation.base import NoCacheNodeEvaluator\n",
    "from syntheseus.search.mol_inventory import ExplicitMolInventory\n",
    "\n",
    "# from Users.ilariasartori.syntheseus.search.graph.and_or import OrNode\n",
    "\n",
    "\n",
    "class DistanceToCost(Enum):\n",
    "    NOTHING = 0\n",
    "    EXP = 1\n",
    "    SQRT = 2\n",
    "    TIMES10 = 3\n",
    "    TIMES100 = 4\n",
    "\n",
    "\n",
    "class TanimotoNNCostEstimator(NoCacheNodeEvaluator):\n",
    "    \"\"\"Estimates cost of a node using Tanimoto distance to purchasable molecules.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        inventory: ExplicitMolInventory,\n",
    "        distance_to_cost: DistanceToCost,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__(**kwargs)\n",
    "        self.distance_to_cost = distance_to_cost\n",
    "        self._set_fingerprints([mol.smiles for mol in inventory.purchasable_mols()])\n",
    "\n",
    "    def get_fingerprint(self, mol: AllChem.Mol):\n",
    "        return AllChem.GetMorganFingerprint(mol, radius=3)\n",
    "\n",
    "    def _set_fingerprints(self, smiles_list: list[str]) -> None:\n",
    "        \"\"\"Initialize fingerprint cache.\"\"\"\n",
    "        mols = list(map(AllChem.MolFromSmiles, smiles_list))\n",
    "        assert None not in mols, \"Invalid SMILES encountered.\"\n",
    "        self._fps = list(map(self.get_fingerprint, mols))\n",
    "\n",
    "    def _get_nearest_neighbour_dist(self, smiles: str) -> float:\n",
    "        fp_query = self.get_fingerprint(AllChem.MolFromSmiles(smiles))\n",
    "        tanimoto_sims = DataStructs.BulkTanimotoSimilarity(fp_query, self._fps)\n",
    "        return 1 - max(tanimoto_sims)\n",
    "\n",
    "    def _evaluate_nodes(self, nodes: list[OrNode], graph=None) -> list[float]:\n",
    "        if len(nodes) == 0:\n",
    "            return []\n",
    "\n",
    "        # Get distances to nearest neighbours\n",
    "        nn_dists = np.asarray(\n",
    "            [self._get_nearest_neighbour_dist(node.mol.smiles) for node in nodes]\n",
    "        )\n",
    "        assert np.min(nn_dists) >= 0\n",
    "\n",
    "        # Turn into costs\n",
    "        if self.distance_to_cost == DistanceToCost.NOTHING:\n",
    "            values = nn_dists\n",
    "        elif self.distance_to_cost == DistanceToCost.EXP:\n",
    "            values = np.exp(nn_dists) - 1\n",
    "        elif self.distance_to_cost == DistanceToCost.SQRT:\n",
    "            values = np.sqrt(nn_dists) \n",
    "        elif self.distance_to_cost == DistanceToCost.TIMES10:\n",
    "            values = 10.0*nn_dists\n",
    "        elif self.distance_to_cost == DistanceToCost.TIMES100:\n",
    "            values = 100.0*nn_dists\n",
    "        else:\n",
    "            raise NotImplementedError(self.distance_to_cost)\n",
    "\n",
    "        return list(values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9d9368",
   "metadata": {},
   "outputs": [],
   "source": [
    "route_div = True # Count number of diverse routes found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9be200",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Demo script comparing nearest neighbour cost function with constant value function on PaRoutes.\n",
    "\"\"\"\n",
    "from __future__ import annotations\n",
    "\n",
    "import argparse\n",
    "import logging\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from syntheseus.search.chem import Molecule\n",
    "from syntheseus.search.graph.and_or import AndNode\n",
    "from syntheseus.search.algorithms.best_first.retro_star import RetroStarSearch, MolIsPurchasableCost\n",
    "from syntheseus.search.analysis.solution_time import get_first_solution_time\n",
    "from syntheseus.search.analysis.route_extraction import min_cost_routes\n",
    "from syntheseus.search.reaction_models.base import BackwardReactionModel\n",
    "from syntheseus.search.mol_inventory import BaseMolInventory\n",
    "from syntheseus.search.node_evaluation.base import (\n",
    "    BaseNodeEvaluator,\n",
    "    NoCacheNodeEvaluator,\n",
    ")\n",
    "from syntheseus.search.node_evaluation.common import ConstantNodeEvaluator\n",
    "\n",
    "from paroutes import PaRoutesInventory, PaRoutesModel, get_target_smiles\n",
    "# from neighbour_value_functions import TanimotoNNCostEstimator, DistanceToCost\n",
    "\n",
    "from syntheseus.search.analysis import diversity\n",
    "# from syntheseus.search.algorithms.best_first.retro_star import MolIsPurchasableCost\n",
    "\n",
    "class SearchResult:\n",
    "    def __init__(self, name, soln_time_dict, num_different_routes_dict, \n",
    "                 final_num_rxn_model_calls_dict, output_graph_dict, routes_dict):\n",
    "        self.name = name\n",
    "        self.soln_time_dict = soln_time_dict\n",
    "        self.num_different_routes_dict = num_different_routes_dict\n",
    "        self.final_num_rxn_model_calls_dict = final_num_rxn_model_calls_dict\n",
    "        self.output_graph_dict = output_graph_dict\n",
    "        self.routes_dict = routes_dict\n",
    "\n",
    "\n",
    "class PaRoutesRxnCost(NoCacheNodeEvaluator[AndNode]):\n",
    "    \"\"\"Cost of reaction is negative log softmax, floored at -3.\"\"\"\n",
    "\n",
    "    def _evaluate_nodes(self, nodes: list[AndNode], graph=None) -> list[float]:\n",
    "        softmaxes = np.asarray([node.reaction.metadata[\"softmax\"] for node in nodes])\n",
    "        costs = np.clip(-np.log(softmaxes), 1e-1, 10.0)\n",
    "        return costs.tolist()\n",
    "\n",
    "\n",
    "def run_algorithm(\n",
    "    name: str,\n",
    "    smiles_list: list[str],\n",
    "    value_function: BaseNodeEvaluator,\n",
    "    rxn_model: BackwardReactionModel,\n",
    "    inventory: BaseMolInventory,\n",
    "    and_node_cost_fn: BaseNodeEvaluator[AndNode],\n",
    "    or_node_cost_fn: BaseNodeEvaluator[OrNode],\n",
    "    max_expansion_depth: int = 15,\n",
    "    prevent_repeat_mol_in_trees: bool= True,\n",
    "    use_tqdm: bool = False,\n",
    "    limit_rxn_model_calls: int = 100,\n",
    "    limit_iterations: int = 1_000_000,\n",
    "    logger: logging.RootLogger = logging.getLogger(),\n",
    ") -> SearchResult:\n",
    "    \"\"\"\n",
    "    Do search on a list of SMILES strings and report the time of first solution.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize algorithm.\n",
    "    common_kwargs = dict(\n",
    "        reaction_model=rxn_model,\n",
    "        mol_inventory=inventory,\n",
    "        limit_reaction_model_calls=limit_rxn_model_calls,\n",
    "        limit_iterations=limit_iterations,\n",
    "        max_expansion_depth=max_expansion_depth,  # prevent overly-deep solutions\n",
    "        prevent_repeat_mol_in_trees=prevent_repeat_mol_in_trees,  # original paper did this\n",
    "    )\n",
    "#     algs = [\n",
    "#         RetroStarSearch(\n",
    "#             and_node_cost_fn=PaRoutesRxnCost(), value_function=fn, **common_kwargs\n",
    "#         )\n",
    "#         for _, fn in value_functions\n",
    "#     ]\n",
    "    alg = RetroStarSearch(\n",
    "            and_node_cost_fn=PaRoutesRxnCost(), value_function=value_function, **common_kwargs\n",
    "        )\n",
    "\n",
    "    # Do search\n",
    "    logger.info(f\"Start search with {name}\")\n",
    "#     logger = logging.getLogger(\"COMPARISON\")\n",
    "    min_soln_times: list[tuple[float, ...]] = []\n",
    "    if use_tqdm:\n",
    "        smiles_iter = tqdm(smiles_list)\n",
    "    else:\n",
    "        smiles_iter = smiles_list\n",
    "        \n",
    "    output_graph_dict = {}\n",
    "    soln_time_dict = {}\n",
    "    routes_dict = {}\n",
    "    final_num_rxn_model_calls_dict = {}\n",
    "    num_different_routes_dict = {}\n",
    "    \n",
    "    for i, smiles in enumerate(smiles_iter):\n",
    "        logger.debug(f\"Start search {i}/{len(smiles_list)}. SMILES: {smiles}\")\n",
    "        this_soln_times = list()\n",
    "#         for (name, _), alg in zip(value_functions, algs):\n",
    "        alg.reset()\n",
    "        output_graph, _ = alg.run_from_mol(Molecule(smiles))\n",
    "#         if i==0:\n",
    "#             output_graph_dict[name] = {}\n",
    "#             soln_time_dict[name] = {}\n",
    "#             routes_dict[name] = {}\n",
    "#             final_num_rxn_model_calls_dict[name] = {}\n",
    "#             num_different_routes_dict[name] = {}\n",
    "\n",
    "        # Analyze solution time\n",
    "        for node in output_graph.nodes():\n",
    "            node.data[\"analysis_time\"] = node.data[\"num_calls_rxn_model\"]\n",
    "        soln_time = get_first_solution_time(output_graph)\n",
    "        this_soln_times.append(soln_time)\n",
    "\n",
    "        # Analyze number of routes\n",
    "        MAX_ROUTES = 10000\n",
    "        routes = list(min_cost_routes(output_graph, MAX_ROUTES))\n",
    "\n",
    "        if alg.reaction_model.num_calls() < limit_rxn_model_calls:\n",
    "            note = \" (NOTE: this was less than the maximum budget)\"\n",
    "        else:\n",
    "            note = \"\"\n",
    "        logger.debug(\n",
    "            f\"Done {name}: nodes={len(output_graph)}, solution time = {soln_time}, \"\n",
    "            f\"num routes = {len(routes)} (capped at {MAX_ROUTES}), \"\n",
    "            f\"final num rxn model calls = {alg.reaction_model.num_calls()}{note}.\"\n",
    "        )\n",
    "\n",
    "        # Analyze route diversity \n",
    "        if (len(routes)>0) & route_div:\n",
    "            route_objects = [output_graph.to_synthesis_graph(nodes) for nodes in routes]\n",
    "            packing_set = diversity.estimate_packing_number(\n",
    "                routes=route_objects,\n",
    "                distance_metric=diversity.reaction_jaccard_distance,\n",
    "                radius=0.999  # because comparison is > not >=\n",
    "            )\n",
    "            logger.debug((f\"number of distinct routes = {len(packing_set)}\"))\n",
    "        else:\n",
    "            packing_set = []\n",
    "\n",
    "        # Save results\n",
    "#         soln_time_dict[name].update({smiles: soln_time})\n",
    "#         final_num_rxn_model_calls_dict[name].update({smiles: alg.reaction_model.num_calls()})\n",
    "#         num_different_routes_dict[name].update({smiles: len(packing_set)})\n",
    "#         output_graph_dict[name].update({smiles: output_graph})\n",
    "#         routes_dict[name].update({smiles: routes})\n",
    "        soln_time_dict.update({smiles: soln_time})\n",
    "        final_num_rxn_model_calls_dict.update({smiles: alg.reaction_model.num_calls()})\n",
    "        num_different_routes_dict.update({smiles: len(packing_set)})\n",
    "        output_graph_dict.update({smiles: output_graph})\n",
    "        routes_dict.update({smiles: routes})\n",
    "            \n",
    "#     return min_soln_times\n",
    "    return SearchResult(name=name,\n",
    "                        soln_time_dict=soln_time_dict, \n",
    "                        num_different_routes_dict=num_different_routes_dict, \n",
    "                        final_num_rxn_model_calls_dict=final_num_rxn_model_calls_dict, \n",
    "                        output_graph_dict=output_graph_dict, \n",
    "                        routes_dict=routes_dict)\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "# def compare_cost_functions(\n",
    "#     smiles_list: list[str],\n",
    "#     value_functions: list[tuple[str, BaseNodeEvaluator]],\n",
    "#     rxn_model: BackwardReactionModel,\n",
    "#     inventory: BaseMolInventory,\n",
    "#     and_node_cost_fn: BaseNodeEvaluator[AndNode],\n",
    "#     or_node_cost_fn: BaseNodeEvaluator[OrNode],\n",
    "#     max_expansion_depth: int = 15,\n",
    "#     prevent_repeat_mol_in_trees: bool= True,\n",
    "#     use_tqdm: bool = False,\n",
    "#     limit_rxn_model_calls: int = 100,\n",
    "#     limit_iterations: int = 1_000_000,\n",
    "#     logger: logging.RootLogger = logging.getLogger(),\n",
    "# ) -> list[tuple[float, ...]]:\n",
    "#     \"\"\"\n",
    "#     Do search on a list of SMILES strings and report the time of first solution.\n",
    "#     \"\"\"\n",
    "\n",
    "#     # Initialize algorithm.\n",
    "#     common_kwargs = dict(\n",
    "#         reaction_model=rxn_model,\n",
    "#         mol_inventory=inventory,\n",
    "#         limit_reaction_model_calls=limit_rxn_model_calls,\n",
    "#         limit_iterations=limit_iterations,\n",
    "#         max_expansion_depth=max_expansion_depth,  # prevent overly-deep solutions\n",
    "#         prevent_repeat_mol_in_trees=prevent_repeat_mol_in_trees,  # original paper did this\n",
    "#     )\n",
    "#     algs = [\n",
    "#         RetroStarSearch(\n",
    "#             and_node_cost_fn=PaRoutesRxnCost(), value_function=fn, **common_kwargs\n",
    "#         )\n",
    "#         for _, fn in value_functions\n",
    "#     ]\n",
    "\n",
    "#     # Do search\n",
    "# #     logger = logging.getLogger(\"COMPARISON\")\n",
    "#     min_soln_times: list[tuple[float, ...]] = []\n",
    "#     if use_tqdm:\n",
    "#         smiles_iter = tqdm(smiles_list)\n",
    "#     else:\n",
    "#         smiles_iter = smiles_list\n",
    "        \n",
    "#     output_graph_dict = {}\n",
    "#     soln_time_dict = {}\n",
    "#     routes_dict = {}\n",
    "#     final_num_rxn_model_calls_dict = {}\n",
    "#     num_different_routes_dict = {}\n",
    "    \n",
    "#     for i, smiles in enumerate(smiles_iter):\n",
    "#         logger.debug(f\"Start search {i}/{len(smiles_list)}. SMILES: {smiles}\")\n",
    "#         this_soln_times = list()\n",
    "#         for (name, _), alg in zip(value_functions, algs):\n",
    "#             alg.reset()\n",
    "#             output_graph, _ = alg.run_from_mol(Molecule(smiles))\n",
    "#             if i==0:\n",
    "#                 output_graph_dict[name] = {}\n",
    "#                 soln_time_dict[name] = {}\n",
    "#                 routes_dict[name] = {}\n",
    "#                 final_num_rxn_model_calls_dict[name] = {}\n",
    "#                 num_different_routes_dict[name] = {}\n",
    "\n",
    "#             # Analyze solution time\n",
    "#             for node in output_graph.nodes():\n",
    "#                 node.data[\"analysis_time\"] = node.data[\"num_calls_rxn_model\"]\n",
    "#             soln_time = get_first_solution_time(output_graph)\n",
    "#             this_soln_times.append(soln_time)\n",
    "\n",
    "#             # Analyze number of routes\n",
    "#             MAX_ROUTES = 10000\n",
    "#             routes = list(min_cost_routes(output_graph, MAX_ROUTES))\n",
    "\n",
    "#             if alg.reaction_model.num_calls() < limit_rxn_model_calls:\n",
    "#                 note = \" (NOTE: this was less than the maximum budget)\"\n",
    "#             else:\n",
    "#                 note = \"\"\n",
    "#             logger.debug(\n",
    "#                 f\"Done {name}: nodes={len(output_graph)}, solution time = {soln_time}, \"\n",
    "#                 f\"num routes = {len(routes)} (capped at {MAX_ROUTES}), \"\n",
    "#                 f\"final num rxn model calls = {alg.reaction_model.num_calls()}{note}.\"\n",
    "#             )\n",
    "\n",
    "#             # Analyze route diversity \n",
    "#             if (len(routes)>0) & route_div:\n",
    "#                 route_objects = [output_graph.to_synthesis_graph(nodes) for nodes in routes]\n",
    "#                 packing_set = diversity.estimate_packing_number(\n",
    "#                     routes=route_objects,\n",
    "#                     distance_metric=diversity.reaction_jaccard_distance,\n",
    "#                     radius=0.999  # because comparison is > not >=\n",
    "#                 )\n",
    "#                 logger.debug((f\"number of distinct routes = {len(packing_set)}\"))\n",
    "#             else:\n",
    "#                 packing_set = []\n",
    "            \n",
    "#             # Save results\n",
    "#             soln_time_dict[name].update({smiles: soln_time})\n",
    "#             final_num_rxn_model_calls_dict[name].update({smiles: alg.reaction_model.num_calls()})\n",
    "#             num_different_routes_dict[name].update({smiles: len(packing_set)})\n",
    "#             output_graph_dict[name].update({smiles: output_graph})\n",
    "#             routes_dict[name].update({smiles: routes})\n",
    "            \n",
    "\n",
    "# #     return min_soln_times\n",
    "#     return soln_time_dict, num_different_routes_dict, final_num_rxn_model_calls_dict, output_graph_dict, routes_dict\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620f1d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arguments\n",
    "\n",
    "# COMMAND LINE\n",
    "# if __name__ == \"__main__\":\n",
    "#     parser = argparse.ArgumentParser()\n",
    "#     parser.add_argument(\n",
    "#         \"--limit_num_smiles\",\n",
    "#         type=int,\n",
    "#         default=None,\n",
    "#         help=\"Maximum number of SMILES to run.\",\n",
    "#     )\n",
    "#     parser.add_argument(\n",
    "#         \"--limit_iterations\",\n",
    "#         type=int,\n",
    "#         default=500,\n",
    "#         help=\"Maximum number of algorithm iterations.\",\n",
    "#     )\n",
    "#     parser.add_argument(\n",
    "#         \"--limit_rxn_model_calls\",\n",
    "#         type=int,\n",
    "#         default=25,\n",
    "#         help=\"Allowed number of calls to reaction model.\",\n",
    "#     )\n",
    "#     parser.add_argument(\n",
    "#         \"--paroutes_n\",\n",
    "#         type=int,\n",
    "#         default=5,\n",
    "#         help=\"Which PaRoutes benchmark to use.\",\n",
    "#     )\n",
    "#     args = parser.parse_args()\n",
    "\n",
    "# NOTEBOOK\n",
    "class Args:\n",
    "    limit_num_smiles = None\n",
    "    limit_iterations = 1000\n",
    "    limit_rxn_model_calls = 100\n",
    "    paroutes_n = 5\n",
    "    max_expansion_depth = 20\n",
    "    max_num_templates = 10  # Default 50\n",
    "    prevent_repeat_mol_in_trees = True\n",
    "    rxn_model = 'PAROUTES'\n",
    "    inventory = 'PAROUTES'\n",
    "    and_node_cost_fn='PAROUTES'\n",
    "    or_node_cost_fn = 'MOL_PURCHASABLE' \n",
    "\n",
    "\n",
    "args=Args()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18832768",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)\n",
    "# formatter = logging.Formatter('%(asctime)s | %(levelname)s | %(message)s')\n",
    "formatter = logging.Formatter('%(asctime)s %(name)s %(levelname)s %(message)s')\n",
    "\n",
    "stdout_handler = logging.StreamHandler(sys.stdout)\n",
    "stdout_handler.setLevel(logging.INFO)\n",
    "stdout_handler.setFormatter(formatter)\n",
    "\n",
    "file_handler = logging.FileHandler(f'{output_folder}/logs.txt', mode='w')\n",
    "file_handler.setLevel(logging.DEBUG)\n",
    "file_handler.setFormatter(formatter)\n",
    "\n",
    "logger.addHandler(file_handler)\n",
    "logger.addHandler(stdout_handler)\n",
    "\n",
    "\n",
    "# logging.basicConfig(\n",
    "# #     stream=sys.stdout,\n",
    "#     filename=logname,\n",
    "#     level=logging.DEBUG,\n",
    "#     format=\"%(asctime)s %(name)s %(levelname)s %(message)s\",\n",
    "#     filemode=\"w\",\n",
    "# )\n",
    "# logging.getLogger().info(args)\n",
    "\n",
    "# Load all SMILES to test\n",
    "test_smiles = get_target_smiles(args.paroutes_n)\n",
    "\n",
    "## Test on smaller dataset\n",
    "test_smiles_all = test_smiles.copy()\n",
    "dim_test = 100\n",
    "test_smiles = test_smiles_all[:dim_test]\n",
    "##\n",
    "\n",
    "if args.limit_num_smiles is not None:\n",
    "    test_smiles = test_smiles[: args.limit_num_smiles]\n",
    "\n",
    "# Make reaction model, inventory, cost functions and value functions\n",
    "if args.and_node_cost_fn == 'PAROUTES':\n",
    "    and_node_cost_fn=PaRoutesRxnCost()\n",
    "else:\n",
    "    raise NotImplementedError(f'and_node_cost_fn: {args.and_node_cost_fn}')\n",
    "\n",
    "if args.or_node_cost_fn == 'MOL_PURCHASABLE':\n",
    "    or_node_cost_fn=MolIsPurchasableCost()\n",
    "else:\n",
    "    raise NotImplementedError(f'and_node_cost_fn: {args.or_node_cost_fn}')\n",
    "\n",
    "if args.inventory == 'PAROUTES':\n",
    "    inventory=PaRoutesInventory(n=args.paroutes_n)\n",
    "else:\n",
    "    raise NotImplementedError(f'and_node_cost_fn: {args.inventory}')\n",
    "\n",
    "if args.rxn_model == 'PAROUTES':\n",
    "    rxn_model=PaRoutesModel(max_num_templates=args.max_num_templates)\n",
    "else:\n",
    "    raise NotImplementedError(f'and_node_cost_fn: {args.rxn_model}')\n",
    "\n",
    "# rxn_model = PaRoutesModel(max_num_templates=args.max_num_templates)\n",
    "# inventory = PaRoutesInventory(n=args.paroutes_n)\n",
    "\n",
    "# and_node_cost_fn=PaRoutesRxnCost()\n",
    "# or_node_cost_fn = MolIsPurchasableCost()\n",
    "\n",
    "value_fns = [\n",
    "    (\"constant-0\", ConstantNodeEvaluator(0.0)),\n",
    "    (\n",
    "        \"Tanimoto-distance\",\n",
    "        TanimotoNNCostEstimator(\n",
    "            inventory=inventory, distance_to_cost=DistanceToCost.NOTHING\n",
    "        ),\n",
    "    ),\n",
    "    (\n",
    "        \"Tanimoto-distance-TIMES10\",\n",
    "        TanimotoNNCostEstimator(\n",
    "            inventory=inventory, distance_to_cost=DistanceToCost.TIMES10\n",
    "        ),\n",
    "    ),\n",
    "    (\n",
    "        \"Tanimoto-distance-TIMES100\",\n",
    "        TanimotoNNCostEstimator(\n",
    "            inventory=inventory, distance_to_cost=DistanceToCost.TIMES100\n",
    "        ),\n",
    "    ),\n",
    "    (\n",
    "        \"Tanimoto-distance-EXP\",\n",
    "        TanimotoNNCostEstimator(\n",
    "            inventory=inventory, distance_to_cost=DistanceToCost.EXP\n",
    "        ),\n",
    "    ),\n",
    "    (\n",
    "        \"Tanimoto-distance-SQRT\",\n",
    "        TanimotoNNCostEstimator(\n",
    "            inventory=inventory, distance_to_cost=DistanceToCost.SQRT\n",
    "        ),\n",
    "    ),\n",
    "]\n",
    "\n",
    "labelalias = {\n",
    "    'constant-0': 'constant-0',\n",
    "    'Tanimoto-distance': 'Tanimoto',\n",
    "    'Tanimoto-distance-TIMES10': 'Tanimoto_times10',\n",
    "    'Tanimoto-distance-TIMES100': 'Tanimoto_times100',\n",
    "    'Tanimoto-distance-EXP': 'Tanimoto_exp',\n",
    "    'Tanimoto-distance-SQRT': 'Tanimoto_sqrt',\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# Run\n",
    "logger.info(f\"Start experiment {eventid}\")\n",
    "args_string = \"\"\n",
    "for attr in dir(args):\n",
    "    if not callable(getattr(args, attr)) and not attr.startswith(\"__\"):\n",
    "        args_string = args_string + \"\\n\" + (f\"{attr}: {getattr(args, attr)}\") \n",
    "logger.info(f\"Args: {args_string}\")\n",
    "# logger.info(f\"rxn_model: \", rxn_model)\n",
    "logger.info(f\"dim_test: {dim_test}\")\n",
    "\n",
    "\n",
    "import pickle\n",
    "\n",
    "result={}\n",
    "for name, fn in value_fns:\n",
    "    alg_result = run_algorithm(\n",
    "        name=name,\n",
    "        smiles_list=test_smiles, \n",
    "        value_function=fn, \n",
    "        rxn_model=rxn_model,\n",
    "        inventory=inventory,\n",
    "        and_node_cost_fn=and_node_cost_fn,\n",
    "        or_node_cost_fn=or_node_cost_fn, \n",
    "        max_expansion_depth=args.max_expansion_depth, \n",
    "        prevent_repeat_mol_in_trees=args.prevent_repeat_mol_in_trees, \n",
    "        use_tqdm=True,\n",
    "        limit_rxn_model_calls=args.limit_rxn_model_calls, \n",
    "        limit_iterations=args.limit_iterations,\n",
    "        logger=logger,\n",
    "    )\n",
    "    result[name] = alg_result\n",
    "    \n",
    "    # Save pickle\n",
    "    with open(f'{output_folder}/result_{name}.pickle', 'wb') as handle:\n",
    "        pickle.dump(alg_result, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "# result = compare_cost_functions(\n",
    "#     smiles_list=test_smiles,\n",
    "#     value_functions=value_fns,\n",
    "#     limit_rxn_model_calls=args.limit_rxn_model_calls,\n",
    "#     limit_iterations=args.limit_iterations,\n",
    "#     and_node_cost_fn=and_node_cost_fn,\n",
    "#     or_node_cost_fn=or_node_cost_fn,\n",
    "#     max_expansion_depth=args.max_expansion_depth,\n",
    "#     prevent_repeat_mol_in_trees=args.prevent_repeat_mol_in_trees,\n",
    "#     use_tqdm=True,\n",
    "#     rxn_model=rxn_model,\n",
    "#     inventory=inventory,\n",
    "#     logger=logger,\n",
    "# )\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac426b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "alg_names = [x[0] for x in value_fns]\n",
    "alg_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425c5df9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d944d1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load pickle\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "# eventid= \"202305-1412-3438-d0f3baee-c6ce-4444-830e-e38d536c9bfa\"\n",
    "# output_folder = f\"Results/{eventid}\"\n",
    "\n",
    "result = {}\n",
    "# alg_names = list()\n",
    "for file_name in [file for file in os.listdir(output_folder) if 'pickle' in file]:\n",
    "    name = file_name.replace('.pickle','').replace('result_','')\n",
    "#     alg_names = alg_names.append(name)\n",
    "    with open(f'{output_folder}/{file_name}', 'rb') as handle:\n",
    "        result[name] = pickle.load(handle)\n",
    "\n",
    "# alg_names = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7256f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce35b3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def create_result_df(result, name):\n",
    "    assert name == result[name].name, f\"name: {name} is different from result[name].name: {result[name].name}\"\n",
    "    \n",
    "    soln_time_dict = result[name].soln_time_dict\n",
    "    num_different_routes_dict = result[name].num_different_routes_dict\n",
    "    final_num_rxn_model_calls_dict = result[name].final_num_rxn_model_calls_dict\n",
    "    output_graph_dict = result[name].output_graph_dict\n",
    "    routes_dict = result[name].routes_dict\n",
    "\n",
    "    # df_results = pd.DataFrame()\n",
    "    df_soln_time = pd.DataFrame({'algorithm': [], 'similes': [], 'property':[], 'value': []})\n",
    "    df_different_routes = pd.DataFrame({'algorithm': [], 'similes': [], 'property':[], 'value': []})\n",
    "\n",
    "    #     for name_alg, value_dict  in soln_time_dict.items():\n",
    "    for smiles, value  in soln_time_dict.items():\n",
    "        row_soln_time = {'algorithm': name, 'similes': smiles, 'property':'sol_time', 'value': value}\n",
    "\n",
    "        df_soln_time = pd.concat([df_soln_time, pd.DataFrame([row_soln_time])], ignore_index=True)\n",
    "\n",
    "    #     for name_alg, value_dict  in num_different_routes_dict.items():\n",
    "    for smiles, value  in num_different_routes_dict.items():\n",
    "        row_different_routes = {'algorithm': name, 'similes': smiles, 'property':'diff_routes', 'value': value}\n",
    "\n",
    "        df_different_routes = pd.concat([df_different_routes, pd.DataFrame([row_different_routes])], ignore_index=True)\n",
    "\n",
    "    df_results_tot = pd.concat([df_soln_time, df_different_routes], axis=0)\n",
    "    return df_results_tot\n",
    "\n",
    "\n",
    "\n",
    "df_results_tot = pd.DataFrame({'algorithm': [], 'similes': [], 'property':[], 'value': []})\n",
    "for name in result.keys():\n",
    "    df_results_alg = create_result_df(result, name)\n",
    "    df_results_tot = pd.concat([df_results_tot, df_results_alg], axis=0)\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec8df8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951d4730",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b926ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2797b8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # result_const_list = [x[0] for x in result_const_and_tan_nothing]\n",
    "# # results_tan_nothing_list = [x[1] for x in result_const_and_tan_nothing]\n",
    "# # result_tan_exp_list = [x[0] for x in result_tan_exp_and_square]\n",
    "# # result_tan_square_list = [x[1] for x in result_tan_exp_and_square]\n",
    "\n",
    "\n",
    "\n",
    "# import pandas as pd\n",
    "\n",
    "# df_results = pd.DataFrame({'const': result_const_list,\n",
    "#                            'tanimoto': results_tan_nothing_list,\n",
    "#                            'tanimoto_exp': result_tan_exp_list,\n",
    "#                            'tanimoto_square': result_tan_square_list\n",
    "#                           })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2893ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_results_is_inf['smiles'] = test_smiles\n",
    "# df_results['smiles'] = test_smiles\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85028c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to csv\n",
    "# df_results_tot.to_csv(f'Results/Compare/compare_times_{dim_test}.csv', index=False)\n",
    "df_results_tot.to_csv(f'{output_folder}/results_all.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793fac5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650369f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# eventid= \"202305-1310-3717-7e7e984c-8c3e-4a18-ad67-5c4b29743282\"\n",
    "# output_folder = f\"Results/{eventid}\"\n",
    "\n",
    "df_results_tot = pd.read_csv(f'{output_folder}/results_all.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbfceb9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4255cdd5",
   "metadata": {},
   "source": [
    "## Solution times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebfe600",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_solution_times = df_results_tot.loc[df_results_tot['property']=='sol_time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687699fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = results_solution_times.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f29d139",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result[\"value_is_inf\"] = (df_result['value'] == np.inf) * 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bfe77cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_grouped = df_result.groupby([\"algorithm\", \"property\"], as_index=False).agg(nr_mol_not_solved=pd.NamedAgg(column=\"value_is_inf\", aggfunc=\"sum\"))\n",
    "df_results_grouped\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dbd13b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_grouped.to_csv(f'{output_folder}/num_mol_not_solved.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae35d57",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "fig = px.box(df_result, x=\"algorithm\", y=\"value\", width=1000, height=600,\n",
    "             labels={\n",
    "#                      \"algorithm\": None,\n",
    "                     \"value\": \"Time to first solution\",\n",
    "#                      \"species\": \"Species of Iris\"\n",
    "                 },\n",
    "#              title=\"Time to first solution\"\n",
    "            )\n",
    "fig.update_layout(xaxis_title=None)\n",
    "fig.update_xaxes(labelalias=labelalias, categoryorder='array', categoryarray=list(labelalias.keys()))\n",
    "fig.write_image(f'{output_folder}/Boxplot_time_first_solution.png') \n",
    "fig.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23311fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82c4346",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9505fa87",
   "metadata": {},
   "source": [
    "## Solution diversity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fbf4417",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_diff_routes = df_results_tot.loc[df_results_tot['property']=='diff_routes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62ce5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = results_diff_routes.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9ca587",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result[\"value_is_zero\"] = (df_result['value'] == 0) * 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df368b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_grouped = df_result.groupby([\"algorithm\", \"property\"], as_index=False).agg(nr_mol_not_solved=pd.NamedAgg(column=\"value_is_zero\", aggfunc=\"sum\"))\n",
    "df_results_grouped\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf374b3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "fig = px.box(df_result, x=\"algorithm\", y=\"value\", width=1000, height=600,\n",
    "             labels={\n",
    "#                      \"algorithm\": None,\n",
    "                     \"value\": \"Number of different routes\",\n",
    "#                      \"species\": \"Species of Iris\"\n",
    "                 },\n",
    "#              title=\"Number of different routes\"\n",
    "            )\n",
    "fig.update_layout(xaxis_title=None)\n",
    "fig.update_xaxes(labelalias=labelalias, categoryorder='array', categoryarray=list(labelalias.keys()))\n",
    "fig.write_image(f'{output_folder}/Boxplot_num_different_routes.png')\n",
    "fig.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b16b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.box(df_result.loc[df_result['value']!=0], x=\"algorithm\", y=\"value\", \n",
    "             width=1000, height=600,\n",
    "             labels={\n",
    "#                      \"algorithm\": None,\n",
    "                     \"value\": \"Number of different routes (removing zeros)\",\n",
    "#                      \"species\": \"Species of Iris\"\n",
    "                 },\n",
    "#              title=\"Number of different routes (removing zeros)\"\n",
    "            )\n",
    "# fig.update_layout(\n",
    "#     xaxis = {\n",
    "#     'tickwidth' : %number in px\n",
    "#     }\n",
    "# )\n",
    "fig.update_layout(xaxis_title=None)\n",
    "fig.update_xaxes(labelalias=labelalias, categoryorder='array', categoryarray=list(labelalias.keys()))\n",
    "fig.write_image(f'{output_folder}/Boxplot_num_different_routes_no_zero.png') \n",
    "fig.show() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f09c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_results_is_inf = (df_results == np.inf) * 1\n",
    "# print(df_results_is_inf.sum(axis=0))\n",
    "# df_results_is_inf['count_inf'] = df_results_is_inf.sum(axis=1)\n",
    "# df_results_is_inf['smiles'] = df_results['smiles']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5261e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# df_results_is_inf.loc[(df_results_is_inf['count_inf']>0) & (df_results_is_inf['count_inf']<3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc988b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618e7c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_results_not_inf = df_results[~df_results.isin([np.nan, np.inf, -np.inf]).any(axis=1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18feab1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import plotly.graph_objects as go\n",
    "# # import plotly.offline as pyo\n",
    "# # pyo.init_notebook_mode()\n",
    "# fig = go.Figure()\n",
    "\n",
    "# for col in df_results_not_inf:\n",
    "#     if col != 'smiles':\n",
    "#         fig.add_trace(go.Box(y=df_results_not_inf[col].values, name=df_results_not_inf[col].name))\n",
    "\n",
    "# fig.update_layout(\n",
    "#     title=\"Boxplot\",\n",
    "#     xaxis_title=\"Method\",\n",
    "#     yaxis_title=\"Min solution time of solved target molecules\",\n",
    "#     legend_title=\"Value function\",\n",
    "# #     font=dict(\n",
    "# #         family=\"Courier New, monospace\",\n",
    "# #         size=18,\n",
    "# #         color=\"RebeccaPurple\"\n",
    "# #     )\n",
    "# )        \n",
    "# fig.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec481165",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.boxplot([df_results_not_inf['const'], df_results_not_inf['tanimoto'], df_results_not_inf['tanimoto_exp']])\n",
    "# ax.set_xticklabels(['const', 'tanimoto', 'tanimoto_exp'])\n",
    "# ax.set_xlabel('Method')\n",
    "# ax.set_ylabel('Min solution time of solved target molecules')\n",
    "# ax.set_title('Boxplot')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65098c34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8809f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52f1f8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8730a560",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

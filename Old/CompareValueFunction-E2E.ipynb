{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3179f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !export PYTHONPATH=/Users/ilariasartori/syntheseus:/Users/ilariasartori/syntheseus/tutorials/search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0859e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !echo $PYTHONPATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b11cd69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from uuid import uuid4\n",
    "import os\n",
    "\n",
    "eventid = datetime.now().strftime('%Y%m-%d%H-%M%S-') + str(uuid4())\n",
    "print(eventid)\n",
    "\n",
    "output_folder = f\"Results/{eventid}\"\n",
    "\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d9e5c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96d1c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Basic code for nearest-neighbour value functions.\"\"\"\n",
    "from __future__ import annotations\n",
    "\n",
    "from enum import Enum\n",
    "\n",
    "import numpy as np\n",
    "from rdkit.Chem import DataStructs, AllChem\n",
    "\n",
    "from syntheseus.search.graph.and_or import OrNode\n",
    "from syntheseus.search.node_evaluation.base import NoCacheNodeEvaluator\n",
    "from syntheseus.search.mol_inventory import ExplicitMolInventory\n",
    "\n",
    "# from Users.ilariasartori.syntheseus.search.graph.and_or import OrNode\n",
    "\n",
    "\n",
    "class DistanceToCost(Enum):\n",
    "    NOTHING = 0\n",
    "    EXP = 1\n",
    "    SQRT = 2\n",
    "    TIMES10 = 3\n",
    "    TIMES100 = 4\n",
    "    NUM_NEIGHBORS_TO_06 = 5\n",
    "\n",
    "\n",
    "class TanimotoNNCostEstimator(NoCacheNodeEvaluator):\n",
    "    \"\"\"Estimates cost of a node using Tanimoto distance to purchasable molecules.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        inventory: ExplicitMolInventory,\n",
    "        distance_to_cost: DistanceToCost,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__(**kwargs)\n",
    "        self.distance_to_cost = distance_to_cost\n",
    "        self._set_fingerprints([mol.smiles for mol in inventory.purchasable_mols()])\n",
    "\n",
    "    def get_fingerprint(self, mol: AllChem.Mol):\n",
    "        return AllChem.GetMorganFingerprint(mol, radius=3)\n",
    "\n",
    "    def _set_fingerprints(self, smiles_list: list[str]) -> None:\n",
    "        \"\"\"Initialize fingerprint cache.\"\"\"\n",
    "        mols = list(map(AllChem.MolFromSmiles, smiles_list))\n",
    "        assert None not in mols, \"Invalid SMILES encountered.\"\n",
    "        self._fps = list(map(self.get_fingerprint, mols))\n",
    "        \n",
    "    def find_min_num_elem_summing_to_threshold(array, threshold):\n",
    "        # Sort the array in ascending order\n",
    "        sorted_array = np.sort(array)\n",
    "\n",
    "        # Calculate the cumulative sum of the sorted array\n",
    "        cum_sum = np.cumsum(sorted_array)\n",
    "\n",
    "        # Find the index where the cumulative sum exceeds threshold \n",
    "        index = np.searchsorted(cum_sum, threshold)\n",
    "\n",
    "        # Check if a subset of elements sums up to more than threshold\n",
    "        if index < len(array):\n",
    "            return index + 1  # Add 1 to account for 0-based indexing\n",
    "\n",
    "        # If no subset of elements sums up to more than threshold\n",
    "        return 2.0*len(array) #-1\n",
    "\n",
    "    def _get_nearest_neighbour_dist(self, smiles: str) -> float:\n",
    "        fp_query = self.get_fingerprint(AllChem.MolFromSmiles(smiles))\n",
    "        tanimoto_sims = DataStructs.BulkTanimotoSimilarity(fp_query, self._fps)\n",
    "        if self.distance_to_cost == DistanceToCost.NUM_NEIGHBORS_TO_06:\n",
    "            return find_min_num_elem_summing_to_threshold(tanimoto_sims, 0.6)/ len(tanimoto_sims)\n",
    "        else:\n",
    "            return 1 - max(tanimoto_sims)\n",
    "\n",
    "    def _evaluate_nodes(self, nodes: list[OrNode], graph=None) -> list[float]:\n",
    "        if len(nodes) == 0:\n",
    "            return []\n",
    "\n",
    "        # Get distances to nearest neighbours\n",
    "        nn_dists = np.asarray(\n",
    "            [self._get_nearest_neighbour_dist(node.mol.smiles) for node in nodes]\n",
    "        )\n",
    "        assert np.min(nn_dists) >= 0\n",
    "\n",
    "        # Turn into costs\n",
    "        if self.distance_to_cost == DistanceToCost.NOTHING:\n",
    "            values = nn_dists\n",
    "        elif self.distance_to_cost == DistanceToCost.EXP:\n",
    "            values = np.exp(nn_dists) - 1\n",
    "        elif self.distance_to_cost == DistanceToCost.SQRT:\n",
    "            values = np.sqrt(nn_dists) \n",
    "        elif self.distance_to_cost == DistanceToCost.TIMES10:\n",
    "            values = 10.0*nn_dists\n",
    "        elif self.distance_to_cost == DistanceToCost.TIMES100:\n",
    "            values = 100.0*nn_dists\n",
    "        elif self.distance_to_cost == DistanceToCost.NUM_NEIGHBORS_TO_06:\n",
    "            values = nn_dists\n",
    "        else:\n",
    "            raise NotImplementedError(self.distance_to_cost)\n",
    "\n",
    "        return list(values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9d9368",
   "metadata": {},
   "outputs": [],
   "source": [
    "route_div = True # Count number of diverse routes found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9be200",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Demo script comparing nearest neighbour cost function with constant value function on PaRoutes.\n",
    "\"\"\"\n",
    "from __future__ import annotations\n",
    "\n",
    "import argparse\n",
    "import logging\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from syntheseus.search.chem import Molecule\n",
    "from syntheseus.search.graph.and_or import AndNode\n",
    "from syntheseus.search.algorithms.best_first.retro_star import RetroStarSearch, MolIsPurchasableCost\n",
    "from syntheseus.search.analysis.solution_time import get_first_solution_time\n",
    "from syntheseus.search.analysis.route_extraction import min_cost_routes\n",
    "from syntheseus.search.reaction_models.base import BackwardReactionModel\n",
    "from syntheseus.search.mol_inventory import BaseMolInventory\n",
    "from syntheseus.search.node_evaluation.base import (\n",
    "    BaseNodeEvaluator,\n",
    "    NoCacheNodeEvaluator,\n",
    ")\n",
    "from syntheseus.search.node_evaluation.common import ConstantNodeEvaluator\n",
    "\n",
    "from paroutes import PaRoutesInventory, PaRoutesModel, get_target_smiles\n",
    "# from neighbour_value_functions import TanimotoNNCostEstimator, DistanceToCost\n",
    "\n",
    "from syntheseus.search.analysis import diversity\n",
    "# from syntheseus.search.algorithms.best_first.retro_star import MolIsPurchasableCost\n",
    "\n",
    "class SearchResult:\n",
    "    def __init__(self, name, soln_time_dict, num_different_routes_dict, \n",
    "                 final_num_rxn_model_calls_dict, output_graph_dict, routes_dict):\n",
    "        self.name = name\n",
    "        self.soln_time_dict = soln_time_dict\n",
    "        self.num_different_routes_dict = num_different_routes_dict\n",
    "        self.final_num_rxn_model_calls_dict = final_num_rxn_model_calls_dict\n",
    "        self.output_graph_dict = output_graph_dict\n",
    "        self.routes_dict = routes_dict\n",
    "\n",
    "\n",
    "class PaRoutesRxnCost(NoCacheNodeEvaluator[AndNode]):\n",
    "    \"\"\"Cost of reaction is negative log softmax, floored at -3.\"\"\"\n",
    "\n",
    "    def _evaluate_nodes(self, nodes: list[AndNode], graph=None) -> list[float]:\n",
    "        softmaxes = np.asarray([node.reaction.metadata[\"softmax\"] for node in nodes])\n",
    "        costs = np.clip(-np.log(softmaxes), 1e-1, 10.0)\n",
    "        return costs.tolist()\n",
    "\n",
    "\n",
    "def run_algorithm(\n",
    "    name: str,\n",
    "    smiles_list: list[str],\n",
    "    value_function: BaseNodeEvaluator,\n",
    "    rxn_model: BackwardReactionModel,\n",
    "    inventory: BaseMolInventory,\n",
    "    and_node_cost_fn: BaseNodeEvaluator[AndNode],\n",
    "    or_node_cost_fn: BaseNodeEvaluator[OrNode],\n",
    "    max_expansion_depth: int = 15,\n",
    "    prevent_repeat_mol_in_trees: bool= True,\n",
    "    use_tqdm: bool = False,\n",
    "    limit_rxn_model_calls: int = 100,\n",
    "    limit_iterations: int = 1_000_000,\n",
    "    logger: logging.RootLogger = logging.getLogger(),\n",
    ") -> SearchResult:\n",
    "    \"\"\"\n",
    "    Do search on a list of SMILES strings and report the time of first solution.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize algorithm.\n",
    "    common_kwargs = dict(\n",
    "        reaction_model=rxn_model,\n",
    "        mol_inventory=inventory,\n",
    "        limit_reaction_model_calls=limit_rxn_model_calls,\n",
    "        limit_iterations=limit_iterations,\n",
    "        max_expansion_depth=max_expansion_depth,  # prevent overly-deep solutions\n",
    "        prevent_repeat_mol_in_trees=prevent_repeat_mol_in_trees,  # original paper did this\n",
    "    )\n",
    "    alg = RetroStarSearch(\n",
    "            and_node_cost_fn=PaRoutesRxnCost(), value_function=value_function, **common_kwargs\n",
    "        )\n",
    "\n",
    "    # Do search\n",
    "    logger.info(f\"Start search with {name}\")\n",
    "    min_soln_times: list[tuple[float, ...]] = []\n",
    "    if use_tqdm:\n",
    "        smiles_iter = tqdm(smiles_list)\n",
    "    else:\n",
    "        smiles_iter = smiles_list\n",
    "        \n",
    "    output_graph_dict = {}\n",
    "    soln_time_dict = {}\n",
    "    routes_dict = {}\n",
    "    final_num_rxn_model_calls_dict = {}\n",
    "    num_different_routes_dict = {}\n",
    "    \n",
    "    for i, smiles in enumerate(smiles_iter):\n",
    "        logger.debug(f\"Start search {i}/{len(smiles_list)}. SMILES: {smiles}\")\n",
    "        this_soln_times = list()\n",
    "        alg.reset()\n",
    "        output_graph, _ = alg.run_from_mol(Molecule(smiles))\n",
    "\n",
    "        # Analyze solution time\n",
    "        for node in output_graph.nodes():\n",
    "            node.data[\"analysis_time\"] = node.data[\"num_calls_rxn_model\"]\n",
    "        soln_time = get_first_solution_time(output_graph)\n",
    "        this_soln_times.append(soln_time)\n",
    "\n",
    "        # Analyze number of routes\n",
    "        MAX_ROUTES = 10000\n",
    "        routes = list(min_cost_routes(output_graph, MAX_ROUTES))\n",
    "\n",
    "        if alg.reaction_model.num_calls() < limit_rxn_model_calls:\n",
    "            note = \" (NOTE: this was less than the maximum budget)\"\n",
    "        else:\n",
    "            note = \"\"\n",
    "        logger.debug(\n",
    "            f\"Done {name}: nodes={len(output_graph)}, solution time = {soln_time}, \"\n",
    "            f\"num routes = {len(routes)} (capped at {MAX_ROUTES}), \"\n",
    "            f\"final num rxn model calls = {alg.reaction_model.num_calls()}{note}.\"\n",
    "        )\n",
    "\n",
    "        # Analyze route diversity \n",
    "        if (len(routes)>0) & route_div:\n",
    "            route_objects = [output_graph.to_synthesis_graph(nodes) for nodes in routes]\n",
    "            packing_set = diversity.estimate_packing_number(\n",
    "                routes=route_objects,\n",
    "                distance_metric=diversity.reaction_jaccard_distance,\n",
    "                radius=0.999  # because comparison is > not >=\n",
    "            )\n",
    "            logger.debug((f\"number of distinct routes = {len(packing_set)}\"))\n",
    "        else:\n",
    "            packing_set = []\n",
    "\n",
    "        # Save results\n",
    "        soln_time_dict.update({smiles: soln_time})\n",
    "        final_num_rxn_model_calls_dict.update({smiles: alg.reaction_model.num_calls()})\n",
    "        num_different_routes_dict.update({smiles: len(packing_set)})\n",
    "        output_graph_dict.update({smiles: output_graph})\n",
    "        routes_dict.update({smiles: routes})\n",
    "            \n",
    "    return SearchResult(name=name,\n",
    "                        soln_time_dict=soln_time_dict, \n",
    "                        num_different_routes_dict=num_different_routes_dict, \n",
    "                        final_num_rxn_model_calls_dict=final_num_rxn_model_calls_dict, \n",
    "                        output_graph_dict=output_graph_dict, \n",
    "                        routes_dict=routes_dict)\n",
    "\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620f1d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arguments\n",
    "\n",
    "# COMMAND LINE\n",
    "# if __name__ == \"__main__\":\n",
    "#     parser = argparse.ArgumentParser()\n",
    "#     parser.add_argument(\n",
    "#         \"--limit_num_smiles\",\n",
    "#         type=int,\n",
    "#         default=None,\n",
    "#         help=\"Maximum number of SMILES to run.\",\n",
    "#     )\n",
    "#     parser.add_argument(\n",
    "#         \"--limit_iterations\",\n",
    "#         type=int,\n",
    "#         default=500,\n",
    "#         help=\"Maximum number of algorithm iterations.\",\n",
    "#     )\n",
    "#     parser.add_argument(\n",
    "#         \"--limit_rxn_model_calls\",\n",
    "#         type=int,\n",
    "#         default=25,\n",
    "#         help=\"Allowed number of calls to reaction model.\",\n",
    "#     )\n",
    "#     parser.add_argument(\n",
    "#         \"--paroutes_n\",\n",
    "#         type=int,\n",
    "#         default=5,\n",
    "#         help=\"Which PaRoutes benchmark to use.\",\n",
    "#     )\n",
    "#     args = parser.parse_args()\n",
    "\n",
    "# NOTEBOOK\n",
    "class Args:\n",
    "    limit_num_smiles = None\n",
    "    limit_iterations = 500\n",
    "    limit_rxn_model_calls = 100\n",
    "    paroutes_n = 5\n",
    "    max_expansion_depth = 20\n",
    "    max_num_templates = 10  # Default 50\n",
    "    prevent_repeat_mol_in_trees = True\n",
    "    rxn_model = 'PAROUTES'\n",
    "    inventory = 'PAROUTES'\n",
    "    and_node_cost_fn='PAROUTES'\n",
    "    or_node_cost_fn = 'MOL_PURCHASABLE' \n",
    "\n",
    "\n",
    "args=Args()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d16b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "alg_names = [x[0] for x in value_fns]\n",
    "alg_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98144b9",
   "metadata": {},
   "source": [
    "## Load from pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b437d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # Load pickle\n",
    "# import pickle\n",
    "# import os\n",
    "\n",
    "# # eventid= \"202305-1412-3438-d0f3baee-c6ce-4444-830e-e38d536c9bfa\"\n",
    "# # output_folder = f\"Results/{eventid}\"\n",
    "\n",
    "# result = {}\n",
    "# for file_name in [file for file in os.listdir(output_folder) if 'pickle' in file]:\n",
    "#     name = file_name.replace('.pickle','').replace('result_','')\n",
    "#     with open(f'{output_folder}/{file_name}', 'rb') as handle:\n",
    "#         result[name] = pickle.load(handle)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0e8c5e",
   "metadata": {},
   "source": [
    "## Create dataframe for time to solution and number of routes found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18832768",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)\n",
    "# formatter = logging.Formatter('%(asctime)s | %(levelname)s | %(message)s')\n",
    "formatter = logging.Formatter('%(asctime)s %(name)s %(levelname)s %(message)s')\n",
    "\n",
    "stdout_handler = logging.StreamHandler(sys.stdout)\n",
    "stdout_handler.setLevel(logging.INFO)\n",
    "stdout_handler.setFormatter(formatter)\n",
    "\n",
    "file_handler = logging.FileHandler(f'{output_folder}/logs.txt', mode='w')\n",
    "file_handler.setLevel(logging.DEBUG)\n",
    "file_handler.setFormatter(formatter)\n",
    "\n",
    "logger.addHandler(file_handler)\n",
    "logger.addHandler(stdout_handler)\n",
    "\n",
    "\n",
    "# Load all SMILES to test\n",
    "test_smiles = get_target_smiles(args.paroutes_n)\n",
    "\n",
    "## Test on smaller dataset\n",
    "test_smiles_all = test_smiles.copy()\n",
    "dim_test = 100\n",
    "test_smiles = test_smiles_all[:dim_test]\n",
    "##\n",
    "\n",
    "if args.limit_num_smiles is not None:\n",
    "    test_smiles = test_smiles[: args.limit_num_smiles]\n",
    "\n",
    "# Make reaction model, inventory, cost functions and value functions\n",
    "if args.and_node_cost_fn == 'PAROUTES':\n",
    "    and_node_cost_fn=PaRoutesRxnCost()\n",
    "else:\n",
    "    raise NotImplementedError(f'and_node_cost_fn: {args.and_node_cost_fn}')\n",
    "\n",
    "if args.or_node_cost_fn == 'MOL_PURCHASABLE':\n",
    "    or_node_cost_fn=MolIsPurchasableCost()\n",
    "else:\n",
    "    raise NotImplementedError(f'or_node_cost_fn: {args.or_node_cost_fn}')\n",
    "\n",
    "if args.inventory == 'PAROUTES':\n",
    "    inventory=PaRoutesInventory(n=args.paroutes_n)\n",
    "else:\n",
    "    raise NotImplementedError(f'inventory: {args.inventory}')\n",
    "\n",
    "if args.rxn_model == 'PAROUTES':\n",
    "    rxn_model=PaRoutesModel(max_num_templates=args.max_num_templates)\n",
    "else:\n",
    "    raise NotImplementedError(f'rxn_model: {args.rxn_model}')\n",
    "\n",
    "\n",
    "value_fns = [\n",
    "#     (\"constant-0\", ConstantNodeEvaluator(0.0)),\n",
    "#     (\n",
    "#         \"Tanimoto-distance\",\n",
    "#         TanimotoNNCostEstimator(\n",
    "#             inventory=inventory, distance_to_cost=DistanceToCost.NOTHING\n",
    "#         ),\n",
    "#     ),\n",
    "#     (\n",
    "#         \"Tanimoto-distance-TIMES10\",\n",
    "#         TanimotoNNCostEstimator(\n",
    "#             inventory=inventory, distance_to_cost=DistanceToCost.TIMES10\n",
    "#         ),\n",
    "#     ),\n",
    "# #     (\n",
    "# #         \"Tanimoto-distance-TIMES100\",\n",
    "# #         TanimotoNNCostEstimator(\n",
    "# #             inventory=inventory, distance_to_cost=DistanceToCost.TIMES100\n",
    "# #         ),\n",
    "# #     ),\n",
    "#     (\n",
    "#         \"Tanimoto-distance-EXP\",\n",
    "#         TanimotoNNCostEstimator(\n",
    "#             inventory=inventory, distance_to_cost=DistanceToCost.EXP\n",
    "#         ),\n",
    "#     ),\n",
    "#     (\n",
    "#         \"Tanimoto-distance-SQRT\",\n",
    "#         TanimotoNNCostEstimator(\n",
    "#             inventory=inventory, distance_to_cost=DistanceToCost.SQRT\n",
    "#         ),\n",
    "#     ),\n",
    "    (\n",
    "        \"Tanimoto-distance-NUM_NEIGHBORS_TO_06\",\n",
    "        TanimotoNNCostEstimator(\n",
    "            inventory=inventory, distance_to_cost=DistanceToCost.NUM_NEIGHBORS_TO_06\n",
    "        ),\n",
    "    ),\n",
    "]\n",
    "\n",
    "labelalias = {\n",
    "    'constant-0': 'constant-0',\n",
    "    'Tanimoto-distance': 'Tanimoto',\n",
    "    'Tanimoto-distance-TIMES10': 'Tanimoto_times10',\n",
    "    'Tanimoto-distance-TIMES100': 'Tanimoto_times100',\n",
    "    'Tanimoto-distance-EXP': 'Tanimoto_exp',\n",
    "    'Tanimoto-distance-SQRT': 'Tanimoto_sqrt',\n",
    "    \"Tanimoto-distance-NUM_NEIGHBORS_TO_06\": \"Tanimoto_nn_to_06\",\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# Run\n",
    "logger.info(f\"Start experiment {eventid}\")\n",
    "args_string = \"\"\n",
    "for attr in dir(args):\n",
    "    if not callable(getattr(args, attr)) and not attr.startswith(\"__\"):\n",
    "        args_string = args_string + \"\\n\" + (f\"{attr}: {getattr(args, attr)}\") \n",
    "logger.info(f\"Args: {args_string}\")\n",
    "logger.info(f\"dim_test: {dim_test}\")\n",
    "\n",
    "\n",
    "import pickle\n",
    "\n",
    "result={}\n",
    "for name, fn in value_fns:\n",
    "    alg_result = run_algorithm(\n",
    "        name=name,\n",
    "        smiles_list=test_smiles, \n",
    "        value_function=fn, \n",
    "        rxn_model=rxn_model,\n",
    "        inventory=inventory,\n",
    "        and_node_cost_fn=and_node_cost_fn,\n",
    "        or_node_cost_fn=or_node_cost_fn, \n",
    "        max_expansion_depth=args.max_expansion_depth, \n",
    "        prevent_repeat_mol_in_trees=args.prevent_repeat_mol_in_trees, \n",
    "        use_tqdm=True,\n",
    "        limit_rxn_model_calls=args.limit_rxn_model_calls, \n",
    "        limit_iterations=args.limit_iterations,\n",
    "        logger=logger,\n",
    "    )\n",
    "    result[name] = alg_result\n",
    "    \n",
    "    # Save pickle\n",
    "    with open(f'{output_folder}/result_{name}.pickle', 'wb') as handle:\n",
    "        pickle.dump(alg_result, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce35b3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def create_result_df(result, name):\n",
    "    assert name == result[name].name, f\"name: {name} is different from result[name].name: {result[name].name}\"\n",
    "    \n",
    "    soln_time_dict = result[name].soln_time_dict\n",
    "    num_different_routes_dict = result[name].num_different_routes_dict\n",
    "    final_num_rxn_model_calls_dict = result[name].final_num_rxn_model_calls_dict\n",
    "    output_graph_dict = result[name].output_graph_dict\n",
    "    routes_dict = result[name].routes_dict\n",
    "\n",
    "    # df_results = pd.DataFrame()\n",
    "    df_soln_time = pd.DataFrame({'algorithm': [], 'similes': [], 'property':[], 'value': []})\n",
    "    df_different_routes = pd.DataFrame({'algorithm': [], 'similes': [], 'property':[], 'value': []})\n",
    "\n",
    "    #     for name_alg, value_dict  in soln_time_dict.items():\n",
    "    for smiles, value  in soln_time_dict.items():\n",
    "        row_soln_time = {'algorithm': name, 'similes': smiles, 'property':'sol_time', 'value': value}\n",
    "\n",
    "        df_soln_time = pd.concat([df_soln_time, pd.DataFrame([row_soln_time])], ignore_index=True)\n",
    "\n",
    "    #     for name_alg, value_dict  in num_different_routes_dict.items():\n",
    "    for smiles, value  in num_different_routes_dict.items():\n",
    "        row_different_routes = {'algorithm': name, 'similes': smiles, 'property':'diff_routes', 'value': value}\n",
    "\n",
    "        df_different_routes = pd.concat([df_different_routes, pd.DataFrame([row_different_routes])], ignore_index=True)\n",
    "\n",
    "    df_results_tot = pd.concat([df_soln_time, df_different_routes], axis=0)\n",
    "    return df_results_tot\n",
    "\n",
    "\n",
    "\n",
    "df_results_tot = pd.DataFrame({'algorithm': [], 'similes': [], 'property':[], 'value': []})\n",
    "for name in result.keys():\n",
    "    df_results_alg = create_result_df(result, name)\n",
    "    df_results_tot = pd.concat([df_results_tot, df_results_alg], axis=0)\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b4c8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85028c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to csv\n",
    "# df_results_tot.to_csv(f'Results/Compare/compare_times_{dim_test}.csv', index=False)\n",
    "df_results_tot.to_csv(f'{output_folder}/results_all.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa13598b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650369f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# eventid= \"202305-1310-3717-7e7e984c-8c3e-4a18-ad67-5c4b29743282\"\n",
    "# output_folder = f\"Results/{eventid}\"\n",
    "\n",
    "df_results_tot = pd.read_csv(f'{output_folder}/results_all.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbfb30a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fb1f57e3",
   "metadata": {},
   "source": [
    "### 1. Solution times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c4ace5",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_solution_times = df_results_tot.loc[df_results_tot['property']=='sol_time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9dbe0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = results_solution_times.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fbdfc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result[\"value_is_inf\"] = (df_result['value'] == np.inf) * 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6bca23",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_grouped = df_result.groupby([\"algorithm\", \"property\"], as_index=False).agg(nr_mol_not_solved=pd.NamedAgg(column=\"value_is_inf\", aggfunc=\"sum\"))\n",
    "df_results_grouped\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20e2302",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_grouped.to_csv(f'{output_folder}/num_mol_not_solved.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f41bbc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "fig = px.box(df_result, x=\"algorithm\", y=\"value\", width=1000, height=600,\n",
    "             labels={\n",
    "#                      \"algorithm\": None,\n",
    "                     \"value\": \"Time to first solution\",\n",
    "#                      \"species\": \"Species of Iris\"\n",
    "                 },\n",
    "#              title=\"Time to first solution\"\n",
    "            )\n",
    "fig.update_layout(xaxis_title=None)\n",
    "fig.update_xaxes(labelalias=labelalias, categoryorder='array', categoryarray=list(labelalias.keys()))\n",
    "fig.write_image(f'{output_folder}/Boxplot_time_first_solution.png') \n",
    "fig.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c45617f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22765a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8338d686",
   "metadata": {},
   "source": [
    "### 2. Solution diversity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949081f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_diff_routes = df_results_tot.loc[df_results_tot['property']=='diff_routes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98aac56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = results_diff_routes.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d369fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result[\"value_is_zero\"] = (df_result['value'] == 0) * 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdfd569e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_grouped = df_result.groupby([\"algorithm\", \"property\"], as_index=False).agg(nr_mol_not_solved=pd.NamedAgg(column=\"value_is_zero\", aggfunc=\"sum\"))\n",
    "df_results_grouped\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140b7f55",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "fig = px.box(df_result, x=\"algorithm\", y=\"value\", width=1000, height=600,\n",
    "             labels={\n",
    "                     \"value\": \"Number of different routes\",\n",
    "                 },\n",
    "            )\n",
    "fig.update_layout(xaxis_title=None)\n",
    "fig.update_xaxes(labelalias=labelalias, categoryorder='array', categoryarray=list(labelalias.keys()))\n",
    "fig.write_image(f'{output_folder}/Boxplot_num_different_routes.png')\n",
    "fig.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26d63fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.box(df_result.loc[df_result['value']!=0], x=\"algorithm\", y=\"value\", \n",
    "             width=1000, height=600,\n",
    "             labels={\n",
    "                     \"value\": \"Number of different routes (removing zeros)\",\n",
    "                 },\n",
    "            )\n",
    "\n",
    "fig.update_layout(xaxis_title=None)\n",
    "fig.update_xaxes(labelalias=labelalias, categoryorder='array', categoryarray=list(labelalias.keys()))\n",
    "fig.write_image(f'{output_folder}/Boxplot_num_different_routes_no_zero.png') \n",
    "fig.show() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65098c34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "13d6377b",
   "metadata": {},
   "source": [
    "## Correlation: value function - actual cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f75c350",
   "metadata": {},
   "outputs": [],
   "source": [
    "# algs_to_consider = list(result.keys())\n",
    "algs_to_consider = ['Tanimoto-distance-TIMES10']\n",
    "\n",
    "algs_string = '_'.join(algs_to_consider)\n",
    "algs_string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86330db3",
   "metadata": {},
   "source": [
    "### 1. Assign costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14ac831",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "cost_type = \"cost_1_react\"\n",
    "# cost_type = \"cost_react_from_data\"\n",
    "# cost_type = \"cost_react_from_data_pow01\"\n",
    "\n",
    "for name in algs_to_consider:    \n",
    "    if cost_type == \"cost_1_react\": \n",
    "        for target_smiles, graph in result[name].output_graph_dict.items():\n",
    "            for node in graph._graph.nodes():\n",
    "                    if isinstance(node, (AndNode,)):\n",
    "                        node.data[\"route_cost\"] = 1.0\n",
    "                    else:\n",
    "                        node.data[\"route_cost\"] = 0.0\n",
    "    elif cost_type == \"cost_react_from_data\": \n",
    "        for target_smiles, graph in result[name].output_graph_dict.items():   \n",
    "#             # 1. Set reaction costs (should be already done by the algorithm)\n",
    "#             and_nodes=[\n",
    "#                     node\n",
    "#                     for node in graph._graph.nodes()\n",
    "#                     if isinstance(node, AndNode) and \"retro_star_rxn_cost\" not in node.data\n",
    "#                 ]\n",
    "#             costs = and_node_cost_fn(and_nodes, graph=graph)\n",
    "#             assert len(costs) == len(and_nodes)\n",
    "#             for node, cost in zip(and_nodes, costs):\n",
    "#                 node.data[\"retro_star_rxn_cost\"] = cost\n",
    "            # 2. Set route costs equal to reaction costs\n",
    "            for node in graph._graph.nodes():\n",
    "                    if isinstance(node, (AndNode,)):\n",
    "                        node.data[\"route_cost\"] = node.data[\"retro_star_rxn_cost\"]\n",
    "                    else:\n",
    "                        node.data[\"route_cost\"] = 0.0\n",
    "    elif cost_type == \"cost_react_from_data_pow01\": \n",
    "        for target_smiles, graph in result[name].output_graph_dict.items():   \n",
    "            for node in graph._graph.nodes():\n",
    "                    if isinstance(node, (AndNode,)):\n",
    "                        node.data[\"route_cost\"] = np.power(node.data[\"retro_star_rxn_cost\"], 0.1)\n",
    "                    else:\n",
    "                        node.data[\"route_cost\"] = 0.0\n",
    "\n",
    "\n",
    "    else:\n",
    "        raise NotImplementedError(f'Cost type {cost_type}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e2c807",
   "metadata": {},
   "source": [
    "### 2. Create dataframe with values and costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d055b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from syntheseus.search.analysis import route_extraction\n",
    "from syntheseus.search import visualization\n",
    "from syntheseus.search.analysis.route_extraction import _min_route_cost, _min_route_partial_cost\n",
    "import networkx as nx\n",
    "\n",
    "import heapq\n",
    "import math\n",
    "from collections.abc import Collection, Iterator\n",
    "from typing import Callable, Optional, TypeVar\n",
    "\n",
    "# def get_descendants(graph, node):\n",
    "#     descendants_set = set(graph.successors(node))\n",
    "#     for graph.successors(node)\n",
    "\n",
    "\n",
    "def custom_cost_min_route(\n",
    "    graph: RetrosynthesisSearchGraph,\n",
    "    start_node,\n",
    "    cost_fn: Callable[[Collection[NodeType], RetrosynthesisSearchGraph[NodeType]], float],\n",
    "    cost_lower_bound: Callable[[Collection[NodeType], RetrosynthesisSearchGraph[NodeType]], float],\n",
    "    max_routes: int,\n",
    "    yield_partial_routes: bool = False,\n",
    ") -> Iterator[tuple[float, Collection[NodeType]]]:\n",
    "    \"\"\"\n",
    "    Iterator over the minimal trees (routes) with lowest cost.\n",
    "    This can be done efficiently given a lower bound on the cost.\n",
    "\n",
    "    NOTE: it is not clear whether this function is the best way to extract routes,\n",
    "    and if in general it is guaranteed to not return the same route twice. We think\n",
    "    this is the case but are not sure in general.\n",
    "\n",
    "    Args:\n",
    "        graph: graph to iterate over. Could be tree, but does not need to be.\n",
    "        cost_fn: Gives the cost of a route (specified by the set of nodes).\n",
    "            A cost of inf means the route will not be returned.\n",
    "        cost_lower_bound: A lower bound of the cost. The lower bound means that\n",
    "            if the function is evaluated on a set A, the cost of a set B >= A\n",
    "            will always exceed this lower bound.\n",
    "            This function will always be evaluated on partial routes.\n",
    "        max_routes: Maximum number of routes to return.\n",
    "        yield_partial_routes: if True, will yield routes whose leaves\n",
    "            have children in the full graph. This could be useful if, for example,\n",
    "            there are purchasable molecules which have children.\n",
    "            Typically this will be undesirable though.\n",
    "\n",
    "    Yields:\n",
    "        Tuples of cost, route nodes.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize priority queue\n",
    "    # items are: cost, whether the cost is the true cost or a lower bound,\n",
    "    # tie-breaking integer (since sets cannot be ordered),\n",
    "    # set of nodes in partial route, list of nodes on the route's frontier\n",
    "    \n",
    "    \n",
    "    ### CHANGE START ###\n",
    "#     queue: list[tuple[float, bool, int, set[NodeType], list[NodeType]]] = [\n",
    "#         (-math.inf, False, 0, {graph.root_node}, [graph.root_node])\n",
    "#     ]\n",
    "    queue: list[tuple[float, bool, int, set[NodeType], list[NodeType]]] = [\n",
    "        (-math.inf, False, 0, {start_node}, [start_node])\n",
    "    ]\n",
    "    ### END CHANGE ###\n",
    "    tie_breaker = 1\n",
    "\n",
    "    # Do best-first search\n",
    "    num_routes_yielded = 0\n",
    "    while len(queue) > 0 and num_routes_yielded < max_routes:\n",
    "        # Pop route\n",
    "        cost, is_true_cost, _, partial_route, route_frontier = heapq.heappop(queue)\n",
    "        assert cost < math.inf, \"Infinite cost routes should not be in the queue.\"\n",
    "\n",
    "        # Scenario 1: if it is a full route, then yield it,\n",
    "        # because its cost must be lower than the partial cost of all other routes.\n",
    "        if is_true_cost:\n",
    "            assert len(route_frontier) == 0\n",
    "            return (cost, partial_route)\n",
    "            num_routes_yielded += 1\n",
    "        else:\n",
    "            # Choose the first node in the frontier to be \"expanded\"\n",
    "            # and re-add to the queue\n",
    "            assert len(route_frontier) > 0\n",
    "            node_to_expand = route_frontier[0]\n",
    "            remaining_frontier = route_frontier[1:]\n",
    "            possible_new_routes: list[tuple[set[NodeType], list[NodeType]]] = []\n",
    "\n",
    "            # Potentially add this node without any of its children\n",
    "            if len(list(graph.successors(node_to_expand))) == 0 or yield_partial_routes:\n",
    "                possible_new_routes.append((partial_route, remaining_frontier))\n",
    "\n",
    "            # Add all children routes, 1 at a time\n",
    "            if isinstance(node_to_expand, OrNode):\n",
    "                # For AND/OR trees, add each And Child and all of its children\n",
    "                for and_child in graph.successors(node_to_expand):\n",
    "                    and_child_children = list(graph.successors(and_child))\n",
    "                    new_partial_route = partial_route | {and_child} | set(and_child_children)\n",
    "                    # New frontier excludes nodes already in partial route which would either already be expanded\n",
    "                    # or be in the frontier already\n",
    "                    new_frontier = remaining_frontier + [\n",
    "                        n for n in and_child_children if n not in partial_route\n",
    "                    ]\n",
    "                    possible_new_routes.append((new_partial_route, new_frontier))\n",
    "#             elif isinstance(node_to_expand, MolSetNode):\n",
    "#                 # For MolSet graphs, add each child individually\n",
    "#                 for child in graph.successors(node_to_expand):\n",
    "#                     new_partial_route = partial_route | {child}\n",
    "#                     new_frontier = list(remaining_frontier)\n",
    "#                     if child not in partial_route:\n",
    "#                         new_frontier.append(child)\n",
    "#                     possible_new_routes.append((new_partial_route, new_frontier))\n",
    "            else:\n",
    "                raise TypeError(f\"Unknown node type {type(node_to_expand)}.\")\n",
    "\n",
    "            # Add all possible routes onto the queue\n",
    "            for new_partial_route, new_frontier in possible_new_routes:\n",
    "                if len(new_frontier) == 0:\n",
    "                    new_cost = cost_fn(new_partial_route, graph)\n",
    "                    assert new_cost >= cost, \"lower bound not satisfied\"\n",
    "                    new_cost_is_full = True\n",
    "                else:\n",
    "                    new_cost = cost_lower_bound(new_partial_route, graph)\n",
    "                    new_cost_is_full = False\n",
    "\n",
    "                if new_cost < math.inf:\n",
    "                    heapq.heappush(\n",
    "                        queue,\n",
    "                        (new_cost, new_cost_is_full, tie_breaker, new_partial_route, new_frontier),\n",
    "                    )\n",
    "                    tie_breaker += 1\n",
    "\n",
    "\n",
    "# def reachable_nodes(G, n):\n",
    "#     \"\"\"\n",
    "#     Returns the set of nodes that can be reached starting from node n in graph G.\n",
    "#     \"\"\"\n",
    "#     visited = set()  # Set to keep track of visited nodes\n",
    "#     stack = [n]  # Stack to keep track of nodes to explore\n",
    "    \n",
    "#     while stack:\n",
    "#         node = stack.pop()\n",
    "#         visited.add(node)\n",
    "#         successors = G.successors(node)\n",
    "#         for s in successors:\n",
    "#             if s not in visited:\n",
    "#                 stack.append(s)\n",
    "    \n",
    "#     return visited\n",
    "\n",
    "rows = []\n",
    "for name in algs_to_consider:    \n",
    "    output_graph_dict = result[name].output_graph_dict\n",
    "    for target_smiles, graph in output_graph_dict.items():\n",
    "        for node in graph._graph.nodes:\n",
    "            if isinstance(node, OrNode): # Molecule \n",
    "                row_data = {'name': name,\n",
    "                            'smiles': node.mol.smiles,\n",
    "                            'is_purchasable': node.mol.metadata[\"is_purchasable\"],\n",
    "                            'node_is_expanded': node.is_expanded,\n",
    "                            'node_depth': node.depth\n",
    "                           }\n",
    "                row_data.update(node.data) \n",
    "                # Compute minimal cost\n",
    "#                 # 1. Create subgraph from current node\n",
    "#                 # Get the set of descendants of the start node\n",
    "# #                 descendants = set(nx.descendants(graph, node))\n",
    "#                 descendants = reachable_nodes(graph, node)\n",
    "#                 # Add the start node itself to the set of descendants\n",
    "#                 descendants.add(node)\n",
    "#                 # Create the subgraph from the descendants\n",
    "#                 subgraph = graph._graph.subgraph(descendants)\n",
    "\n",
    "#                 # 2. Compute min cost routes\n",
    "#                 min_cost_route = route_extraction.min_cost_routes(subgraph, max_routes=1)\n",
    "#                 min_cost = _min_route_cost(min_cost_route, subgraph)\n",
    "#                 \n",
    "                min_route_result = custom_cost_min_route(\n",
    "                    graph=graph,\n",
    "                    start_node=node,\n",
    "                    cost_fn=_min_route_cost,\n",
    "                    cost_lower_bound=_min_route_partial_cost,\n",
    "                    max_routes=1,\n",
    "                    yield_partial_routes= False,\n",
    "                )\n",
    "                if min_route_result is not None:\n",
    "                    min_cost, min_cost_route = min_route_result\n",
    "                else:\n",
    "                    min_cost = np.inf\n",
    "                row_data.update({'minimal_cost_forward': min_cost})\n",
    "                rows = rows + [row_data]\n",
    "df_nodes = pd.DataFrame(rows)                \n",
    "        \n",
    "df_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb80f1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nodes['is_solved'] = (df_nodes['first_solution_time'] != np.inf)*1.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def41b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nodes.to_csv(f'{output_folder}/{algs_string}_df_nodes.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5de56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select_algorithm = 'Tanimoto-distance-TIMES10'\n",
    "\n",
    "df_nodes_red = df_nodes.loc[df_nodes['name'].isin(algs_to_consider)]\n",
    "\n",
    "solved_mask = df_nodes_red['is_solved']==1.0\n",
    "df_nodes_red_solved = df_nodes_red.loc[solved_mask]\n",
    "df_nodes_red_not_solved = df_nodes_red.loc[~solved_mask]\n",
    "\n",
    "x_axis_var = 'minimal_cost_forward'\n",
    "# y_axis_var = 'retro_star_value'\n",
    "y_axis_var = 'reaction_number'\n",
    "\n",
    "\n",
    "df_nodes_red['x_var_inf'] = (df_nodes_red[x_axis_var] == np.inf)*1.0\n",
    "df_nodes_red['y_var_inf'] = (df_nodes_red[y_axis_var] == np.inf)*1.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb90b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nodes_red.groupby(['is_solved', 'x_var_inf']).agg(\n",
    "    count=pd.NamedAgg(column=\"smiles\", aggfunc=\"count\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60cde2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nodes_red.groupby(['is_solved', 'y_var_inf']).agg(\n",
    "    count=pd.NamedAgg(column=\"smiles\", aggfunc=\"count\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb23b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "\n",
    "fig = px.box(df_nodes_red_solved, y=x_axis_var, \n",
    "             width=1000, height=600,\n",
    "             labels={\n",
    "#                      \"value\": \"Number of different routes (removing zeros)\",\n",
    "                 },\n",
    "            )\n",
    "\n",
    "# fig.update_layout(xaxis_title=None)\n",
    "# fig.update_xaxes(labelalias=labelalias, categoryorder='array', categoryarray=list(labelalias.keys()))\n",
    "# fig.write_image(f'{output_folder}/Correlation_{x_axis_var}_{y_axis_var}.png') \n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a484619",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.box(df_nodes_red, y=y_axis_var, x= 'is_solved',\n",
    "             width=1000, height=600,\n",
    "             labels={\n",
    "#                      \"value\": \"Number of different routes (removing zeros)\",\n",
    "                 },\n",
    "            )\n",
    "\n",
    "# fig.update_layout(xaxis_title=None)\n",
    "# fig.update_xaxes(labelalias=labelalias, categoryorder='array', categoryarray=list(labelalias.keys()))\n",
    "fig.write_image(f'{output_folder}/{y_axis_var}_{algs_string}_solved_not_solved.png') \n",
    "fig.show() \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8769dedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = px.box(df_nodes_red_not_solved, y=y_axis_var, \n",
    "#              width=1000, height=600,\n",
    "#              labels={\n",
    "# #                      \"value\": \"Number of different routes (removing zeros)\",\n",
    "#                  },\n",
    "#             )\n",
    "\n",
    "# # fig.update_layout(xaxis_title=None)\n",
    "# # fig.update_xaxes(labelalias=labelalias, categoryorder='array', categoryarray=list(labelalias.keys()))\n",
    "# # fig.write_image(f'{output_folder}/Correlation_{x_axis_var}_{y_axis_var}.png') \n",
    "# fig.show() \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f86bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "fig = px.scatter(df_nodes_red_solved, x=x_axis_var, y=y_axis_var, \n",
    "             width=1000, height=600,\n",
    "             labels={\n",
    "#                      \"value\": \"Number of different routes (removing zeros)\",\n",
    "                 },\n",
    "            )\n",
    "\n",
    "# fig.update_layout(xaxis_title=None)\n",
    "# fig.update_xaxes(labelalias=labelalias, categoryorder='array', categoryarray=list(labelalias.keys()))\n",
    "fig.write_image(f'{output_folder}/Correlation_{x_axis_var}_{y_axis_var}_{algs_string}.png') \n",
    "fig.show() \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4ca8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "fig = px.scatter(df_nodes_red_solved, x=x_axis_var, y=y_axis_var, color=\"node_depth\", \n",
    "             width=1000, height=600,\n",
    "             labels={\n",
    "#                      \"value\": \"Number of different routes (removing zeros)\",\n",
    "                 },\n",
    "            )\n",
    "\n",
    "# fig.update_layout(xaxis_title=None)\n",
    "# fig.update_xaxes(labelalias=labelalias, categoryorder='array', categoryarray=list(labelalias.keys()))\n",
    "fig.write_image(f'{output_folder}/Correlation_{x_axis_var}_{y_axis_var}_{algs_string}_by_node_depth.png') \n",
    "fig.show() \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0f754a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(df_nodes_red_solved.loc[df_nodes_red_solved['node_depth']<5], x=x_axis_var, y=y_axis_var, \n",
    "             width=1000, height=600,\n",
    "             labels={\n",
    "#                      \"value\": \"Number of different routes (removing zeros)\",\n",
    "                 },\n",
    "            )\n",
    "\n",
    "# fig.update_layout(xaxis_title=None)\n",
    "# fig.update_xaxes(labelalias=labelalias, categoryorder='array', categoryarray=list(labelalias.keys()))\n",
    "fig.write_image(f'{output_folder}/Correlation_{x_axis_var}_{y_axis_var}_{algs_string}_depth_below_5.png') \n",
    "fig.show() \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2fb19d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.box(df_nodes_red_solved, x=x_axis_var, y=y_axis_var, \n",
    "             width=1000, height=600,\n",
    "             labels={\n",
    "#                      \"value\": \"Number of different routes (removing zeros)\",\n",
    "                 },\n",
    "            )\n",
    "# fig = px.box(df_nodes_red_solved.loc[df_nodes_red_solved['node_depth']<5], x=x_axis_var, y=y_axis_var, \n",
    "#              width=1000, height=600,\n",
    "#              labels={\n",
    "# #                      \"value\": \"Number of different routes (removing zeros)\",\n",
    "#                  },\n",
    "#             )\n",
    "\n",
    "# fig.update_layout(xaxis_title=None)\n",
    "fig.update_xaxes(categoryorder='category ascending')\n",
    "fig.write_image(f'{output_folder}/Correlation_{x_axis_var}_{y_axis_var}_{algs_string}_boxplot.png') \n",
    "fig.show() \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964000ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = px.box(df_nodes_red_solved.loc[df_nodes_red_solved['node_depth']<5], x=x_axis_var, y=y_axis_var, \n",
    "             width=1000, height=600,\n",
    "             labels={\n",
    "#                      \"value\": \"Number of different routes (removing zeros)\",\n",
    "                 },\n",
    "            )\n",
    "\n",
    "# fig.update_layout(xaxis_title=None)\n",
    "fig.update_xaxes(categoryorder='category ascending')\n",
    "fig.write_image(f'{output_folder}/Correlation_{x_axis_var}_{y_axis_var}_{algs_string}_boxplot_depth_below_5.png') \n",
    "fig.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cebf848",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = px.box(df_nodes_red_solved.loc[df_nodes_red_solved['node_depth']>=5], x=x_axis_var, y=y_axis_var, \n",
    "             width=1000, height=600,\n",
    "             labels={\n",
    "#                      \"value\": \"Number of different routes (removing zeros)\",\n",
    "                 },\n",
    "            )\n",
    "\n",
    "# fig.update_layout(xaxis_title=None)\n",
    "fig.update_xaxes(categoryorder='category ascending')\n",
    "fig.write_image(f'{output_folder}/Correlation_{x_axis_var}_{y_axis_var}_{algs_string}_boxplot_depth_above_5.png') \n",
    "fig.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e78529",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad7523b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
